{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0      3   2   2  25   0   3  10   0   0   0   0   0   0   0   0   0   1   1\n",
      "1      3   3   1  61   0   3  10   0   0   0   0   0   0   0   0   0   7   1\n",
      "2      3   3   1  65   0   3  10   0   0   0   0   0   0   0   0   0   6   1\n",
      "3      3   2   1  49   0   3  10   0   0   0   1   0   0   0   0   0   5   1\n",
      "4      3   1   1  54   0   5   2   1   1   0   0   0   0   0   0   1   5   1\n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "3414   1   2   1  57   0   6   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3415   1   1   1  24   0   3   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3416   1   1   1  50   0   3  10   0   0   0   0   0   0   0   0   0   6   4\n",
      "3417   1   2   1  58   0   3   9   0   0   0   0   0   0   0   0   0   6   4\n",
      "3418   1   2   1   3   0   4  10   0   0   0   0   0   0   0   0   0   5   4\n",
      "\n",
      "[3419 rows x 18 columns]\n",
      "      0\n",
      "0     0\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "...  ..\n",
      "3414  1\n",
      "3415  1\n",
      "3416  1\n",
      "3417  0\n",
      "3418  1\n",
      "\n",
      "[3419 rows x 1 columns]\n",
      "(2735, 18)\n",
      "(2735, 1)\n",
      "(684, 18)\n",
      "Index(['Location of Incident', 'Time', 'Sex', 'Age', 'Intentional', 'Role',\n",
      "       'Injury Agent', 'Confined Space', 'Grain Involved', 'Alcohol/Drugs',\n",
      "       'Seatbelt', 'Helmet', 'ROPS', 'Agritourism', 'Other PPE',\n",
      "       'Drowning/Suffocation', 'Day', 'Season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('/Users/eddie/Downloads/Log In - AgInjuryNews (1).xlsx - Sheet1 (1) - Log In - AgInjuryNews (1).xlsx - Sheet1 (1).csv')\n",
    "X = pd.DataFrame(dataset.iloc[:,:18].values)\n",
    "Y = pd.DataFrame(dataset.iloc[:,18:].values)\n",
    "print(X)\n",
    "print(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=0)\n",
    "X_train, X_train_val, Y_train, Y_train_val = train_test_split(X,Y,test_size=0.2)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.reshape(2735,18,1)\n",
    "X_test.reshape(684,18,1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "features = pd.DataFrame(dataset.iloc[:,:18])\n",
    "features = features.columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SimpleRNN, Input, LayerNormalization, MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "69/69 - 7s - loss: 0.6563 - accuracy: 0.6399 - val_loss: 0.6695 - val_accuracy: 0.6088 - 7s/epoch - 95ms/step\n",
      "Epoch 2/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 956ms/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "69/69 - 1s - loss: 0.6511 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 4/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6825 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6780 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 1s/epoch - 16ms/step\n",
      "Epoch 8/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6806 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 9/1000\n",
      "69/69 - 1s - loss: 0.6586 - accuracy: 0.6444 - val_loss: 0.6896 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 10/1000\n",
      "69/69 - 1s - loss: 0.6569 - accuracy: 0.6444 - val_loss: 0.6849 - val_accuracy: 0.6088 - 695ms/epoch - 10ms/step\n",
      "Epoch 11/1000\n",
      "69/69 - 1s - loss: 0.6511 - accuracy: 0.6444 - val_loss: 0.6913 - val_accuracy: 0.6088 - 737ms/epoch - 11ms/step\n",
      "Epoch 12/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6832 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 1s/epoch - 16ms/step\n",
      "Epoch 18/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6742 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 19/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6758 - val_accuracy: 0.6088 - 773ms/epoch - 11ms/step\n",
      "Epoch 20/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 745ms/epoch - 11ms/step\n",
      "Epoch 21/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6877 - val_accuracy: 0.6088 - 969ms/epoch - 14ms/step\n",
      "Epoch 22/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 1s/epoch - 15ms/step\n",
      "Epoch 24/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 996ms/epoch - 14ms/step\n",
      "Epoch 25/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 930ms/epoch - 13ms/step\n",
      "Epoch 26/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6731 - val_accuracy: 0.6088 - 937ms/epoch - 14ms/step\n",
      "Epoch 27/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 689ms/epoch - 10ms/step\n",
      "Epoch 28/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6797 - val_accuracy: 0.6088 - 581ms/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "69/69 - 1s - loss: 0.6546 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "69/69 - 1s - loss: 0.6551 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6762 - val_accuracy: 0.6088 - 638ms/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6768 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 846ms/epoch - 12ms/step\n",
      "Epoch 34/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 35/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6743 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 36/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 907ms/epoch - 13ms/step\n",
      "Epoch 37/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 690ms/epoch - 10ms/step\n",
      "Epoch 38/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6767 - val_accuracy: 0.6088 - 646ms/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 716ms/epoch - 10ms/step\n",
      "Epoch 44/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6801 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 45/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 46/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6933 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 47/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 827ms/epoch - 12ms/step\n",
      "Epoch 48/1000\n",
      "69/69 - 1s - loss: 0.6551 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 49/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 634ms/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 636ms/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6748 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 53/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 682ms/epoch - 10ms/step\n",
      "Epoch 55/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 56/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6773 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 57/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 58/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 832ms/epoch - 12ms/step\n",
      "Epoch 59/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 60/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 61/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6928 - val_accuracy: 0.6088 - 602ms/epoch - 9ms/step\n",
      "Epoch 62/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 602ms/epoch - 9ms/step\n",
      "Epoch 63/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6791 - val_accuracy: 0.6088 - 602ms/epoch - 9ms/step\n",
      "Epoch 64/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 65/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6725 - val_accuracy: 0.6088 - 742ms/epoch - 11ms/step\n",
      "Epoch 66/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6826 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 67/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 68/1000\n",
      "69/69 - 1s - loss: 0.6573 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 69/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 744ms/epoch - 11ms/step\n",
      "Epoch 70/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6726 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 71/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 72/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 73/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 651ms/epoch - 9ms/step\n",
      "Epoch 74/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 75/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 771ms/epoch - 11ms/step\n",
      "Epoch 76/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 77/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 78/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 79/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 732ms/epoch - 11ms/step\n",
      "Epoch 80/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 584ms/epoch - 8ms/step\n",
      "Epoch 81/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 645ms/epoch - 9ms/step\n",
      "Epoch 82/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6808 - val_accuracy: 0.6088 - 648ms/epoch - 9ms/step\n",
      "Epoch 83/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6797 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 84/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 85/1000\n",
      "69/69 - 1s - loss: 0.6564 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 702ms/epoch - 10ms/step\n",
      "Epoch 86/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 911ms/epoch - 13ms/step\n",
      "Epoch 87/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 904ms/epoch - 13ms/step\n",
      "Epoch 88/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 89/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6732 - val_accuracy: 0.6088 - 844ms/epoch - 12ms/step\n",
      "Epoch 90/1000\n",
      "69/69 - 1s - loss: 0.6509 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 91/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6768 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 92/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6774 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 93/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 94/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6764 - val_accuracy: 0.6088 - 638ms/epoch - 9ms/step\n",
      "Epoch 95/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6733 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 96/1000\n",
      "69/69 - 1s - loss: 0.6555 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 816ms/epoch - 12ms/step\n",
      "Epoch 97/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6755 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 98/1000\n",
      "69/69 - 1s - loss: 0.6511 - accuracy: 0.6444 - val_loss: 0.6911 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 99/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 100/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6793 - val_accuracy: 0.6088 - 702ms/epoch - 10ms/step\n",
      "Epoch 101/1000\n",
      "69/69 - 1s - loss: 0.6551 - accuracy: 0.6444 - val_loss: 0.6760 - val_accuracy: 0.6088 - 652ms/epoch - 9ms/step\n",
      "Epoch 102/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 103/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 621ms/epoch - 9ms/step\n",
      "Epoch 104/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 632ms/epoch - 9ms/step\n",
      "Epoch 105/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 106/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 668ms/epoch - 10ms/step\n",
      "Epoch 107/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6736 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 108/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6756 - val_accuracy: 0.6088 - 909ms/epoch - 13ms/step\n",
      "Epoch 109/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 110/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 864ms/epoch - 13ms/step\n",
      "Epoch 111/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 112/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 113/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6756 - val_accuracy: 0.6088 - 621ms/epoch - 9ms/step\n",
      "Epoch 114/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6758 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 115/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6781 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 116/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6726 - val_accuracy: 0.6088 - 637ms/epoch - 9ms/step\n",
      "Epoch 117/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6809 - val_accuracy: 0.6088 - 786ms/epoch - 11ms/step\n",
      "Epoch 118/1000\n",
      "69/69 - 1s - loss: 0.6557 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 119/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 120/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 883ms/epoch - 13ms/step\n",
      "Epoch 121/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 765ms/epoch - 11ms/step\n",
      "Epoch 122/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 123/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6762 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 124/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 125/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 126/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6820 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 127/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 128/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6774 - val_accuracy: 0.6088 - 904ms/epoch - 13ms/step\n",
      "Epoch 129/1000\n",
      "69/69 - 1s - loss: 0.6559 - accuracy: 0.6444 - val_loss: 0.6799 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 130/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6732 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 131/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6785 - val_accuracy: 0.6088 - 878ms/epoch - 13ms/step\n",
      "Epoch 132/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 676ms/epoch - 10ms/step\n",
      "Epoch 133/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6804 - val_accuracy: 0.6088 - 591ms/epoch - 9ms/step\n",
      "Epoch 134/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 135/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6743 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 136/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6762 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 137/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 138/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6787 - val_accuracy: 0.6088 - 713ms/epoch - 10ms/step\n",
      "Epoch 139/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 140/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.7046 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 141/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 900ms/epoch - 13ms/step\n",
      "Epoch 142/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6775 - val_accuracy: 0.6088 - 774ms/epoch - 11ms/step\n",
      "Epoch 143/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6834 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 144/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 145/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6790 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 146/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6803 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 147/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6848 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 148/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 653ms/epoch - 9ms/step\n",
      "Epoch 149/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 150/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6828 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 151/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 906ms/epoch - 13ms/step\n",
      "Epoch 152/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 153/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 154/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6849 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 155/1000\n",
      "69/69 - 1s - loss: 0.6509 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 156/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6837 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 157/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 634ms/epoch - 9ms/step\n",
      "Epoch 158/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 159/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 701ms/epoch - 10ms/step\n",
      "Epoch 160/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 161/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 162/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 163/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 859ms/epoch - 12ms/step\n",
      "Epoch 164/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 165/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 166/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6771 - val_accuracy: 0.6088 - 626ms/epoch - 9ms/step\n",
      "Epoch 167/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 168/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 645ms/epoch - 9ms/step\n",
      "Epoch 169/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 170/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6761 - val_accuracy: 0.6088 - 763ms/epoch - 11ms/step\n",
      "Epoch 171/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6759 - val_accuracy: 0.6088 - 906ms/epoch - 13ms/step\n",
      "Epoch 172/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 907ms/epoch - 13ms/step\n",
      "Epoch 173/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6736 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 174/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 725ms/epoch - 11ms/step\n",
      "Epoch 175/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 176/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 627ms/epoch - 9ms/step\n",
      "Epoch 177/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 178/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 179/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6757 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 180/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6731 - val_accuracy: 0.6088 - 909ms/epoch - 13ms/step\n",
      "Epoch 181/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 957ms/epoch - 14ms/step\n",
      "Epoch 182/1000\n",
      "69/69 - 1s - loss: 0.6554 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 958ms/epoch - 14ms/step\n",
      "Epoch 183/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6746 - val_accuracy: 0.6088 - 947ms/epoch - 14ms/step\n",
      "Epoch 184/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6776 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 185/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 186/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 187/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 188/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 189/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 635ms/epoch - 9ms/step\n",
      "Epoch 190/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 806ms/epoch - 12ms/step\n",
      "Epoch 191/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 192/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 193/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6714 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 194/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 735ms/epoch - 11ms/step\n",
      "Epoch 195/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6743 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 196/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6772 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 197/1000\n",
      "69/69 - 1s - loss: 0.6508 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 626ms/epoch - 9ms/step\n",
      "Epoch 198/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6788 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 199/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 200/1000\n",
      "69/69 - 1s - loss: 0.6557 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 689ms/epoch - 10ms/step\n",
      "Epoch 201/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 202/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 903ms/epoch - 13ms/step\n",
      "Epoch 203/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 204/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 850ms/epoch - 12ms/step\n",
      "Epoch 205/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 206/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6773 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 207/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6898 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 208/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6799 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 209/1000\n",
      "69/69 - 1s - loss: 0.6508 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 210/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6714 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 211/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 803ms/epoch - 12ms/step\n",
      "Epoch 212/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6766 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 213/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6757 - val_accuracy: 0.6088 - 878ms/epoch - 13ms/step\n",
      "Epoch 214/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 215/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 734ms/epoch - 11ms/step\n",
      "Epoch 216/1000\n",
      "69/69 - 1s - loss: 0.6554 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 217/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6762 - val_accuracy: 0.6088 - 569ms/epoch - 8ms/step\n",
      "Epoch 218/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 219/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6756 - val_accuracy: 0.6088 - 621ms/epoch - 9ms/step\n",
      "Epoch 220/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 221/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6766 - val_accuracy: 0.6088 - 709ms/epoch - 10ms/step\n",
      "Epoch 222/1000\n",
      "69/69 - 1s - loss: 0.6555 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 223/1000\n",
      "69/69 - 1s - loss: 0.6575 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 224/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 225/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6725 - val_accuracy: 0.6088 - 805ms/epoch - 12ms/step\n",
      "Epoch 226/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6783 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 227/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6811 - val_accuracy: 0.6088 - 595ms/epoch - 9ms/step\n",
      "Epoch 228/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 229/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6777 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 230/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6733 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 231/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 681ms/epoch - 10ms/step\n",
      "Epoch 232/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6742 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 233/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6824 - val_accuracy: 0.6088 - 882ms/epoch - 13ms/step\n",
      "Epoch 234/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 235/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 845ms/epoch - 12ms/step\n",
      "Epoch 236/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 237/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 590ms/epoch - 9ms/step\n",
      "Epoch 238/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6822 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 239/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 240/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 636ms/epoch - 9ms/step\n",
      "Epoch 241/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6765 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 242/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6736 - val_accuracy: 0.6088 - 696ms/epoch - 10ms/step\n",
      "Epoch 243/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6851 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 244/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6783 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 245/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 904ms/epoch - 13ms/step\n",
      "Epoch 246/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 827ms/epoch - 12ms/step\n",
      "Epoch 247/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6766 - val_accuracy: 0.6088 - 592ms/epoch - 9ms/step\n",
      "Epoch 248/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 588ms/epoch - 9ms/step\n",
      "Epoch 249/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6736 - val_accuracy: 0.6088 - 637ms/epoch - 9ms/step\n",
      "Epoch 250/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 597ms/epoch - 9ms/step\n",
      "Epoch 251/1000\n",
      "69/69 - 1s - loss: 0.6557 - accuracy: 0.6444 - val_loss: 0.6748 - val_accuracy: 0.6088 - 589ms/epoch - 9ms/step\n",
      "Epoch 252/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 588ms/epoch - 9ms/step\n",
      "Epoch 253/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 851ms/epoch - 12ms/step\n",
      "Epoch 254/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6743 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 255/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 256/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6731 - val_accuracy: 0.6088 - 818ms/epoch - 12ms/step\n",
      "Epoch 257/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 258/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6765 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 259/1000\n",
      "69/69 - 1s - loss: 0.6498 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 260/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6761 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 261/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 631ms/epoch - 9ms/step\n",
      "Epoch 262/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6760 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 263/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 264/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6772 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 265/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 626ms/epoch - 9ms/step\n",
      "Epoch 266/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 267/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6777 - val_accuracy: 0.6088 - 908ms/epoch - 13ms/step\n",
      "Epoch 268/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6829 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 269/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 751ms/epoch - 11ms/step\n",
      "Epoch 270/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6754 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 271/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6783 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 272/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 273/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6762 - val_accuracy: 0.6088 - 634ms/epoch - 9ms/step\n",
      "Epoch 274/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6724 - val_accuracy: 0.6088 - 627ms/epoch - 9ms/step\n",
      "Epoch 275/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 634ms/epoch - 9ms/step\n",
      "Epoch 276/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 654ms/epoch - 9ms/step\n",
      "Epoch 277/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 278/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 700ms/epoch - 10ms/step\n",
      "Epoch 279/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 280/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 281/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 282/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6802 - val_accuracy: 0.6088 - 632ms/epoch - 9ms/step\n",
      "Epoch 283/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 284/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6888 - val_accuracy: 0.6088 - 597ms/epoch - 9ms/step\n",
      "Epoch 285/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 286/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 580ms/epoch - 8ms/step\n",
      "Epoch 287/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6845 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 288/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 289/1000\n",
      "69/69 - 1s - loss: 0.6566 - accuracy: 0.6444 - val_loss: 0.6776 - val_accuracy: 0.6088 - 644ms/epoch - 9ms/step\n",
      "Epoch 290/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6760 - val_accuracy: 0.6088 - 865ms/epoch - 13ms/step\n",
      "Epoch 291/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6796 - val_accuracy: 0.6088 - 878ms/epoch - 13ms/step\n",
      "Epoch 292/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6731 - val_accuracy: 0.6088 - 878ms/epoch - 13ms/step\n",
      "Epoch 293/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 759ms/epoch - 11ms/step\n",
      "Epoch 294/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 579ms/epoch - 8ms/step\n",
      "Epoch 295/1000\n",
      "69/69 - 1s - loss: 0.6551 - accuracy: 0.6444 - val_loss: 0.6788 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 296/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6766 - val_accuracy: 0.6088 - 649ms/epoch - 9ms/step\n",
      "Epoch 297/1000\n",
      "69/69 - 1s - loss: 0.6560 - accuracy: 0.6444 - val_loss: 0.6751 - val_accuracy: 0.6088 - 640ms/epoch - 9ms/step\n",
      "Epoch 298/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 640ms/epoch - 9ms/step\n",
      "Epoch 299/1000\n",
      "69/69 - 1s - loss: 0.6503 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 651ms/epoch - 9ms/step\n",
      "Epoch 300/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6765 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 301/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6800 - val_accuracy: 0.6088 - 674ms/epoch - 10ms/step\n",
      "Epoch 302/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 828ms/epoch - 12ms/step\n",
      "Epoch 303/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 304/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6785 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 305/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 838ms/epoch - 12ms/step\n",
      "Epoch 306/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6737 - val_accuracy: 0.6088 - 573ms/epoch - 8ms/step\n",
      "Epoch 307/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 308/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.6088 - 637ms/epoch - 9ms/step\n",
      "Epoch 309/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6812 - val_accuracy: 0.6088 - 653ms/epoch - 9ms/step\n",
      "Epoch 310/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 660ms/epoch - 10ms/step\n",
      "Epoch 311/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 637ms/epoch - 9ms/step\n",
      "Epoch 312/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 660ms/epoch - 10ms/step\n",
      "Epoch 313/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 646ms/epoch - 9ms/step\n",
      "Epoch 314/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 797ms/epoch - 12ms/step\n",
      "Epoch 315/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6734 - val_accuracy: 0.6088 - 873ms/epoch - 13ms/step\n",
      "Epoch 316/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 317/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 318/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 626ms/epoch - 9ms/step\n",
      "Epoch 319/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 692ms/epoch - 10ms/step\n",
      "Epoch 320/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 654ms/epoch - 9ms/step\n",
      "Epoch 321/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 322/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6759 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 323/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 577ms/epoch - 8ms/step\n",
      "Epoch 324/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 592ms/epoch - 9ms/step\n",
      "Epoch 325/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 839ms/epoch - 12ms/step\n",
      "Epoch 326/1000\n",
      "69/69 - 1s - loss: 0.6546 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 327/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6841 - val_accuracy: 0.6088 - 882ms/epoch - 13ms/step\n",
      "Epoch 328/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 781ms/epoch - 11ms/step\n",
      "Epoch 329/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6726 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 330/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6943 - val_accuracy: 0.6088 - 631ms/epoch - 9ms/step\n",
      "Epoch 331/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 332/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6780 - val_accuracy: 0.6088 - 632ms/epoch - 9ms/step\n",
      "Epoch 333/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6747 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 334/1000\n",
      "69/69 - 1s - loss: 0.6555 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 673ms/epoch - 10ms/step\n",
      "Epoch 335/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6755 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 336/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 640ms/epoch - 9ms/step\n",
      "Epoch 337/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 872ms/epoch - 13ms/step\n",
      "Epoch 338/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 339/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6843 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 340/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 792ms/epoch - 11ms/step\n",
      "Epoch 341/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 635ms/epoch - 9ms/step\n",
      "Epoch 342/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 637ms/epoch - 9ms/step\n",
      "Epoch 343/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 344/1000\n",
      "69/69 - 1s - loss: 0.6567 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 643ms/epoch - 9ms/step\n",
      "Epoch 345/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 346/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 347/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 627ms/epoch - 9ms/step\n",
      "Epoch 348/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 637ms/epoch - 9ms/step\n",
      "Epoch 349/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 812ms/epoch - 12ms/step\n",
      "Epoch 350/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 351/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6788 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 352/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6746 - val_accuracy: 0.6088 - 840ms/epoch - 12ms/step\n",
      "Epoch 353/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 354/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6733 - val_accuracy: 0.6088 - 645ms/epoch - 9ms/step\n",
      "Epoch 355/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 356/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 635ms/epoch - 9ms/step\n",
      "Epoch 357/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 635ms/epoch - 9ms/step\n",
      "Epoch 358/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6755 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 359/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 634ms/epoch - 9ms/step\n",
      "Epoch 360/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 633ms/epoch - 9ms/step\n",
      "Epoch 361/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 800ms/epoch - 12ms/step\n",
      "Epoch 362/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 901ms/epoch - 13ms/step\n",
      "Epoch 363/1000\n",
      "69/69 - 1s - loss: 0.6559 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 364/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6748 - val_accuracy: 0.6088 - 854ms/epoch - 12ms/step\n",
      "Epoch 365/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 627ms/epoch - 9ms/step\n",
      "Epoch 366/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 647ms/epoch - 9ms/step\n",
      "Epoch 367/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 368/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 369/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 370/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6831 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 371/1000\n",
      "69/69 - 1s - loss: 0.6498 - accuracy: 0.6444 - val_loss: 0.6786 - val_accuracy: 0.6088 - 580ms/epoch - 8ms/step\n",
      "Epoch 372/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6743 - val_accuracy: 0.6088 - 593ms/epoch - 9ms/step\n",
      "Epoch 373/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 661ms/epoch - 10ms/step\n",
      "Epoch 374/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 375/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 376/1000\n",
      "69/69 - 1s - loss: 0.6556 - accuracy: 0.6444 - val_loss: 0.6891 - val_accuracy: 0.6088 - 898ms/epoch - 13ms/step\n",
      "Epoch 377/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6762 - val_accuracy: 0.6088 - 691ms/epoch - 10ms/step\n",
      "Epoch 378/1000\n",
      "69/69 - 1s - loss: 0.6558 - accuracy: 0.6444 - val_loss: 0.6733 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 379/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 380/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 381/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6748 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 382/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 383/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 654ms/epoch - 9ms/step\n",
      "Epoch 384/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6770 - val_accuracy: 0.6088 - 654ms/epoch - 9ms/step\n",
      "Epoch 385/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 386/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 387/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6753 - val_accuracy: 0.6088 - 889ms/epoch - 13ms/step\n",
      "Epoch 388/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 756ms/epoch - 11ms/step\n",
      "Epoch 389/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6764 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 390/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 391/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 683ms/epoch - 10ms/step\n",
      "Epoch 392/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6712 - val_accuracy: 0.6088 - 631ms/epoch - 9ms/step\n",
      "Epoch 393/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 738ms/epoch - 11ms/step\n",
      "Epoch 394/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6798 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 395/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 869ms/epoch - 13ms/step\n",
      "Epoch 396/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6724 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 397/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6901 - val_accuracy: 0.6088 - 814ms/epoch - 12ms/step\n",
      "Epoch 398/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 627ms/epoch - 9ms/step\n",
      "Epoch 399/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6834 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 400/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6802 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 401/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 402/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 626ms/epoch - 9ms/step\n",
      "Epoch 403/1000\n",
      "69/69 - 1s - loss: 0.6580 - accuracy: 0.6444 - val_loss: 0.6759 - val_accuracy: 0.6088 - 762ms/epoch - 11ms/step\n",
      "Epoch 404/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 907ms/epoch - 13ms/step\n",
      "Epoch 405/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 406/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 407/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 908ms/epoch - 13ms/step\n",
      "Epoch 408/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 668ms/epoch - 10ms/step\n",
      "Epoch 409/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6734 - val_accuracy: 0.6088 - 655ms/epoch - 9ms/step\n",
      "Epoch 410/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 411/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6759 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 412/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 413/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 715ms/epoch - 10ms/step\n",
      "Epoch 414/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 415/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6734 - val_accuracy: 0.6088 - 883ms/epoch - 13ms/step\n",
      "Epoch 416/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 900ms/epoch - 13ms/step\n",
      "Epoch 417/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6802 - val_accuracy: 0.6088 - 830ms/epoch - 12ms/step\n",
      "Epoch 418/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 419/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6771 - val_accuracy: 0.6088 - 649ms/epoch - 9ms/step\n",
      "Epoch 420/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 593ms/epoch - 9ms/step\n",
      "Epoch 421/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 634ms/epoch - 9ms/step\n",
      "Epoch 422/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 765ms/epoch - 11ms/step\n",
      "Epoch 423/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 909ms/epoch - 13ms/step\n",
      "Epoch 424/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6767 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 425/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 917ms/epoch - 13ms/step\n",
      "Epoch 426/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6731 - val_accuracy: 0.6088 - 908ms/epoch - 13ms/step\n",
      "Epoch 427/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 757ms/epoch - 11ms/step\n",
      "Epoch 428/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 429/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 586ms/epoch - 8ms/step\n",
      "Epoch 430/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 585ms/epoch - 8ms/step\n",
      "Epoch 431/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 597ms/epoch - 9ms/step\n",
      "Epoch 432/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6819 - val_accuracy: 0.6088 - 771ms/epoch - 11ms/step\n",
      "Epoch 433/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6780 - val_accuracy: 0.6088 - 913ms/epoch - 13ms/step\n",
      "Epoch 434/1000\n",
      "69/69 - 1s - loss: 0.6553 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 904ms/epoch - 13ms/step\n",
      "Epoch 435/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 920ms/epoch - 13ms/step\n",
      "Epoch 436/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 906ms/epoch - 13ms/step\n",
      "Epoch 437/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6815 - val_accuracy: 0.6088 - 788ms/epoch - 11ms/step\n",
      "Epoch 438/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 439/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 440/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6748 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 441/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 442/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 826ms/epoch - 12ms/step\n",
      "Epoch 443/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 444/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 913ms/epoch - 13ms/step\n",
      "Epoch 445/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 446/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6778 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 447/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 850ms/epoch - 12ms/step\n",
      "Epoch 448/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6782 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 449/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 580ms/epoch - 8ms/step\n",
      "Epoch 450/1000\n",
      "69/69 - 1s - loss: 0.6506 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 451/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 645ms/epoch - 9ms/step\n",
      "Epoch 452/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 848ms/epoch - 12ms/step\n",
      "Epoch 453/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 915ms/epoch - 13ms/step\n",
      "Epoch 454/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6796 - val_accuracy: 0.6088 - 908ms/epoch - 13ms/step\n",
      "Epoch 455/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 456/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 457/1000\n",
      "69/69 - 1s - loss: 0.6511 - accuracy: 0.6444 - val_loss: 0.6919 - val_accuracy: 0.6088 - 903ms/epoch - 13ms/step\n",
      "Epoch 458/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 741ms/epoch - 11ms/step\n",
      "Epoch 459/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 460/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 654ms/epoch - 9ms/step\n",
      "Epoch 461/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6771 - val_accuracy: 0.6088 - 680ms/epoch - 10ms/step\n",
      "Epoch 462/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 882ms/epoch - 13ms/step\n",
      "Epoch 463/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 464/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6807 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 465/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 466/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6773 - val_accuracy: 0.6088 - 903ms/epoch - 13ms/step\n",
      "Epoch 467/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 773ms/epoch - 11ms/step\n",
      "Epoch 468/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 602ms/epoch - 9ms/step\n",
      "Epoch 469/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 470/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6776 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 471/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 794ms/epoch - 12ms/step\n",
      "Epoch 472/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6864 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 473/1000\n",
      "69/69 - 1s - loss: 0.6570 - accuracy: 0.6444 - val_loss: 0.6825 - val_accuracy: 0.6088 - 913ms/epoch - 13ms/step\n",
      "Epoch 474/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 909ms/epoch - 13ms/step\n",
      "Epoch 475/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 476/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6751 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 477/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6758 - val_accuracy: 0.6088 - 726ms/epoch - 11ms/step\n",
      "Epoch 478/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 646ms/epoch - 9ms/step\n",
      "Epoch 479/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 626ms/epoch - 9ms/step\n",
      "Epoch 480/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6794 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 481/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6712 - val_accuracy: 0.6088 - 763ms/epoch - 11ms/step\n",
      "Epoch 482/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6760 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 483/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 484/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 485/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 486/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6761 - val_accuracy: 0.6088 - 825ms/epoch - 12ms/step\n",
      "Epoch 487/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6951 - val_accuracy: 0.6088 - 632ms/epoch - 9ms/step\n",
      "Epoch 488/1000\n",
      "69/69 - 1s - loss: 0.6549 - accuracy: 0.6444 - val_loss: 0.6801 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 489/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 490/1000\n",
      "69/69 - 1s - loss: 0.6546 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 602ms/epoch - 9ms/step\n",
      "Epoch 491/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6738 - val_accuracy: 0.6088 - 798ms/epoch - 12ms/step\n",
      "Epoch 492/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 907ms/epoch - 13ms/step\n",
      "Epoch 493/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6712 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 494/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 495/1000\n",
      "69/69 - 1s - loss: 0.6570 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 496/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6856 - val_accuracy: 0.6088 - 664ms/epoch - 10ms/step\n",
      "Epoch 497/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 498/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 499/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6779 - val_accuracy: 0.6088 - 593ms/epoch - 9ms/step\n",
      "Epoch 500/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 501/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 883ms/epoch - 13ms/step\n",
      "Epoch 502/1000\n",
      "69/69 - 1s - loss: 0.6563 - accuracy: 0.6444 - val_loss: 0.6756 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 503/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6726 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 504/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6732 - val_accuracy: 0.6088 - 898ms/epoch - 13ms/step\n",
      "Epoch 505/1000\n",
      "69/69 - 1s - loss: 0.6501 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 922ms/epoch - 13ms/step\n",
      "Epoch 506/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 507/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 602ms/epoch - 9ms/step\n",
      "Epoch 508/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6785 - val_accuracy: 0.6088 - 644ms/epoch - 9ms/step\n",
      "Epoch 509/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6746 - val_accuracy: 0.6088 - 645ms/epoch - 9ms/step\n",
      "Epoch 510/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 669ms/epoch - 10ms/step\n",
      "Epoch 511/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 512/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6769 - val_accuracy: 0.6088 - 912ms/epoch - 13ms/step\n",
      "Epoch 513/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 861ms/epoch - 12ms/step\n",
      "Epoch 514/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 922ms/epoch - 13ms/step\n",
      "Epoch 515/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6725 - val_accuracy: 0.6088 - 653ms/epoch - 9ms/step\n",
      "Epoch 516/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 631ms/epoch - 9ms/step\n",
      "Epoch 517/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 640ms/epoch - 9ms/step\n",
      "Epoch 518/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6786 - val_accuracy: 0.6088 - 640ms/epoch - 9ms/step\n",
      "Epoch 519/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6826 - val_accuracy: 0.6088 - 649ms/epoch - 9ms/step\n",
      "Epoch 520/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6775 - val_accuracy: 0.6088 - 762ms/epoch - 11ms/step\n",
      "Epoch 521/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 522/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 936ms/epoch - 14ms/step\n",
      "Epoch 523/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 934ms/epoch - 14ms/step\n",
      "Epoch 524/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6767 - val_accuracy: 0.6088 - 904ms/epoch - 13ms/step\n",
      "Epoch 525/1000\n",
      "69/69 - 1s - loss: 0.6554 - accuracy: 0.6444 - val_loss: 0.6768 - val_accuracy: 0.6088 - 898ms/epoch - 13ms/step\n",
      "Epoch 526/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 527/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 528/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6799 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 529/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 530/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6858 - val_accuracy: 0.6088 - 692ms/epoch - 10ms/step\n",
      "Epoch 531/1000\n",
      "69/69 - 1s - loss: 0.6563 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 532/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6807 - val_accuracy: 0.6088 - 900ms/epoch - 13ms/step\n",
      "Epoch 533/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6757 - val_accuracy: 0.6088 - 907ms/epoch - 13ms/step\n",
      "Epoch 534/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 927ms/epoch - 13ms/step\n",
      "Epoch 535/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 733ms/epoch - 11ms/step\n",
      "Epoch 536/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 580ms/epoch - 8ms/step\n",
      "Epoch 537/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6897 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 538/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 539/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6793 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 540/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6712 - val_accuracy: 0.6088 - 781ms/epoch - 11ms/step\n",
      "Epoch 541/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 901ms/epoch - 13ms/step\n",
      "Epoch 542/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6746 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 543/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6792 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 544/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 545/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 651ms/epoch - 9ms/step\n",
      "Epoch 546/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 576ms/epoch - 8ms/step\n",
      "Epoch 547/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6758 - val_accuracy: 0.6088 - 570ms/epoch - 8ms/step\n",
      "Epoch 548/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 549/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 550/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 876ms/epoch - 13ms/step\n",
      "Epoch 551/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6725 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 552/1000\n",
      "69/69 - 1s - loss: 0.6510 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 553/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 554/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 793ms/epoch - 11ms/step\n",
      "Epoch 555/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6775 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 556/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6856 - val_accuracy: 0.6088 - 632ms/epoch - 9ms/step\n",
      "Epoch 557/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6742 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 558/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 559/1000\n",
      "69/69 - 1s - loss: 0.6508 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 560/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 869ms/epoch - 13ms/step\n",
      "Epoch 561/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6811 - val_accuracy: 0.6088 - 889ms/epoch - 13ms/step\n",
      "Epoch 562/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 563/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.7001 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 564/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 857ms/epoch - 12ms/step\n",
      "Epoch 565/1000\n",
      "69/69 - 1s - loss: 0.6567 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 566/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6743 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 567/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 568/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 631ms/epoch - 9ms/step\n",
      "Epoch 569/1000\n",
      "69/69 - 1s - loss: 0.6549 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 570/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 816ms/epoch - 12ms/step\n",
      "Epoch 571/1000\n",
      "69/69 - 1s - loss: 0.6560 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 572/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 573/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 574/1000\n",
      "69/69 - 1s - loss: 0.6564 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 575/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6807 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 576/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6806 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 577/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 578/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6768 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 579/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6758 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 580/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 788ms/epoch - 11ms/step\n",
      "Epoch 581/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 872ms/epoch - 13ms/step\n",
      "Epoch 582/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 583/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 584/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 585/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 586/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 587/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6802 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 588/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 615ms/epoch - 9ms/step\n",
      "Epoch 589/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6785 - val_accuracy: 0.6088 - 633ms/epoch - 9ms/step\n",
      "Epoch 590/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6714 - val_accuracy: 0.6088 - 668ms/epoch - 10ms/step\n",
      "Epoch 591/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6766 - val_accuracy: 0.6088 - 882ms/epoch - 13ms/step\n",
      "Epoch 592/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 909ms/epoch - 13ms/step\n",
      "Epoch 593/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 594/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 889ms/epoch - 13ms/step\n",
      "Epoch 595/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 850ms/epoch - 12ms/step\n",
      "Epoch 596/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 597/1000\n",
      "69/69 - 1s - loss: 0.6558 - accuracy: 0.6444 - val_loss: 0.6770 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 598/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 599/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 613ms/epoch - 9ms/step\n",
      "Epoch 600/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6738 - val_accuracy: 0.6088 - 652ms/epoch - 9ms/step\n",
      "Epoch 601/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6724 - val_accuracy: 0.6088 - 760ms/epoch - 11ms/step\n",
      "Epoch 602/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6792 - val_accuracy: 0.6088 - 876ms/epoch - 13ms/step\n",
      "Epoch 603/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6780 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 604/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 605/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 606/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 672ms/epoch - 10ms/step\n",
      "Epoch 607/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 608/1000\n",
      "69/69 - 1s - loss: 0.6511 - accuracy: 0.6444 - val_loss: 0.6732 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 609/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 595ms/epoch - 9ms/step\n",
      "Epoch 610/1000\n",
      "69/69 - 1s - loss: 0.6546 - accuracy: 0.6444 - val_loss: 0.6759 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 611/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6770 - val_accuracy: 0.6088 - 859ms/epoch - 12ms/step\n",
      "Epoch 612/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6859 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 613/1000\n",
      "69/69 - 1s - loss: 0.6568 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 614/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6765 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 615/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 616/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 617/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6769 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 618/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 584ms/epoch - 8ms/step\n",
      "Epoch 619/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 583ms/epoch - 8ms/step\n",
      "Epoch 620/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6769 - val_accuracy: 0.6088 - 635ms/epoch - 9ms/step\n",
      "Epoch 621/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6760 - val_accuracy: 0.6088 - 872ms/epoch - 13ms/step\n",
      "Epoch 622/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6852 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 623/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 624/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 889ms/epoch - 13ms/step\n",
      "Epoch 625/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 761ms/epoch - 11ms/step\n",
      "Epoch 626/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 575ms/epoch - 8ms/step\n",
      "Epoch 627/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6770 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 628/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 635ms/epoch - 9ms/step\n",
      "Epoch 629/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 637ms/epoch - 9ms/step\n",
      "Epoch 630/1000\n",
      "69/69 - 1s - loss: 0.6506 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 655ms/epoch - 9ms/step\n",
      "Epoch 631/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 632/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 633/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6842 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 634/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6787 - val_accuracy: 0.6088 - 924ms/epoch - 13ms/step\n",
      "Epoch 635/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 834ms/epoch - 12ms/step\n",
      "Epoch 636/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 573ms/epoch - 8ms/step\n",
      "Epoch 637/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6863 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 638/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6803 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 639/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 640/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 641/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 820ms/epoch - 12ms/step\n",
      "Epoch 642/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 643/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6792 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 644/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 645/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6777 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 646/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 647/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 648/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6858 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 649/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6768 - val_accuracy: 0.6088 - 595ms/epoch - 9ms/step\n",
      "Epoch 650/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 651/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6736 - val_accuracy: 0.6088 - 695ms/epoch - 10ms/step\n",
      "Epoch 652/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 875ms/epoch - 13ms/step\n",
      "Epoch 653/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 654/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 655/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 656/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6732 - val_accuracy: 0.6088 - 673ms/epoch - 10ms/step\n",
      "Epoch 657/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6851 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 658/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 659/1000\n",
      "69/69 - 1s - loss: 0.6567 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 660/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 661/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 721ms/epoch - 10ms/step\n",
      "Epoch 662/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 663/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6786 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 664/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 665/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 666/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6908 - val_accuracy: 0.6088 - 654ms/epoch - 9ms/step\n",
      "Epoch 667/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6724 - val_accuracy: 0.6088 - 667ms/epoch - 10ms/step\n",
      "Epoch 668/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 669/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 670/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 673ms/epoch - 10ms/step\n",
      "Epoch 671/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6800 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 672/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 896ms/epoch - 13ms/step\n",
      "Epoch 673/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 875ms/epoch - 13ms/step\n",
      "Epoch 674/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6773 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 675/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 693ms/epoch - 10ms/step\n",
      "Epoch 676/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 581ms/epoch - 8ms/step\n",
      "Epoch 677/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 678/1000\n",
      "69/69 - 1s - loss: 0.6562 - accuracy: 0.6444 - val_loss: 0.6771 - val_accuracy: 0.6088 - 579ms/epoch - 8ms/step\n",
      "Epoch 679/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6758 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 680/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 777ms/epoch - 11ms/step\n",
      "Epoch 681/1000\n",
      "69/69 - 1s - loss: 0.6507 - accuracy: 0.6444 - val_loss: 0.6876 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 682/1000\n",
      "69/69 - 1s - loss: 0.6544 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 898ms/epoch - 13ms/step\n",
      "Epoch 683/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6714 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 684/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 685/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 686/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 687/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 588ms/epoch - 9ms/step\n",
      "Epoch 688/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 589ms/epoch - 9ms/step\n",
      "Epoch 689/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6798 - val_accuracy: 0.6088 - 649ms/epoch - 9ms/step\n",
      "Epoch 690/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 889ms/epoch - 13ms/step\n",
      "Epoch 691/1000\n",
      "69/69 - 1s - loss: 0.6556 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 692/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6763 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 693/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6727 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 694/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6746 - val_accuracy: 0.6088 - 736ms/epoch - 11ms/step\n",
      "Epoch 695/1000\n",
      "69/69 - 1s - loss: 0.6555 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 696/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 626ms/epoch - 9ms/step\n",
      "Epoch 697/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 698/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 699/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6743 - val_accuracy: 0.6088 - 714ms/epoch - 10ms/step\n",
      "Epoch 700/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 701/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6711 - val_accuracy: 0.6088 - 882ms/epoch - 13ms/step\n",
      "Epoch 702/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6791 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 703/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 900ms/epoch - 13ms/step\n",
      "Epoch 704/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6733 - val_accuracy: 0.6088 - 636ms/epoch - 9ms/step\n",
      "Epoch 705/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6788 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 706/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 579ms/epoch - 8ms/step\n",
      "Epoch 707/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6789 - val_accuracy: 0.6088 - 590ms/epoch - 9ms/step\n",
      "Epoch 708/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 595ms/epoch - 9ms/step\n",
      "Epoch 709/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 832ms/epoch - 12ms/step\n",
      "Epoch 710/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 711/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 883ms/epoch - 13ms/step\n",
      "Epoch 712/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 713/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 846ms/epoch - 12ms/step\n",
      "Epoch 714/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 715/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6841 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 716/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 717/1000\n",
      "69/69 - 1s - loss: 0.6557 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 718/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6782 - val_accuracy: 0.6088 - 597ms/epoch - 9ms/step\n",
      "Epoch 719/1000\n",
      "69/69 - 1s - loss: 0.6578 - accuracy: 0.6444 - val_loss: 0.6860 - val_accuracy: 0.6088 - 747ms/epoch - 11ms/step\n",
      "Epoch 720/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 721/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6751 - val_accuracy: 0.6088 - 905ms/epoch - 13ms/step\n",
      "Epoch 722/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 723/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 724/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 725/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6873 - val_accuracy: 0.6088 - 591ms/epoch - 9ms/step\n",
      "Epoch 726/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6846 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 727/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 728/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 729/1000\n",
      "69/69 - 1s - loss: 0.6549 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 730/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 883ms/epoch - 13ms/step\n",
      "Epoch 731/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6726 - val_accuracy: 0.6088 - 876ms/epoch - 13ms/step\n",
      "Epoch 732/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 882ms/epoch - 13ms/step\n",
      "Epoch 733/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 734/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 777ms/epoch - 11ms/step\n",
      "Epoch 735/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6772 - val_accuracy: 0.6088 - 664ms/epoch - 10ms/step\n",
      "Epoch 736/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 737/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 592ms/epoch - 9ms/step\n",
      "Epoch 738/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 739/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6837 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 740/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 837ms/epoch - 12ms/step\n",
      "Epoch 741/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6830 - val_accuracy: 0.6088 - 866ms/epoch - 13ms/step\n",
      "Epoch 742/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 889ms/epoch - 13ms/step\n",
      "Epoch 743/1000\n",
      "69/69 - 1s - loss: 0.6499 - accuracy: 0.6444 - val_loss: 0.6786 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 744/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 829ms/epoch - 12ms/step\n",
      "Epoch 745/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6747 - val_accuracy: 0.6088 - 590ms/epoch - 9ms/step\n",
      "Epoch 746/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 592ms/epoch - 9ms/step\n",
      "Epoch 747/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 598ms/epoch - 9ms/step\n",
      "Epoch 748/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6927 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 749/1000\n",
      "69/69 - 1s - loss: 0.6570 - accuracy: 0.6444 - val_loss: 0.6773 - val_accuracy: 0.6088 - 689ms/epoch - 10ms/step\n",
      "Epoch 750/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 751/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 752/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 753/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6747 - val_accuracy: 0.6088 - 937ms/epoch - 14ms/step\n",
      "Epoch 754/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 755/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 605ms/epoch - 9ms/step\n",
      "Epoch 756/1000\n",
      "69/69 - 1s - loss: 0.6549 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 593ms/epoch - 9ms/step\n",
      "Epoch 757/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 758/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 759/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 760/1000\n",
      "69/69 - 1s - loss: 0.6510 - accuracy: 0.6444 - val_loss: 0.6776 - val_accuracy: 0.6088 - 863ms/epoch - 13ms/step\n",
      "Epoch 761/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6714 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 762/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 763/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6792 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 764/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6803 - val_accuracy: 0.6088 - 668ms/epoch - 10ms/step\n",
      "Epoch 765/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 595ms/epoch - 9ms/step\n",
      "Epoch 766/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6753 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 767/1000\n",
      "69/69 - 1s - loss: 0.6509 - accuracy: 0.6444 - val_loss: 0.6864 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 768/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 769/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6808 - val_accuracy: 0.6088 - 597ms/epoch - 9ms/step\n",
      "Epoch 770/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6725 - val_accuracy: 0.6088 - 688ms/epoch - 10ms/step\n",
      "Epoch 771/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 884ms/epoch - 13ms/step\n",
      "Epoch 772/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6833 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 773/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 901ms/epoch - 13ms/step\n",
      "Epoch 774/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 849ms/epoch - 12ms/step\n",
      "Epoch 775/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6839 - val_accuracy: 0.6088 - 581ms/epoch - 8ms/step\n",
      "Epoch 776/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6853 - val_accuracy: 0.6088 - 588ms/epoch - 9ms/step\n",
      "Epoch 777/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 565ms/epoch - 8ms/step\n",
      "Epoch 778/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 573ms/epoch - 8ms/step\n",
      "Epoch 779/1000\n",
      "69/69 - 1s - loss: 0.6571 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 780/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 781ms/epoch - 11ms/step\n",
      "Epoch 781/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6849 - val_accuracy: 0.6088 - 869ms/epoch - 13ms/step\n",
      "Epoch 782/1000\n",
      "69/69 - 1s - loss: 0.6565 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 783/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 784/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6817 - val_accuracy: 0.6088 - 734ms/epoch - 11ms/step\n",
      "Epoch 785/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 786/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6777 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 787/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 596ms/epoch - 9ms/step\n",
      "Epoch 788/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6779 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 789/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 790/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6733 - val_accuracy: 0.6088 - 625ms/epoch - 9ms/step\n",
      "Epoch 791/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6885 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 792/1000\n",
      "69/69 - 1s - loss: 0.6557 - accuracy: 0.6444 - val_loss: 0.6816 - val_accuracy: 0.6088 - 904ms/epoch - 13ms/step\n",
      "Epoch 793/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6774 - val_accuracy: 0.6088 - 876ms/epoch - 13ms/step\n",
      "Epoch 794/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 883ms/epoch - 13ms/step\n",
      "Epoch 795/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6712 - val_accuracy: 0.6088 - 668ms/epoch - 10ms/step\n",
      "Epoch 796/1000\n",
      "69/69 - 1s - loss: 0.6533 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 797/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6731 - val_accuracy: 0.6088 - 581ms/epoch - 8ms/step\n",
      "Epoch 798/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6739 - val_accuracy: 0.6088 - 599ms/epoch - 9ms/step\n",
      "Epoch 799/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 800/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6756 - val_accuracy: 0.6088 - 621ms/epoch - 9ms/step\n",
      "Epoch 801/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6791 - val_accuracy: 0.6088 - 720ms/epoch - 10ms/step\n",
      "Epoch 802/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6761 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 803/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 804/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 936ms/epoch - 14ms/step\n",
      "Epoch 805/1000\n",
      "69/69 - 1s - loss: 0.6548 - accuracy: 0.6444 - val_loss: 0.6734 - val_accuracy: 0.6088 - 814ms/epoch - 12ms/step\n",
      "Epoch 806/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 807/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6770 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 808/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 597ms/epoch - 9ms/step\n",
      "Epoch 809/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 810/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 811/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 660ms/epoch - 10ms/step\n",
      "Epoch 812/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 902ms/epoch - 13ms/step\n",
      "Epoch 813/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6775 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 814/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6817 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 815/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6749 - val_accuracy: 0.6088 - 853ms/epoch - 12ms/step\n",
      "Epoch 816/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 817/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 818/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6729 - val_accuracy: 0.6088 - 591ms/epoch - 9ms/step\n",
      "Epoch 819/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6819 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 820/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6735 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 821/1000\n",
      "69/69 - 1s - loss: 0.6551 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 822/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 689ms/epoch - 10ms/step\n",
      "Epoch 823/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 892ms/epoch - 13ms/step\n",
      "Epoch 824/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 825/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6734 - val_accuracy: 0.6088 - 904ms/epoch - 13ms/step\n",
      "Epoch 826/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 837ms/epoch - 12ms/step\n",
      "Epoch 827/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 602ms/epoch - 9ms/step\n",
      "Epoch 828/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6803 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 829/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6712 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 830/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 632ms/epoch - 9ms/step\n",
      "Epoch 831/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6853 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 832/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 833/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6819 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 834/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 872ms/epoch - 13ms/step\n",
      "Epoch 835/1000\n",
      "69/69 - 1s - loss: 0.6511 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 836/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6787 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 837/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6762 - val_accuracy: 0.6088 - 916ms/epoch - 13ms/step\n",
      "Epoch 838/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 676ms/epoch - 10ms/step\n",
      "Epoch 839/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 840/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6731 - val_accuracy: 0.6088 - 595ms/epoch - 9ms/step\n",
      "Epoch 841/1000\n",
      "69/69 - 1s - loss: 0.6506 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 842/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6769 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 843/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 667ms/epoch - 10ms/step\n",
      "Epoch 844/1000\n",
      "69/69 - 1s - loss: 0.6566 - accuracy: 0.6444 - val_loss: 0.6753 - val_accuracy: 0.6088 - 854ms/epoch - 12ms/step\n",
      "Epoch 845/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6796 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 846/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 899ms/epoch - 13ms/step\n",
      "Epoch 847/1000\n",
      "69/69 - 1s - loss: 0.6574 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 900ms/epoch - 13ms/step\n",
      "Epoch 848/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6766 - val_accuracy: 0.6088 - 701ms/epoch - 10ms/step\n",
      "Epoch 849/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 850/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 851/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6710 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 852/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6751 - val_accuracy: 0.6088 - 583ms/epoch - 8ms/step\n",
      "Epoch 853/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6778 - val_accuracy: 0.6088 - 589ms/epoch - 9ms/step\n",
      "Epoch 854/1000\n",
      "69/69 - 1s - loss: 0.6508 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 692ms/epoch - 10ms/step\n",
      "Epoch 855/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 903ms/epoch - 13ms/step\n",
      "Epoch 856/1000\n",
      "69/69 - 1s - loss: 0.6539 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 864ms/epoch - 13ms/step\n",
      "Epoch 857/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 858/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6773 - val_accuracy: 0.6088 - 847ms/epoch - 12ms/step\n",
      "Epoch 859/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 600ms/epoch - 9ms/step\n",
      "Epoch 860/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 861/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 631ms/epoch - 9ms/step\n",
      "Epoch 862/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 598ms/epoch - 9ms/step\n",
      "Epoch 863/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6872 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 864/1000\n",
      "69/69 - 1s - loss: 0.6556 - accuracy: 0.6444 - val_loss: 0.6715 - val_accuracy: 0.6088 - 620ms/epoch - 9ms/step\n",
      "Epoch 865/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6738 - val_accuracy: 0.6088 - 719ms/epoch - 10ms/step\n",
      "Epoch 866/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 891ms/epoch - 13ms/step\n",
      "Epoch 867/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6825 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 868/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6734 - val_accuracy: 0.6088 - 876ms/epoch - 13ms/step\n",
      "Epoch 869/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6719 - val_accuracy: 0.6088 - 853ms/epoch - 12ms/step\n",
      "Epoch 870/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6718 - val_accuracy: 0.6088 - 584ms/epoch - 8ms/step\n",
      "Epoch 871/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.6088 - 632ms/epoch - 9ms/step\n",
      "Epoch 872/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 639ms/epoch - 9ms/step\n",
      "Epoch 873/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 874/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 589ms/epoch - 9ms/step\n",
      "Epoch 875/1000\n",
      "69/69 - 1s - loss: 0.6508 - accuracy: 0.6444 - val_loss: 0.6819 - val_accuracy: 0.6088 - 744ms/epoch - 11ms/step\n",
      "Epoch 876/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6870 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 877/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6754 - val_accuracy: 0.6088 - 873ms/epoch - 13ms/step\n",
      "Epoch 878/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 879/1000\n",
      "69/69 - 1s - loss: 0.6550 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 814ms/epoch - 12ms/step\n",
      "Epoch 880/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6741 - val_accuracy: 0.6088 - 609ms/epoch - 9ms/step\n",
      "Epoch 881/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6815 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 882/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6733 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 883/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6850 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 884/1000\n",
      "69/69 - 1s - loss: 0.6546 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 885/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 886/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6742 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 887/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6771 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 888/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 889/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6757 - val_accuracy: 0.6088 - 877ms/epoch - 13ms/step\n",
      "Epoch 890/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 891/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6722 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 892/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 893/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 590ms/epoch - 9ms/step\n",
      "Epoch 894/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6761 - val_accuracy: 0.6088 - 608ms/epoch - 9ms/step\n",
      "Epoch 895/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 896/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 883ms/epoch - 13ms/step\n",
      "Epoch 897/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6723 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 898/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6700 - val_accuracy: 0.6088 - 903ms/epoch - 13ms/step\n",
      "Epoch 899/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6713 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 900/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6757 - val_accuracy: 0.6088 - 702ms/epoch - 10ms/step\n",
      "Epoch 901/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 627ms/epoch - 9ms/step\n",
      "Epoch 902/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6712 - val_accuracy: 0.6088 - 619ms/epoch - 9ms/step\n",
      "Epoch 903/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 638ms/epoch - 9ms/step\n",
      "Epoch 904/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 905/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6726 - val_accuracy: 0.6088 - 627ms/epoch - 9ms/step\n",
      "Epoch 906/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6755 - val_accuracy: 0.6088 - 629ms/epoch - 9ms/step\n",
      "Epoch 907/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 843ms/epoch - 12ms/step\n",
      "Epoch 908/1000\n",
      "69/69 - 1s - loss: 0.6499 - accuracy: 0.6444 - val_loss: 0.6884 - val_accuracy: 0.6088 - 879ms/epoch - 13ms/step\n",
      "Epoch 909/1000\n",
      "69/69 - 1s - loss: 0.6546 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 910/1000\n",
      "69/69 - 1s - loss: 0.6504 - accuracy: 0.6444 - val_loss: 0.6832 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 911/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6750 - val_accuracy: 0.6088 - 671ms/epoch - 10ms/step\n",
      "Epoch 912/1000\n",
      "69/69 - 1s - loss: 0.6531 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 610ms/epoch - 9ms/step\n",
      "Epoch 913/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 914/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6779 - val_accuracy: 0.6088 - 643ms/epoch - 9ms/step\n",
      "Epoch 915/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 641ms/epoch - 9ms/step\n",
      "Epoch 916/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 644ms/epoch - 9ms/step\n",
      "Epoch 917/1000\n",
      "69/69 - 1s - loss: 0.6535 - accuracy: 0.6444 - val_loss: 0.6751 - val_accuracy: 0.6088 - 836ms/epoch - 12ms/step\n",
      "Epoch 918/1000\n",
      "69/69 - 1s - loss: 0.6506 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 919/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6754 - val_accuracy: 0.6088 - 886ms/epoch - 13ms/step\n",
      "Epoch 920/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6807 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 921/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 756ms/epoch - 11ms/step\n",
      "Epoch 922/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 614ms/epoch - 9ms/step\n",
      "Epoch 923/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 587ms/epoch - 9ms/step\n",
      "Epoch 924/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6794 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 925/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6726 - val_accuracy: 0.6088 - 606ms/epoch - 9ms/step\n",
      "Epoch 926/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6701 - val_accuracy: 0.6088 - 617ms/epoch - 9ms/step\n",
      "Epoch 927/1000\n",
      "69/69 - 1s - loss: 0.6515 - accuracy: 0.6444 - val_loss: 0.6724 - val_accuracy: 0.6088 - 820ms/epoch - 12ms/step\n",
      "Epoch 928/1000\n",
      "69/69 - 1s - loss: 0.6549 - accuracy: 0.6444 - val_loss: 0.6759 - val_accuracy: 0.6088 - 887ms/epoch - 13ms/step\n",
      "Epoch 929/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 900ms/epoch - 13ms/step\n",
      "Epoch 930/1000\n",
      "69/69 - 1s - loss: 0.6523 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 931/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6847 - val_accuracy: 0.6088 - 719ms/epoch - 10ms/step\n",
      "Epoch 932/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 933/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6778 - val_accuracy: 0.6088 - 640ms/epoch - 9ms/step\n",
      "Epoch 934/1000\n",
      "69/69 - 1s - loss: 0.6560 - accuracy: 0.6444 - val_loss: 0.6753 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 935/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6808 - val_accuracy: 0.6088 - 638ms/epoch - 9ms/step\n",
      "Epoch 936/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6740 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 937/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6736 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 938/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6695 - val_accuracy: 0.6088 - 890ms/epoch - 13ms/step\n",
      "Epoch 939/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6781 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 940/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6708 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 941/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 942/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6757 - val_accuracy: 0.6088 - 643ms/epoch - 9ms/step\n",
      "Epoch 943/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6839 - val_accuracy: 0.6088 - 588ms/epoch - 9ms/step\n",
      "Epoch 944/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6788 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 945/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 604ms/epoch - 9ms/step\n",
      "Epoch 946/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6734 - val_accuracy: 0.6088 - 583ms/epoch - 8ms/step\n",
      "Epoch 947/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 727ms/epoch - 11ms/step\n",
      "Epoch 948/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6793 - val_accuracy: 0.6088 - 881ms/epoch - 13ms/step\n",
      "Epoch 949/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 950/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6716 - val_accuracy: 0.6088 - 871ms/epoch - 13ms/step\n",
      "Epoch 951/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 805ms/epoch - 12ms/step\n",
      "Epoch 952/1000\n",
      "69/69 - 1s - loss: 0.6504 - accuracy: 0.6444 - val_loss: 0.6780 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 953/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6751 - val_accuracy: 0.6088 - 634ms/epoch - 9ms/step\n",
      "Epoch 954/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 622ms/epoch - 9ms/step\n",
      "Epoch 955/1000\n",
      "69/69 - 1s - loss: 0.6519 - accuracy: 0.6444 - val_loss: 0.6816 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 956/1000\n",
      "69/69 - 1s - loss: 0.6536 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 628ms/epoch - 9ms/step\n",
      "Epoch 957/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 603ms/epoch - 9ms/step\n",
      "Epoch 958/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6698 - val_accuracy: 0.6088 - 783ms/epoch - 11ms/step\n",
      "Epoch 959/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6778 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 960/1000\n",
      "69/69 - 1s - loss: 0.6526 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 893ms/epoch - 13ms/step\n",
      "Epoch 961/1000\n",
      "69/69 - 1s - loss: 0.6520 - accuracy: 0.6444 - val_loss: 0.6706 - val_accuracy: 0.6088 - 898ms/epoch - 13ms/step\n",
      "Epoch 962/1000\n",
      "69/69 - 1s - loss: 0.6537 - accuracy: 0.6444 - val_loss: 0.6770 - val_accuracy: 0.6088 - 734ms/epoch - 11ms/step\n",
      "Epoch 963/1000\n",
      "69/69 - 1s - loss: 0.6549 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 648ms/epoch - 9ms/step\n",
      "Epoch 964/1000\n",
      "69/69 - 1s - loss: 0.6512 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 965/1000\n",
      "69/69 - 1s - loss: 0.6541 - accuracy: 0.6444 - val_loss: 0.6709 - val_accuracy: 0.6088 - 653ms/epoch - 9ms/step\n",
      "Epoch 966/1000\n",
      "69/69 - 1s - loss: 0.6517 - accuracy: 0.6444 - val_loss: 0.6697 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 967/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6761 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 968/1000\n",
      "69/69 - 1s - loss: 0.6529 - accuracy: 0.6444 - val_loss: 0.6744 - val_accuracy: 0.6088 - 639ms/epoch - 9ms/step\n",
      "Epoch 969/1000\n",
      "69/69 - 1s - loss: 0.6547 - accuracy: 0.6444 - val_loss: 0.6782 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 970/1000\n",
      "69/69 - 1s - loss: 0.6552 - accuracy: 0.6444 - val_loss: 0.6772 - val_accuracy: 0.6088 - 895ms/epoch - 13ms/step\n",
      "Epoch 971/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6753 - val_accuracy: 0.6088 - 894ms/epoch - 13ms/step\n",
      "Epoch 972/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6758 - val_accuracy: 0.6088 - 889ms/epoch - 13ms/step\n",
      "Epoch 973/1000\n",
      "69/69 - 1s - loss: 0.6525 - accuracy: 0.6444 - val_loss: 0.6815 - val_accuracy: 0.6088 - 642ms/epoch - 9ms/step\n",
      "Epoch 974/1000\n",
      "69/69 - 1s - loss: 0.6528 - accuracy: 0.6444 - val_loss: 0.6732 - val_accuracy: 0.6088 - 594ms/epoch - 9ms/step\n",
      "Epoch 975/1000\n",
      "69/69 - 1s - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6728 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 976/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6720 - val_accuracy: 0.6088 - 633ms/epoch - 9ms/step\n",
      "Epoch 977/1000\n",
      "69/69 - 1s - loss: 0.6542 - accuracy: 0.6444 - val_loss: 0.6702 - val_accuracy: 0.6088 - 655ms/epoch - 9ms/step\n",
      "Epoch 978/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6778 - val_accuracy: 0.6088 - 623ms/epoch - 9ms/step\n",
      "Epoch 979/1000\n",
      "69/69 - 1s - loss: 0.6540 - accuracy: 0.6444 - val_loss: 0.6780 - val_accuracy: 0.6088 - 797ms/epoch - 12ms/step\n",
      "Epoch 980/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6721 - val_accuracy: 0.6088 - 874ms/epoch - 13ms/step\n",
      "Epoch 981/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6705 - val_accuracy: 0.6088 - 885ms/epoch - 13ms/step\n",
      "Epoch 982/1000\n",
      "69/69 - 1s - loss: 0.6534 - accuracy: 0.6444 - val_loss: 0.6725 - val_accuracy: 0.6088 - 871ms/epoch - 13ms/step\n",
      "Epoch 983/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6694 - val_accuracy: 0.6088 - 750ms/epoch - 11ms/step\n",
      "Epoch 984/1000\n",
      "69/69 - 1s - loss: 0.6564 - accuracy: 0.6444 - val_loss: 0.6730 - val_accuracy: 0.6088 - 616ms/epoch - 9ms/step\n",
      "Epoch 985/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6742 - val_accuracy: 0.6088 - 630ms/epoch - 9ms/step\n",
      "Epoch 986/1000\n",
      "69/69 - 1s - loss: 0.6518 - accuracy: 0.6444 - val_loss: 0.6717 - val_accuracy: 0.6088 - 612ms/epoch - 9ms/step\n",
      "Epoch 987/1000\n",
      "69/69 - 1s - loss: 0.6545 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 601ms/epoch - 9ms/step\n",
      "Epoch 988/1000\n",
      "69/69 - 1s - loss: 0.6524 - accuracy: 0.6444 - val_loss: 0.6779 - val_accuracy: 0.6088 - 624ms/epoch - 9ms/step\n",
      "Epoch 989/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 704ms/epoch - 10ms/step\n",
      "Epoch 990/1000\n",
      "69/69 - 1s - loss: 0.6527 - accuracy: 0.6444 - val_loss: 0.6753 - val_accuracy: 0.6088 - 897ms/epoch - 13ms/step\n",
      "Epoch 991/1000\n",
      "69/69 - 1s - loss: 0.6563 - accuracy: 0.6444 - val_loss: 0.6812 - val_accuracy: 0.6088 - 880ms/epoch - 13ms/step\n",
      "Epoch 992/1000\n",
      "69/69 - 1s - loss: 0.6514 - accuracy: 0.6444 - val_loss: 0.6704 - val_accuracy: 0.6088 - 888ms/epoch - 13ms/step\n",
      "Epoch 993/1000\n",
      "69/69 - 1s - loss: 0.6521 - accuracy: 0.6444 - val_loss: 0.6693 - val_accuracy: 0.6088 - 848ms/epoch - 12ms/step\n",
      "Epoch 994/1000\n",
      "69/69 - 1s - loss: 0.6543 - accuracy: 0.6444 - val_loss: 0.6699 - val_accuracy: 0.6088 - 583ms/epoch - 8ms/step\n",
      "Epoch 995/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6707 - val_accuracy: 0.6088 - 597ms/epoch - 9ms/step\n",
      "Epoch 996/1000\n",
      "69/69 - 1s - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.6714 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 997/1000\n",
      "69/69 - 1s - loss: 0.6516 - accuracy: 0.6444 - val_loss: 0.6736 - val_accuracy: 0.6088 - 618ms/epoch - 9ms/step\n",
      "Epoch 998/1000\n",
      "69/69 - 1s - loss: 0.6522 - accuracy: 0.6444 - val_loss: 0.6755 - val_accuracy: 0.6088 - 607ms/epoch - 9ms/step\n",
      "Epoch 999/1000\n",
      "69/69 - 1s - loss: 0.6530 - accuracy: 0.6444 - val_loss: 0.6703 - val_accuracy: 0.6088 - 611ms/epoch - 9ms/step\n",
      "Epoch 1000/1000\n",
      "69/69 - 1s - loss: 0.6532 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.6088 - 866ms/epoch - 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x173549e1340>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0.1):\n",
    "    # Multi-Head Attention layer\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
    "    attention_output = Dropout(dropout)(attention_output)\n",
    "    attention_output = Add()([attention_output, inputs])\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "\n",
    "    # Feed Forward Network\n",
    "    ff_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    return Add()([ff_output, attention_output])\n",
    "\n",
    "# Build the model\n",
    "inputs = Input(shape=(18, 1))\n",
    "x = transformer_block(inputs, head_size=64, num_heads=4, ff_dim=64, dropout=0.1)\n",
    "x = transformer_block(x, head_size=64, num_heads=4, ff_dim=64, dropout=0.1)\n",
    "\n",
    "# Flatten and Dense layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer (binary classification)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=32, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000       255\n",
      "           1   0.627193  1.000000  0.770889       429\n",
      "\n",
      "    accuracy                       0.627193       684\n",
      "   macro avg   0.313596  0.500000  0.385445       684\n",
      "weighted avg   0.393371  0.627193  0.483496       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "res.round()\n",
    "actual = []\n",
    "for num in res:\n",
    "    if num>0.5:\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,actual,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x173573ed640>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "confusionmatrix = confusion_matrix(Y_test, actual)\n",
    "cm_display = ConfusionMatrixDisplay(confusionmatrix, display_labels=[0,1])\n",
    "cm_display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
