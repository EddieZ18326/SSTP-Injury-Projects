{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0      3   2   2  25   0   3  10   0   0   0   0   0   0   0   0   0   1   1\n",
      "1      3   3   1  61   0   3  10   0   0   0   0   0   0   0   0   0   7   1\n",
      "2      3   3   1  65   0   3  10   0   0   0   0   0   0   0   0   0   6   1\n",
      "3      3   2   1  49   0   3  10   0   0   0   1   0   0   0   0   0   5   1\n",
      "4      3   1   1  54   0   5   2   1   1   0   0   0   0   0   0   1   5   1\n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "3414   1   2   1  57   0   6   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3415   1   1   1  24   0   3   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3416   1   1   1  50   0   3  10   0   0   0   0   0   0   0   0   0   6   4\n",
      "3417   1   2   1  58   0   3   9   0   0   0   0   0   0   0   0   0   6   4\n",
      "3418   1   2   1   3   0   4  10   0   0   0   0   0   0   0   0   0   5   4\n",
      "\n",
      "[3419 rows x 18 columns]\n",
      "      0\n",
      "0     0\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "...  ..\n",
      "3414  1\n",
      "3415  1\n",
      "3416  1\n",
      "3417  0\n",
      "3418  1\n",
      "\n",
      "[3419 rows x 1 columns]\n",
      "(2735, 18)\n",
      "(2735, 1)\n",
      "(684, 18)\n",
      "Index(['Location of Incident', 'Time', 'Sex', 'Age', 'Intentional', 'Role',\n",
      "       'Injury Agent', 'Confined Space', 'Grain Involved', 'Alcohol/Drugs',\n",
      "       'Seatbelt', 'Helmet', 'ROPS', 'Agritourism', 'Other PPE',\n",
      "       'Drowning/Suffocation', 'Day', 'Season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('/Users/eddie/Downloads/Log In - AgInjuryNews (1).xlsx - Sheet1 (1) - Log In - AgInjuryNews (1).xlsx - Sheet1 (1).csv')\n",
    "\n",
    "X = pd.DataFrame(dataset.iloc[:,:18].values)\n",
    "Y = pd.DataFrame(dataset.iloc[:,18:].values)\n",
    "print(X)\n",
    "print(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=0)\n",
    "X_train, X_train_val, Y_train, Y_train_val = train_test_split(X,Y,test_size=0.2)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.reshape(2735,18,1)\n",
    "X_test.reshape(684,18,1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "features = pd.DataFrame(dataset.iloc[:,:18])\n",
    "features = features.columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, SimpleRNN, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=96, max_value=256, step=16)\n",
    "  model.add(SimpleRNN(hp_units, input_shape=(18, 1), return_sequences=True))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Second SimpleRNN layer\n",
    "  hp_units2 = hp.Int('units2', min_value=16, max_value=96, step=8)\n",
    "  model.add(SimpleRNN(hp_units2, return_sequences=True))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Third SimpleRNN layer\n",
    "  model.add(SimpleRNN(hp_units2, return_sequences=False))  # This will output a single vector for the next layer\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Dense layer with more units\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4,1e-5,1e-6])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape = (18,)))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from rnn_bayes_opt\\rnn_bayes_opt\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     directory='rnn_bayes_opt',\n",
    "                     project_name='rnn_bayes_opt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 96 and the optimal learning rate for the optimizer\n",
      "is 1e-06.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(X_train, Y_train, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.8118 - accuracy: 0.5288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 15s 50ms/step - loss: 0.8118 - accuracy: 0.5288 - val_loss: 0.6712 - val_accuracy: 0.6271\n",
      "Epoch 2/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8256 - accuracy: 0.5315 - val_loss: 0.6712 - val_accuracy: 0.6271\n",
      "Epoch 3/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8107 - accuracy: 0.5324 - val_loss: 0.6714 - val_accuracy: 0.6271\n",
      "Epoch 4/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7925 - accuracy: 0.5398 - val_loss: 0.6714 - val_accuracy: 0.6271\n",
      "Epoch 5/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8175 - accuracy: 0.5370 - val_loss: 0.6715 - val_accuracy: 0.6271\n",
      "Epoch 6/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7911 - accuracy: 0.5553 - val_loss: 0.6715 - val_accuracy: 0.6271\n",
      "Epoch 7/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8217 - accuracy: 0.5306 - val_loss: 0.6715 - val_accuracy: 0.6271\n",
      "Epoch 8/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7991 - accuracy: 0.5302 - val_loss: 0.6718 - val_accuracy: 0.6271\n",
      "Epoch 9/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7903 - accuracy: 0.5462 - val_loss: 0.6718 - val_accuracy: 0.6271\n",
      "Epoch 10/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7909 - accuracy: 0.5507 - val_loss: 0.6719 - val_accuracy: 0.6289\n",
      "Epoch 11/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7933 - accuracy: 0.5347 - val_loss: 0.6720 - val_accuracy: 0.6289\n",
      "Epoch 12/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.8087 - accuracy: 0.5320 - val_loss: 0.6721 - val_accuracy: 0.6289\n",
      "Epoch 13/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8127 - accuracy: 0.5352 - val_loss: 0.6721 - val_accuracy: 0.6289\n",
      "Epoch 14/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8005 - accuracy: 0.5370 - val_loss: 0.6722 - val_accuracy: 0.6289\n",
      "Epoch 15/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.8156 - accuracy: 0.5210 - val_loss: 0.6725 - val_accuracy: 0.6289\n",
      "Epoch 16/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8117 - accuracy: 0.5283 - val_loss: 0.6726 - val_accuracy: 0.6289\n",
      "Epoch 17/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.8061 - accuracy: 0.5338 - val_loss: 0.6727 - val_accuracy: 0.6289\n",
      "Epoch 18/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7812 - accuracy: 0.5562 - val_loss: 0.6727 - val_accuracy: 0.6289\n",
      "Epoch 19/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8207 - accuracy: 0.5219 - val_loss: 0.6730 - val_accuracy: 0.6289\n",
      "Epoch 20/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7863 - accuracy: 0.5457 - val_loss: 0.6731 - val_accuracy: 0.6289\n",
      "Epoch 21/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7959 - accuracy: 0.5558 - val_loss: 0.6732 - val_accuracy: 0.6289\n",
      "Epoch 22/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8015 - accuracy: 0.5416 - val_loss: 0.6731 - val_accuracy: 0.6289\n",
      "Epoch 23/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8071 - accuracy: 0.5283 - val_loss: 0.6732 - val_accuracy: 0.6289\n",
      "Epoch 24/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7740 - accuracy: 0.5503 - val_loss: 0.6733 - val_accuracy: 0.6307\n",
      "Epoch 25/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8083 - accuracy: 0.5320 - val_loss: 0.6732 - val_accuracy: 0.6307\n",
      "Epoch 26/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7884 - accuracy: 0.5439 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 27/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7873 - accuracy: 0.5494 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 28/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8028 - accuracy: 0.5370 - val_loss: 0.6733 - val_accuracy: 0.6307\n",
      "Epoch 29/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.8193 - accuracy: 0.5306 - val_loss: 0.6735 - val_accuracy: 0.6307\n",
      "Epoch 30/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7935 - accuracy: 0.5411 - val_loss: 0.6735 - val_accuracy: 0.6307\n",
      "Epoch 31/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7945 - accuracy: 0.5356 - val_loss: 0.6735 - val_accuracy: 0.6307\n",
      "Epoch 32/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7968 - accuracy: 0.5297 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 33/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.8145 - accuracy: 0.5283 - val_loss: 0.6733 - val_accuracy: 0.6307\n",
      "Epoch 34/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7989 - accuracy: 0.5443 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 35/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7886 - accuracy: 0.5398 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 36/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7834 - accuracy: 0.5384 - val_loss: 0.6736 - val_accuracy: 0.6307\n",
      "Epoch 37/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.8083 - accuracy: 0.5516 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 38/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.8136 - accuracy: 0.5274 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 39/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7820 - accuracy: 0.5370 - val_loss: 0.6735 - val_accuracy: 0.6307\n",
      "Epoch 40/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.8016 - accuracy: 0.5516 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 41/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8007 - accuracy: 0.5452 - val_loss: 0.6736 - val_accuracy: 0.6307\n",
      "Epoch 42/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7901 - accuracy: 0.5398 - val_loss: 0.6739 - val_accuracy: 0.6307\n",
      "Epoch 43/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8059 - accuracy: 0.5356 - val_loss: 0.6739 - val_accuracy: 0.6307\n",
      "Epoch 44/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8095 - accuracy: 0.5302 - val_loss: 0.6741 - val_accuracy: 0.6307\n",
      "Epoch 45/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8010 - accuracy: 0.5238 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 46/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7822 - accuracy: 0.5548 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 47/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7877 - accuracy: 0.5388 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 48/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7733 - accuracy: 0.5608 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 49/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8088 - accuracy: 0.5274 - val_loss: 0.6743 - val_accuracy: 0.6307\n",
      "Epoch 50/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7792 - accuracy: 0.5644 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 51/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7873 - accuracy: 0.5558 - val_loss: 0.6744 - val_accuracy: 0.6307\n",
      "Epoch 52/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7870 - accuracy: 0.5416 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 53/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.8081 - accuracy: 0.5297 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 54/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7727 - accuracy: 0.5471 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 55/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.8012 - accuracy: 0.5356 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 56/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8019 - accuracy: 0.5512 - val_loss: 0.6739 - val_accuracy: 0.6307\n",
      "Epoch 57/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7916 - accuracy: 0.5425 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 58/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8259 - accuracy: 0.5247 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 59/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7788 - accuracy: 0.5512 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 60/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7890 - accuracy: 0.5425 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 61/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7947 - accuracy: 0.5530 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 62/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7973 - accuracy: 0.5448 - val_loss: 0.6741 - val_accuracy: 0.6307\n",
      "Epoch 63/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7883 - accuracy: 0.5503 - val_loss: 0.6741 - val_accuracy: 0.6307\n",
      "Epoch 64/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7926 - accuracy: 0.5366 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 65/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.8117 - accuracy: 0.5338 - val_loss: 0.6744 - val_accuracy: 0.6307\n",
      "Epoch 66/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7932 - accuracy: 0.5439 - val_loss: 0.6743 - val_accuracy: 0.6307\n",
      "Epoch 67/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7935 - accuracy: 0.5462 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 68/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.8019 - accuracy: 0.5297 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 69/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7815 - accuracy: 0.5402 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 70/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7793 - accuracy: 0.5553 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 71/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7800 - accuracy: 0.5315 - val_loss: 0.6741 - val_accuracy: 0.6307\n",
      "Epoch 72/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7835 - accuracy: 0.5471 - val_loss: 0.6741 - val_accuracy: 0.6307\n",
      "Epoch 73/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7712 - accuracy: 0.5448 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 74/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7810 - accuracy: 0.5457 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 75/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7744 - accuracy: 0.5471 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 76/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7961 - accuracy: 0.5338 - val_loss: 0.6741 - val_accuracy: 0.6307\n",
      "Epoch 77/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7757 - accuracy: 0.5631 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 78/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7787 - accuracy: 0.5480 - val_loss: 0.6742 - val_accuracy: 0.6307\n",
      "Epoch 79/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7916 - accuracy: 0.5512 - val_loss: 0.6741 - val_accuracy: 0.6307\n",
      "Epoch 80/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7693 - accuracy: 0.5603 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 81/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7800 - accuracy: 0.5603 - val_loss: 0.6740 - val_accuracy: 0.6307\n",
      "Epoch 82/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7713 - accuracy: 0.5539 - val_loss: 0.6738 - val_accuracy: 0.6307\n",
      "Epoch 83/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7773 - accuracy: 0.5471 - val_loss: 0.6739 - val_accuracy: 0.6307\n",
      "Epoch 84/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7782 - accuracy: 0.5411 - val_loss: 0.6738 - val_accuracy: 0.6307\n",
      "Epoch 85/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7884 - accuracy: 0.5434 - val_loss: 0.6738 - val_accuracy: 0.6307\n",
      "Epoch 86/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7938 - accuracy: 0.5457 - val_loss: 0.6738 - val_accuracy: 0.6307\n",
      "Epoch 87/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7779 - accuracy: 0.5475 - val_loss: 0.6738 - val_accuracy: 0.6307\n",
      "Epoch 88/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7824 - accuracy: 0.5516 - val_loss: 0.6736 - val_accuracy: 0.6307\n",
      "Epoch 89/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7875 - accuracy: 0.5361 - val_loss: 0.6736 - val_accuracy: 0.6307\n",
      "Epoch 90/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7781 - accuracy: 0.5512 - val_loss: 0.6735 - val_accuracy: 0.6307\n",
      "Epoch 91/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7832 - accuracy: 0.5548 - val_loss: 0.6735 - val_accuracy: 0.6307\n",
      "Epoch 92/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7899 - accuracy: 0.5448 - val_loss: 0.6733 - val_accuracy: 0.6307\n",
      "Epoch 93/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7861 - accuracy: 0.5503 - val_loss: 0.6733 - val_accuracy: 0.6307\n",
      "Epoch 94/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7688 - accuracy: 0.5503 - val_loss: 0.6732 - val_accuracy: 0.6307\n",
      "Epoch 95/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7779 - accuracy: 0.5484 - val_loss: 0.6733 - val_accuracy: 0.6307\n",
      "Epoch 96/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7573 - accuracy: 0.5622 - val_loss: 0.6733 - val_accuracy: 0.6307\n",
      "Epoch 97/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7780 - accuracy: 0.5457 - val_loss: 0.6734 - val_accuracy: 0.6307\n",
      "Epoch 98/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7774 - accuracy: 0.5526 - val_loss: 0.6732 - val_accuracy: 0.6307\n",
      "Epoch 99/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7625 - accuracy: 0.5398 - val_loss: 0.6732 - val_accuracy: 0.6307\n",
      "Epoch 100/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7883 - accuracy: 0.5494 - val_loss: 0.6732 - val_accuracy: 0.6307\n",
      "Epoch 101/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7622 - accuracy: 0.5539 - val_loss: 0.6731 - val_accuracy: 0.6307\n",
      "Epoch 102/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7774 - accuracy: 0.5631 - val_loss: 0.6731 - val_accuracy: 0.6307\n",
      "Epoch 103/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7859 - accuracy: 0.5494 - val_loss: 0.6731 - val_accuracy: 0.6307\n",
      "Epoch 104/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7701 - accuracy: 0.5484 - val_loss: 0.6730 - val_accuracy: 0.6307\n",
      "Epoch 105/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7712 - accuracy: 0.5594 - val_loss: 0.6729 - val_accuracy: 0.6307\n",
      "Epoch 106/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7949 - accuracy: 0.5361 - val_loss: 0.6728 - val_accuracy: 0.6307\n",
      "Epoch 107/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7753 - accuracy: 0.5553 - val_loss: 0.6726 - val_accuracy: 0.6307\n",
      "Epoch 108/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7939 - accuracy: 0.5462 - val_loss: 0.6723 - val_accuracy: 0.6307\n",
      "Epoch 109/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.8015 - accuracy: 0.5366 - val_loss: 0.6723 - val_accuracy: 0.6307\n",
      "Epoch 110/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7792 - accuracy: 0.5443 - val_loss: 0.6723 - val_accuracy: 0.6307\n",
      "Epoch 111/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7741 - accuracy: 0.5530 - val_loss: 0.6723 - val_accuracy: 0.6307\n",
      "Epoch 112/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7762 - accuracy: 0.5462 - val_loss: 0.6721 - val_accuracy: 0.6307\n",
      "Epoch 113/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7696 - accuracy: 0.5590 - val_loss: 0.6720 - val_accuracy: 0.6307\n",
      "Epoch 114/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7862 - accuracy: 0.5603 - val_loss: 0.6720 - val_accuracy: 0.6325\n",
      "Epoch 115/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7680 - accuracy: 0.5452 - val_loss: 0.6721 - val_accuracy: 0.6325\n",
      "Epoch 116/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7767 - accuracy: 0.5475 - val_loss: 0.6720 - val_accuracy: 0.6325\n",
      "Epoch 117/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7794 - accuracy: 0.5297 - val_loss: 0.6719 - val_accuracy: 0.6325\n",
      "Epoch 118/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7585 - accuracy: 0.5507 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 119/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7485 - accuracy: 0.5708 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 120/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7616 - accuracy: 0.5594 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 121/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7652 - accuracy: 0.5608 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 122/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7849 - accuracy: 0.5544 - val_loss: 0.6717 - val_accuracy: 0.6325\n",
      "Epoch 123/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7567 - accuracy: 0.5594 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 124/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7590 - accuracy: 0.5562 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 125/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7634 - accuracy: 0.5489 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 126/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7674 - accuracy: 0.5585 - val_loss: 0.6716 - val_accuracy: 0.6325\n",
      "Epoch 127/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7574 - accuracy: 0.5640 - val_loss: 0.6718 - val_accuracy: 0.6325\n",
      "Epoch 128/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7810 - accuracy: 0.5443 - val_loss: 0.6716 - val_accuracy: 0.6325\n",
      "Epoch 129/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7451 - accuracy: 0.5750 - val_loss: 0.6715 - val_accuracy: 0.6325\n",
      "Epoch 130/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7582 - accuracy: 0.5553 - val_loss: 0.6713 - val_accuracy: 0.6325\n",
      "Epoch 131/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7583 - accuracy: 0.5663 - val_loss: 0.6713 - val_accuracy: 0.6325\n",
      "Epoch 132/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7700 - accuracy: 0.5494 - val_loss: 0.6714 - val_accuracy: 0.6325\n",
      "Epoch 133/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7591 - accuracy: 0.5635 - val_loss: 0.6713 - val_accuracy: 0.6325\n",
      "Epoch 134/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7723 - accuracy: 0.5544 - val_loss: 0.6713 - val_accuracy: 0.6325\n",
      "Epoch 135/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7501 - accuracy: 0.5713 - val_loss: 0.6713 - val_accuracy: 0.6325\n",
      "Epoch 136/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7673 - accuracy: 0.5448 - val_loss: 0.6713 - val_accuracy: 0.6325\n",
      "Epoch 137/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7791 - accuracy: 0.5521 - val_loss: 0.6711 - val_accuracy: 0.6325\n",
      "Epoch 138/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7737 - accuracy: 0.5558 - val_loss: 0.6710 - val_accuracy: 0.6307\n",
      "Epoch 139/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7691 - accuracy: 0.5558 - val_loss: 0.6709 - val_accuracy: 0.6307\n",
      "Epoch 140/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7631 - accuracy: 0.5530 - val_loss: 0.6708 - val_accuracy: 0.6307\n",
      "Epoch 141/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7414 - accuracy: 0.5754 - val_loss: 0.6707 - val_accuracy: 0.6307\n",
      "Epoch 142/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7578 - accuracy: 0.5626 - val_loss: 0.6707 - val_accuracy: 0.6289\n",
      "Epoch 143/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7617 - accuracy: 0.5635 - val_loss: 0.6706 - val_accuracy: 0.6289\n",
      "Epoch 144/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7461 - accuracy: 0.5644 - val_loss: 0.6706 - val_accuracy: 0.6289\n",
      "Epoch 145/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7656 - accuracy: 0.5576 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 146/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7439 - accuracy: 0.5672 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 147/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7583 - accuracy: 0.5617 - val_loss: 0.6703 - val_accuracy: 0.6289\n",
      "Epoch 148/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7598 - accuracy: 0.5635 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 149/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7516 - accuracy: 0.5676 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 150/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7575 - accuracy: 0.5571 - val_loss: 0.6705 - val_accuracy: 0.6289\n",
      "Epoch 151/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7611 - accuracy: 0.5567 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 152/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7874 - accuracy: 0.5334 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 153/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7659 - accuracy: 0.5562 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 154/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7568 - accuracy: 0.5622 - val_loss: 0.6704 - val_accuracy: 0.6289\n",
      "Epoch 155/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7740 - accuracy: 0.5516 - val_loss: 0.6703 - val_accuracy: 0.6289\n",
      "Epoch 156/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7456 - accuracy: 0.5745 - val_loss: 0.6701 - val_accuracy: 0.6289\n",
      "Epoch 157/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7640 - accuracy: 0.5548 - val_loss: 0.6702 - val_accuracy: 0.6307\n",
      "Epoch 158/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7674 - accuracy: 0.5562 - val_loss: 0.6703 - val_accuracy: 0.6307\n",
      "Epoch 159/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7576 - accuracy: 0.5498 - val_loss: 0.6704 - val_accuracy: 0.6307\n",
      "Epoch 160/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7647 - accuracy: 0.5585 - val_loss: 0.6703 - val_accuracy: 0.6307\n",
      "Epoch 161/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7752 - accuracy: 0.5512 - val_loss: 0.6702 - val_accuracy: 0.6307\n",
      "Epoch 162/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7678 - accuracy: 0.5567 - val_loss: 0.6703 - val_accuracy: 0.6307\n",
      "Epoch 163/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7540 - accuracy: 0.5571 - val_loss: 0.6703 - val_accuracy: 0.6307\n",
      "Epoch 164/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7464 - accuracy: 0.5759 - val_loss: 0.6703 - val_accuracy: 0.6307\n",
      "Epoch 165/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7735 - accuracy: 0.5521 - val_loss: 0.6702 - val_accuracy: 0.6307\n",
      "Epoch 166/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7523 - accuracy: 0.5535 - val_loss: 0.6702 - val_accuracy: 0.6307\n",
      "Epoch 167/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7646 - accuracy: 0.5530 - val_loss: 0.6701 - val_accuracy: 0.6325\n",
      "Epoch 168/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7556 - accuracy: 0.5507 - val_loss: 0.6700 - val_accuracy: 0.6325\n",
      "Epoch 169/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.7634 - accuracy: 0.5558 - val_loss: 0.6699 - val_accuracy: 0.6325\n",
      "Epoch 170/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7547 - accuracy: 0.5558 - val_loss: 0.6699 - val_accuracy: 0.6325\n",
      "Epoch 171/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7712 - accuracy: 0.5489 - val_loss: 0.6697 - val_accuracy: 0.6325\n",
      "Epoch 172/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7718 - accuracy: 0.5448 - val_loss: 0.6697 - val_accuracy: 0.6325\n",
      "Epoch 173/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7761 - accuracy: 0.5388 - val_loss: 0.6697 - val_accuracy: 0.6325\n",
      "Epoch 174/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7555 - accuracy: 0.5590 - val_loss: 0.6695 - val_accuracy: 0.6325\n",
      "Epoch 175/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7619 - accuracy: 0.5530 - val_loss: 0.6693 - val_accuracy: 0.6307\n",
      "Epoch 176/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7713 - accuracy: 0.5498 - val_loss: 0.6694 - val_accuracy: 0.6307\n",
      "Epoch 177/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7597 - accuracy: 0.5631 - val_loss: 0.6693 - val_accuracy: 0.6307\n",
      "Epoch 178/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7636 - accuracy: 0.5603 - val_loss: 0.6693 - val_accuracy: 0.6325\n",
      "Epoch 179/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7688 - accuracy: 0.5580 - val_loss: 0.6693 - val_accuracy: 0.6325\n",
      "Epoch 180/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7649 - accuracy: 0.5498 - val_loss: 0.6693 - val_accuracy: 0.6325\n",
      "Epoch 181/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7549 - accuracy: 0.5494 - val_loss: 0.6693 - val_accuracy: 0.6325\n",
      "Epoch 182/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7399 - accuracy: 0.5731 - val_loss: 0.6691 - val_accuracy: 0.6325\n",
      "Epoch 183/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7720 - accuracy: 0.5603 - val_loss: 0.6692 - val_accuracy: 0.6325\n",
      "Epoch 184/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7518 - accuracy: 0.5599 - val_loss: 0.6691 - val_accuracy: 0.6325\n",
      "Epoch 185/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7625 - accuracy: 0.5585 - val_loss: 0.6691 - val_accuracy: 0.6325\n",
      "Epoch 186/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7755 - accuracy: 0.5507 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 187/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7699 - accuracy: 0.5658 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 188/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7406 - accuracy: 0.5590 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 189/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7480 - accuracy: 0.5535 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 190/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7522 - accuracy: 0.5608 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 191/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7607 - accuracy: 0.5448 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 192/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7699 - accuracy: 0.5324 - val_loss: 0.6691 - val_accuracy: 0.6325\n",
      "Epoch 193/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7673 - accuracy: 0.5516 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 194/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7577 - accuracy: 0.5603 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 195/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7699 - accuracy: 0.5503 - val_loss: 0.6690 - val_accuracy: 0.6325\n",
      "Epoch 196/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7552 - accuracy: 0.5576 - val_loss: 0.6689 - val_accuracy: 0.6325\n",
      "Epoch 197/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7500 - accuracy: 0.5658 - val_loss: 0.6689 - val_accuracy: 0.6307\n",
      "Epoch 198/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7789 - accuracy: 0.5430 - val_loss: 0.6688 - val_accuracy: 0.6289\n",
      "Epoch 199/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7673 - accuracy: 0.5576 - val_loss: 0.6687 - val_accuracy: 0.6289\n",
      "Epoch 200/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7505 - accuracy: 0.5663 - val_loss: 0.6688 - val_accuracy: 0.6289\n",
      "Epoch 201/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7608 - accuracy: 0.5590 - val_loss: 0.6688 - val_accuracy: 0.6289\n",
      "Epoch 202/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7520 - accuracy: 0.5676 - val_loss: 0.6686 - val_accuracy: 0.6289\n",
      "Epoch 203/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7436 - accuracy: 0.5686 - val_loss: 0.6685 - val_accuracy: 0.6289\n",
      "Epoch 204/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7519 - accuracy: 0.5580 - val_loss: 0.6685 - val_accuracy: 0.6271\n",
      "Epoch 205/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7571 - accuracy: 0.5649 - val_loss: 0.6684 - val_accuracy: 0.6252\n",
      "Epoch 206/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7565 - accuracy: 0.5576 - val_loss: 0.6684 - val_accuracy: 0.6252\n",
      "Epoch 207/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7656 - accuracy: 0.5375 - val_loss: 0.6682 - val_accuracy: 0.6252\n",
      "Epoch 208/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7701 - accuracy: 0.5471 - val_loss: 0.6683 - val_accuracy: 0.6252\n",
      "Epoch 209/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7607 - accuracy: 0.5548 - val_loss: 0.6682 - val_accuracy: 0.6252\n",
      "Epoch 210/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7426 - accuracy: 0.5631 - val_loss: 0.6681 - val_accuracy: 0.6234\n",
      "Epoch 211/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7464 - accuracy: 0.5658 - val_loss: 0.6681 - val_accuracy: 0.6234\n",
      "Epoch 212/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7565 - accuracy: 0.5494 - val_loss: 0.6681 - val_accuracy: 0.6216\n",
      "Epoch 213/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7463 - accuracy: 0.5617 - val_loss: 0.6681 - val_accuracy: 0.6179\n",
      "Epoch 214/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7528 - accuracy: 0.5658 - val_loss: 0.6681 - val_accuracy: 0.6179\n",
      "Epoch 215/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7614 - accuracy: 0.5521 - val_loss: 0.6681 - val_accuracy: 0.6179\n",
      "Epoch 216/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7426 - accuracy: 0.5708 - val_loss: 0.6680 - val_accuracy: 0.6179\n",
      "Epoch 217/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7516 - accuracy: 0.5644 - val_loss: 0.6680 - val_accuracy: 0.6179\n",
      "Epoch 218/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7478 - accuracy: 0.5736 - val_loss: 0.6679 - val_accuracy: 0.6161\n",
      "Epoch 219/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7501 - accuracy: 0.5603 - val_loss: 0.6678 - val_accuracy: 0.6161\n",
      "Epoch 220/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7616 - accuracy: 0.5654 - val_loss: 0.6678 - val_accuracy: 0.6161\n",
      "Epoch 221/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7491 - accuracy: 0.5672 - val_loss: 0.6676 - val_accuracy: 0.6179\n",
      "Epoch 222/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.7399 - accuracy: 0.5750 - val_loss: 0.6676 - val_accuracy: 0.6179\n",
      "Epoch 223/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7521 - accuracy: 0.5686 - val_loss: 0.6676 - val_accuracy: 0.6179\n",
      "Epoch 224/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7562 - accuracy: 0.5489 - val_loss: 0.6676 - val_accuracy: 0.6179\n",
      "Epoch 225/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7664 - accuracy: 0.5530 - val_loss: 0.6675 - val_accuracy: 0.6161\n",
      "Epoch 226/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7668 - accuracy: 0.5484 - val_loss: 0.6674 - val_accuracy: 0.6161\n",
      "Epoch 227/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7634 - accuracy: 0.5475 - val_loss: 0.6673 - val_accuracy: 0.6179\n",
      "Epoch 228/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7468 - accuracy: 0.5594 - val_loss: 0.6672 - val_accuracy: 0.6179\n",
      "Epoch 229/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7412 - accuracy: 0.5681 - val_loss: 0.6672 - val_accuracy: 0.6179\n",
      "Epoch 230/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7453 - accuracy: 0.5859 - val_loss: 0.6671 - val_accuracy: 0.6161\n",
      "Epoch 231/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7741 - accuracy: 0.5393 - val_loss: 0.6670 - val_accuracy: 0.6161\n",
      "Epoch 232/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7508 - accuracy: 0.5548 - val_loss: 0.6670 - val_accuracy: 0.6161\n",
      "Epoch 233/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7573 - accuracy: 0.5590 - val_loss: 0.6669 - val_accuracy: 0.6161\n",
      "Epoch 234/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7304 - accuracy: 0.5795 - val_loss: 0.6669 - val_accuracy: 0.6161\n",
      "Epoch 235/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7496 - accuracy: 0.5667 - val_loss: 0.6670 - val_accuracy: 0.6161\n",
      "Epoch 236/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7400 - accuracy: 0.5681 - val_loss: 0.6669 - val_accuracy: 0.6161\n",
      "Epoch 237/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7440 - accuracy: 0.5622 - val_loss: 0.6669 - val_accuracy: 0.6161\n",
      "Epoch 238/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7464 - accuracy: 0.5654 - val_loss: 0.6668 - val_accuracy: 0.6161\n",
      "Epoch 239/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7554 - accuracy: 0.5603 - val_loss: 0.6666 - val_accuracy: 0.6161\n",
      "Epoch 240/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7364 - accuracy: 0.5772 - val_loss: 0.6666 - val_accuracy: 0.6161\n",
      "Epoch 241/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7497 - accuracy: 0.5695 - val_loss: 0.6666 - val_accuracy: 0.6161\n",
      "Epoch 242/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7250 - accuracy: 0.5722 - val_loss: 0.6667 - val_accuracy: 0.6161\n",
      "Epoch 243/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7562 - accuracy: 0.5503 - val_loss: 0.6667 - val_accuracy: 0.6161\n",
      "Epoch 244/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7473 - accuracy: 0.5672 - val_loss: 0.6666 - val_accuracy: 0.6161\n",
      "Epoch 245/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7625 - accuracy: 0.5571 - val_loss: 0.6664 - val_accuracy: 0.6179\n",
      "Epoch 246/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7330 - accuracy: 0.5745 - val_loss: 0.6665 - val_accuracy: 0.6179\n",
      "Epoch 247/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7579 - accuracy: 0.5580 - val_loss: 0.6665 - val_accuracy: 0.6179\n",
      "Epoch 248/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7417 - accuracy: 0.5750 - val_loss: 0.6664 - val_accuracy: 0.6179\n",
      "Epoch 249/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7648 - accuracy: 0.5466 - val_loss: 0.6665 - val_accuracy: 0.6179\n",
      "Epoch 250/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7642 - accuracy: 0.5512 - val_loss: 0.6664 - val_accuracy: 0.6179\n",
      "Epoch 251/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7494 - accuracy: 0.5576 - val_loss: 0.6663 - val_accuracy: 0.6179\n",
      "Epoch 252/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7419 - accuracy: 0.5713 - val_loss: 0.6662 - val_accuracy: 0.6161\n",
      "Epoch 253/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7333 - accuracy: 0.5631 - val_loss: 0.6662 - val_accuracy: 0.6161\n",
      "Epoch 254/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7368 - accuracy: 0.5558 - val_loss: 0.6662 - val_accuracy: 0.6161\n",
      "Epoch 255/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7477 - accuracy: 0.5658 - val_loss: 0.6662 - val_accuracy: 0.6161\n",
      "Epoch 256/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7380 - accuracy: 0.5759 - val_loss: 0.6662 - val_accuracy: 0.6161\n",
      "Epoch 257/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7387 - accuracy: 0.5617 - val_loss: 0.6661 - val_accuracy: 0.6179\n",
      "Epoch 258/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7516 - accuracy: 0.5635 - val_loss: 0.6661 - val_accuracy: 0.6161\n",
      "Epoch 259/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7610 - accuracy: 0.5448 - val_loss: 0.6661 - val_accuracy: 0.6161\n",
      "Epoch 260/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7373 - accuracy: 0.5754 - val_loss: 0.6662 - val_accuracy: 0.6161\n",
      "Epoch 261/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7431 - accuracy: 0.5612 - val_loss: 0.6662 - val_accuracy: 0.6161\n",
      "Epoch 262/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7349 - accuracy: 0.5722 - val_loss: 0.6660 - val_accuracy: 0.6161\n",
      "Epoch 263/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7332 - accuracy: 0.5777 - val_loss: 0.6660 - val_accuracy: 0.6161\n",
      "Epoch 264/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7520 - accuracy: 0.5539 - val_loss: 0.6660 - val_accuracy: 0.6161\n",
      "Epoch 265/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7411 - accuracy: 0.5654 - val_loss: 0.6660 - val_accuracy: 0.6161\n",
      "Epoch 266/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7290 - accuracy: 0.5690 - val_loss: 0.6661 - val_accuracy: 0.6161\n",
      "Epoch 267/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7469 - accuracy: 0.5667 - val_loss: 0.6661 - val_accuracy: 0.6161\n",
      "Epoch 268/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7478 - accuracy: 0.5562 - val_loss: 0.6661 - val_accuracy: 0.6161\n",
      "Epoch 269/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7611 - accuracy: 0.5640 - val_loss: 0.6661 - val_accuracy: 0.6161\n",
      "Epoch 270/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7429 - accuracy: 0.5782 - val_loss: 0.6660 - val_accuracy: 0.6161\n",
      "Epoch 271/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7366 - accuracy: 0.5663 - val_loss: 0.6659 - val_accuracy: 0.6161\n",
      "Epoch 272/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7386 - accuracy: 0.5608 - val_loss: 0.6660 - val_accuracy: 0.6161\n",
      "Epoch 273/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7395 - accuracy: 0.5718 - val_loss: 0.6659 - val_accuracy: 0.6161\n",
      "Epoch 274/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7395 - accuracy: 0.5635 - val_loss: 0.6659 - val_accuracy: 0.6161\n",
      "Epoch 275/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7340 - accuracy: 0.5818 - val_loss: 0.6659 - val_accuracy: 0.6161\n",
      "Epoch 276/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7580 - accuracy: 0.5567 - val_loss: 0.6658 - val_accuracy: 0.6161\n",
      "Epoch 277/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7616 - accuracy: 0.5512 - val_loss: 0.6657 - val_accuracy: 0.6161\n",
      "Epoch 278/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7583 - accuracy: 0.5503 - val_loss: 0.6657 - val_accuracy: 0.6161\n",
      "Epoch 279/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7557 - accuracy: 0.5663 - val_loss: 0.6657 - val_accuracy: 0.6161\n",
      "Epoch 280/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7449 - accuracy: 0.5649 - val_loss: 0.6657 - val_accuracy: 0.6161\n",
      "Epoch 281/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7457 - accuracy: 0.5571 - val_loss: 0.6657 - val_accuracy: 0.6143\n",
      "Epoch 282/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7262 - accuracy: 0.5809 - val_loss: 0.6656 - val_accuracy: 0.6143\n",
      "Epoch 283/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7300 - accuracy: 0.5740 - val_loss: 0.6656 - val_accuracy: 0.6143\n",
      "Epoch 284/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7471 - accuracy: 0.5727 - val_loss: 0.6655 - val_accuracy: 0.6143\n",
      "Epoch 285/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7479 - accuracy: 0.5603 - val_loss: 0.6654 - val_accuracy: 0.6143\n",
      "Epoch 286/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7461 - accuracy: 0.5663 - val_loss: 0.6654 - val_accuracy: 0.6143\n",
      "Epoch 287/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7421 - accuracy: 0.5695 - val_loss: 0.6654 - val_accuracy: 0.6124\n",
      "Epoch 288/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7501 - accuracy: 0.5649 - val_loss: 0.6654 - val_accuracy: 0.6143\n",
      "Epoch 289/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7564 - accuracy: 0.5539 - val_loss: 0.6653 - val_accuracy: 0.6124\n",
      "Epoch 290/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7260 - accuracy: 0.5603 - val_loss: 0.6654 - val_accuracy: 0.6124\n",
      "Epoch 291/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7369 - accuracy: 0.5580 - val_loss: 0.6654 - val_accuracy: 0.6143\n",
      "Epoch 292/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7261 - accuracy: 0.5841 - val_loss: 0.6654 - val_accuracy: 0.6161\n",
      "Epoch 293/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7494 - accuracy: 0.5617 - val_loss: 0.6653 - val_accuracy: 0.6143\n",
      "Epoch 294/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7532 - accuracy: 0.5626 - val_loss: 0.6652 - val_accuracy: 0.6143\n",
      "Epoch 295/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7653 - accuracy: 0.5480 - val_loss: 0.6651 - val_accuracy: 0.6143\n",
      "Epoch 296/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7402 - accuracy: 0.5786 - val_loss: 0.6650 - val_accuracy: 0.6143\n",
      "Epoch 297/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.7347 - accuracy: 0.5800 - val_loss: 0.6649 - val_accuracy: 0.6124\n",
      "Epoch 298/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7239 - accuracy: 0.5663 - val_loss: 0.6650 - val_accuracy: 0.6124\n",
      "Epoch 299/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7330 - accuracy: 0.5681 - val_loss: 0.6649 - val_accuracy: 0.6124\n",
      "Epoch 300/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7526 - accuracy: 0.5640 - val_loss: 0.6650 - val_accuracy: 0.6143\n",
      "Epoch 301/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7637 - accuracy: 0.5439 - val_loss: 0.6649 - val_accuracy: 0.6124\n",
      "Epoch 302/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7294 - accuracy: 0.5612 - val_loss: 0.6649 - val_accuracy: 0.6124\n",
      "Epoch 303/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7435 - accuracy: 0.5658 - val_loss: 0.6648 - val_accuracy: 0.6124\n",
      "Epoch 304/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7576 - accuracy: 0.5535 - val_loss: 0.6647 - val_accuracy: 0.6124\n",
      "Epoch 305/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7454 - accuracy: 0.5667 - val_loss: 0.6646 - val_accuracy: 0.6124\n",
      "Epoch 306/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7435 - accuracy: 0.5745 - val_loss: 0.6646 - val_accuracy: 0.6106\n",
      "Epoch 307/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7458 - accuracy: 0.5548 - val_loss: 0.6646 - val_accuracy: 0.6124\n",
      "Epoch 308/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7423 - accuracy: 0.5731 - val_loss: 0.6644 - val_accuracy: 0.6106\n",
      "Epoch 309/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7393 - accuracy: 0.5622 - val_loss: 0.6644 - val_accuracy: 0.6106\n",
      "Epoch 310/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7420 - accuracy: 0.5722 - val_loss: 0.6644 - val_accuracy: 0.6106\n",
      "Epoch 311/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7469 - accuracy: 0.5594 - val_loss: 0.6643 - val_accuracy: 0.6106\n",
      "Epoch 312/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7381 - accuracy: 0.5718 - val_loss: 0.6641 - val_accuracy: 0.6106\n",
      "Epoch 313/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7258 - accuracy: 0.5855 - val_loss: 0.6641 - val_accuracy: 0.6106\n",
      "Epoch 314/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7410 - accuracy: 0.5590 - val_loss: 0.6641 - val_accuracy: 0.6106\n",
      "Epoch 315/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7434 - accuracy: 0.5612 - val_loss: 0.6641 - val_accuracy: 0.6106\n",
      "Epoch 316/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7452 - accuracy: 0.5498 - val_loss: 0.6640 - val_accuracy: 0.6106\n",
      "Epoch 317/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7438 - accuracy: 0.5686 - val_loss: 0.6640 - val_accuracy: 0.6106\n",
      "Epoch 318/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7209 - accuracy: 0.5841 - val_loss: 0.6638 - val_accuracy: 0.6106\n",
      "Epoch 319/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7441 - accuracy: 0.5585 - val_loss: 0.6638 - val_accuracy: 0.6106\n",
      "Epoch 320/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7302 - accuracy: 0.5850 - val_loss: 0.6639 - val_accuracy: 0.6106\n",
      "Epoch 321/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7386 - accuracy: 0.5608 - val_loss: 0.6639 - val_accuracy: 0.6106\n",
      "Epoch 322/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7412 - accuracy: 0.5644 - val_loss: 0.6638 - val_accuracy: 0.6106\n",
      "Epoch 323/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7459 - accuracy: 0.5553 - val_loss: 0.6638 - val_accuracy: 0.6106\n",
      "Epoch 324/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7305 - accuracy: 0.5695 - val_loss: 0.6638 - val_accuracy: 0.6106\n",
      "Epoch 325/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7592 - accuracy: 0.5548 - val_loss: 0.6638 - val_accuracy: 0.6106\n",
      "Epoch 326/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7458 - accuracy: 0.5617 - val_loss: 0.6637 - val_accuracy: 0.6106\n",
      "Epoch 327/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7475 - accuracy: 0.5571 - val_loss: 0.6637 - val_accuracy: 0.6106\n",
      "Epoch 328/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7447 - accuracy: 0.5603 - val_loss: 0.6636 - val_accuracy: 0.6106\n",
      "Epoch 329/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7348 - accuracy: 0.5827 - val_loss: 0.6635 - val_accuracy: 0.6088\n",
      "Epoch 330/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7400 - accuracy: 0.5617 - val_loss: 0.6635 - val_accuracy: 0.6088\n",
      "Epoch 331/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7413 - accuracy: 0.5580 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 332/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7424 - accuracy: 0.5590 - val_loss: 0.6635 - val_accuracy: 0.6088\n",
      "Epoch 333/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7378 - accuracy: 0.5763 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 334/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7614 - accuracy: 0.5535 - val_loss: 0.6633 - val_accuracy: 0.6088\n",
      "Epoch 335/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7361 - accuracy: 0.5608 - val_loss: 0.6633 - val_accuracy: 0.6088\n",
      "Epoch 336/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7459 - accuracy: 0.5658 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 337/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7285 - accuracy: 0.5654 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 338/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7444 - accuracy: 0.5612 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 339/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7289 - accuracy: 0.5768 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 340/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7403 - accuracy: 0.5786 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 341/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7309 - accuracy: 0.5750 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 342/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7440 - accuracy: 0.5736 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 343/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7127 - accuracy: 0.5782 - val_loss: 0.6633 - val_accuracy: 0.6088\n",
      "Epoch 344/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7402 - accuracy: 0.5708 - val_loss: 0.6633 - val_accuracy: 0.6088\n",
      "Epoch 345/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7312 - accuracy: 0.5727 - val_loss: 0.6633 - val_accuracy: 0.6088\n",
      "Epoch 346/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7396 - accuracy: 0.5667 - val_loss: 0.6632 - val_accuracy: 0.6088\n",
      "Epoch 347/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7208 - accuracy: 0.5818 - val_loss: 0.6632 - val_accuracy: 0.6088\n",
      "Epoch 348/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7306 - accuracy: 0.5736 - val_loss: 0.6631 - val_accuracy: 0.6088\n",
      "Epoch 349/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7222 - accuracy: 0.5841 - val_loss: 0.6632 - val_accuracy: 0.6088\n",
      "Epoch 350/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7315 - accuracy: 0.5727 - val_loss: 0.6631 - val_accuracy: 0.6088\n",
      "Epoch 351/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7415 - accuracy: 0.5631 - val_loss: 0.6630 - val_accuracy: 0.6088\n",
      "Epoch 352/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7455 - accuracy: 0.5635 - val_loss: 0.6628 - val_accuracy: 0.6088\n",
      "Epoch 353/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7517 - accuracy: 0.5608 - val_loss: 0.6627 - val_accuracy: 0.6088\n",
      "Epoch 354/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7165 - accuracy: 0.5791 - val_loss: 0.6627 - val_accuracy: 0.6088\n",
      "Epoch 355/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7336 - accuracy: 0.5658 - val_loss: 0.6626 - val_accuracy: 0.6088\n",
      "Epoch 356/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7316 - accuracy: 0.5777 - val_loss: 0.6627 - val_accuracy: 0.6088\n",
      "Epoch 357/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7294 - accuracy: 0.5750 - val_loss: 0.6626 - val_accuracy: 0.6088\n",
      "Epoch 358/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7271 - accuracy: 0.5740 - val_loss: 0.6626 - val_accuracy: 0.6088\n",
      "Epoch 359/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7365 - accuracy: 0.5599 - val_loss: 0.6625 - val_accuracy: 0.6088\n",
      "Epoch 360/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7273 - accuracy: 0.5763 - val_loss: 0.6625 - val_accuracy: 0.6088\n",
      "Epoch 361/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7274 - accuracy: 0.5864 - val_loss: 0.6624 - val_accuracy: 0.6106\n",
      "Epoch 362/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7360 - accuracy: 0.5727 - val_loss: 0.6625 - val_accuracy: 0.6106\n",
      "Epoch 363/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7246 - accuracy: 0.5823 - val_loss: 0.6625 - val_accuracy: 0.6106\n",
      "Epoch 364/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7258 - accuracy: 0.5745 - val_loss: 0.6624 - val_accuracy: 0.6106\n",
      "Epoch 365/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7419 - accuracy: 0.5663 - val_loss: 0.6624 - val_accuracy: 0.6106\n",
      "Epoch 366/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7345 - accuracy: 0.5676 - val_loss: 0.6624 - val_accuracy: 0.6106\n",
      "Epoch 367/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7385 - accuracy: 0.5658 - val_loss: 0.6623 - val_accuracy: 0.6106\n",
      "Epoch 368/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7370 - accuracy: 0.5681 - val_loss: 0.6623 - val_accuracy: 0.6106\n",
      "Epoch 369/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7189 - accuracy: 0.5868 - val_loss: 0.6623 - val_accuracy: 0.6106\n",
      "Epoch 370/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7343 - accuracy: 0.5676 - val_loss: 0.6623 - val_accuracy: 0.6124\n",
      "Epoch 371/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7360 - accuracy: 0.5644 - val_loss: 0.6623 - val_accuracy: 0.6124\n",
      "Epoch 372/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7270 - accuracy: 0.5681 - val_loss: 0.6623 - val_accuracy: 0.6106\n",
      "Epoch 373/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7425 - accuracy: 0.5622 - val_loss: 0.6622 - val_accuracy: 0.6124\n",
      "Epoch 374/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7461 - accuracy: 0.5489 - val_loss: 0.6622 - val_accuracy: 0.6124\n",
      "Epoch 375/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7313 - accuracy: 0.5754 - val_loss: 0.6622 - val_accuracy: 0.6124\n",
      "Epoch 376/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7495 - accuracy: 0.5622 - val_loss: 0.6622 - val_accuracy: 0.6124\n",
      "Epoch 377/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7170 - accuracy: 0.5704 - val_loss: 0.6621 - val_accuracy: 0.6124\n",
      "Epoch 378/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7363 - accuracy: 0.5567 - val_loss: 0.6621 - val_accuracy: 0.6124\n",
      "Epoch 379/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7320 - accuracy: 0.5772 - val_loss: 0.6621 - val_accuracy: 0.6124\n",
      "Epoch 380/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7347 - accuracy: 0.5699 - val_loss: 0.6621 - val_accuracy: 0.6124\n",
      "Epoch 381/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7257 - accuracy: 0.5882 - val_loss: 0.6621 - val_accuracy: 0.6124\n",
      "Epoch 382/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7330 - accuracy: 0.5603 - val_loss: 0.6620 - val_accuracy: 0.6124\n",
      "Epoch 383/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7272 - accuracy: 0.5768 - val_loss: 0.6620 - val_accuracy: 0.6124\n",
      "Epoch 384/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7402 - accuracy: 0.5631 - val_loss: 0.6620 - val_accuracy: 0.6124\n",
      "Epoch 385/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7352 - accuracy: 0.5681 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 386/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7323 - accuracy: 0.5727 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 387/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7280 - accuracy: 0.5676 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 388/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7304 - accuracy: 0.5754 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 389/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7376 - accuracy: 0.5594 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 390/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7285 - accuracy: 0.5891 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 391/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7355 - accuracy: 0.5708 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 392/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7407 - accuracy: 0.5562 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 393/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7343 - accuracy: 0.5832 - val_loss: 0.6619 - val_accuracy: 0.6124\n",
      "Epoch 394/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7386 - accuracy: 0.5599 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 395/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7366 - accuracy: 0.5704 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 396/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7227 - accuracy: 0.5740 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 397/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7271 - accuracy: 0.5704 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 398/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7149 - accuracy: 0.5814 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 399/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7431 - accuracy: 0.5695 - val_loss: 0.6617 - val_accuracy: 0.6124\n",
      "Epoch 400/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7255 - accuracy: 0.5699 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 401/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7170 - accuracy: 0.5786 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 402/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7145 - accuracy: 0.5850 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 403/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7230 - accuracy: 0.5736 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 404/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.7168 - accuracy: 0.5891 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 405/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7226 - accuracy: 0.5795 - val_loss: 0.6618 - val_accuracy: 0.6124\n",
      "Epoch 406/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7276 - accuracy: 0.5736 - val_loss: 0.6617 - val_accuracy: 0.6124\n",
      "Epoch 407/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7341 - accuracy: 0.5731 - val_loss: 0.6617 - val_accuracy: 0.6124\n",
      "Epoch 408/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7316 - accuracy: 0.5731 - val_loss: 0.6617 - val_accuracy: 0.6124\n",
      "Epoch 409/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7420 - accuracy: 0.5640 - val_loss: 0.6617 - val_accuracy: 0.6124\n",
      "Epoch 410/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7114 - accuracy: 0.5823 - val_loss: 0.6617 - val_accuracy: 0.6124\n",
      "Epoch 411/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7250 - accuracy: 0.5676 - val_loss: 0.6616 - val_accuracy: 0.6124\n",
      "Epoch 412/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7420 - accuracy: 0.5553 - val_loss: 0.6616 - val_accuracy: 0.6124\n",
      "Epoch 413/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7173 - accuracy: 0.5782 - val_loss: 0.6616 - val_accuracy: 0.6124\n",
      "Epoch 414/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7319 - accuracy: 0.5777 - val_loss: 0.6616 - val_accuracy: 0.6124\n",
      "Epoch 415/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7424 - accuracy: 0.5681 - val_loss: 0.6615 - val_accuracy: 0.6143\n",
      "Epoch 416/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7287 - accuracy: 0.5704 - val_loss: 0.6615 - val_accuracy: 0.6143\n",
      "Epoch 417/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7246 - accuracy: 0.5763 - val_loss: 0.6615 - val_accuracy: 0.6124\n",
      "Epoch 418/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7286 - accuracy: 0.5681 - val_loss: 0.6615 - val_accuracy: 0.6124\n",
      "Epoch 419/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7488 - accuracy: 0.5672 - val_loss: 0.6615 - val_accuracy: 0.6124\n",
      "Epoch 420/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7359 - accuracy: 0.5759 - val_loss: 0.6614 - val_accuracy: 0.6124\n",
      "Epoch 421/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7252 - accuracy: 0.5672 - val_loss: 0.6614 - val_accuracy: 0.6124\n",
      "Epoch 422/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7319 - accuracy: 0.5658 - val_loss: 0.6614 - val_accuracy: 0.6124\n",
      "Epoch 423/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7356 - accuracy: 0.5585 - val_loss: 0.6613 - val_accuracy: 0.6143\n",
      "Epoch 424/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7251 - accuracy: 0.5850 - val_loss: 0.6613 - val_accuracy: 0.6143\n",
      "Epoch 425/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7134 - accuracy: 0.5809 - val_loss: 0.6613 - val_accuracy: 0.6143\n",
      "Epoch 426/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7322 - accuracy: 0.5814 - val_loss: 0.6612 - val_accuracy: 0.6143\n",
      "Epoch 427/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7285 - accuracy: 0.5603 - val_loss: 0.6612 - val_accuracy: 0.6124\n",
      "Epoch 428/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7210 - accuracy: 0.5777 - val_loss: 0.6612 - val_accuracy: 0.6124\n",
      "Epoch 429/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7276 - accuracy: 0.5868 - val_loss: 0.6612 - val_accuracy: 0.6124\n",
      "Epoch 430/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7289 - accuracy: 0.5699 - val_loss: 0.6612 - val_accuracy: 0.6124\n",
      "Epoch 431/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7475 - accuracy: 0.5530 - val_loss: 0.6611 - val_accuracy: 0.6124\n",
      "Epoch 432/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7274 - accuracy: 0.5768 - val_loss: 0.6611 - val_accuracy: 0.6124\n",
      "Epoch 433/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7416 - accuracy: 0.5612 - val_loss: 0.6610 - val_accuracy: 0.6143\n",
      "Epoch 434/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7342 - accuracy: 0.5622 - val_loss: 0.6610 - val_accuracy: 0.6143\n",
      "Epoch 435/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7114 - accuracy: 0.5809 - val_loss: 0.6610 - val_accuracy: 0.6143\n",
      "Epoch 436/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7321 - accuracy: 0.5676 - val_loss: 0.6609 - val_accuracy: 0.6143\n",
      "Epoch 437/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7404 - accuracy: 0.5516 - val_loss: 0.6609 - val_accuracy: 0.6143\n",
      "Epoch 438/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7262 - accuracy: 0.5791 - val_loss: 0.6609 - val_accuracy: 0.6124\n",
      "Epoch 439/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7077 - accuracy: 0.5809 - val_loss: 0.6608 - val_accuracy: 0.6124\n",
      "Epoch 440/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7339 - accuracy: 0.5795 - val_loss: 0.6608 - val_accuracy: 0.6124\n",
      "Epoch 441/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7362 - accuracy: 0.5553 - val_loss: 0.6607 - val_accuracy: 0.6124\n",
      "Epoch 442/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7297 - accuracy: 0.5768 - val_loss: 0.6607 - val_accuracy: 0.6124\n",
      "Epoch 443/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7385 - accuracy: 0.5603 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 444/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7297 - accuracy: 0.5608 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 445/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7286 - accuracy: 0.5823 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 446/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7433 - accuracy: 0.5663 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 447/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7332 - accuracy: 0.5635 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 448/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7262 - accuracy: 0.5763 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 449/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7269 - accuracy: 0.5795 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 450/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7278 - accuracy: 0.5676 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 451/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7259 - accuracy: 0.5690 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 452/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7221 - accuracy: 0.5905 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 453/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7461 - accuracy: 0.5580 - val_loss: 0.6606 - val_accuracy: 0.6124\n",
      "Epoch 454/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7374 - accuracy: 0.5782 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 455/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7096 - accuracy: 0.5804 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 456/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7271 - accuracy: 0.5768 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 457/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7165 - accuracy: 0.5791 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 458/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7283 - accuracy: 0.5622 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 459/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7407 - accuracy: 0.5718 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 460/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7291 - accuracy: 0.5713 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 461/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7212 - accuracy: 0.5708 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 462/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7248 - accuracy: 0.5786 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 463/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7385 - accuracy: 0.5503 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 464/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7333 - accuracy: 0.5681 - val_loss: 0.6605 - val_accuracy: 0.6124\n",
      "Epoch 465/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7175 - accuracy: 0.5791 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 466/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7356 - accuracy: 0.5672 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 467/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7136 - accuracy: 0.5782 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 468/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7107 - accuracy: 0.5795 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 469/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7383 - accuracy: 0.5530 - val_loss: 0.6604 - val_accuracy: 0.6124\n",
      "Epoch 470/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7152 - accuracy: 0.5827 - val_loss: 0.6603 - val_accuracy: 0.6124\n",
      "Epoch 471/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7245 - accuracy: 0.5782 - val_loss: 0.6603 - val_accuracy: 0.6124\n",
      "Epoch 472/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7226 - accuracy: 0.5795 - val_loss: 0.6602 - val_accuracy: 0.6124\n",
      "Epoch 473/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7297 - accuracy: 0.5727 - val_loss: 0.6602 - val_accuracy: 0.6124\n",
      "Epoch 474/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7303 - accuracy: 0.5672 - val_loss: 0.6602 - val_accuracy: 0.6124\n",
      "Epoch 475/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7137 - accuracy: 0.5973 - val_loss: 0.6602 - val_accuracy: 0.6124\n",
      "Epoch 476/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7243 - accuracy: 0.5690 - val_loss: 0.6602 - val_accuracy: 0.6124\n",
      "Epoch 477/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7159 - accuracy: 0.5772 - val_loss: 0.6601 - val_accuracy: 0.6124\n",
      "Epoch 478/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7280 - accuracy: 0.5750 - val_loss: 0.6601 - val_accuracy: 0.6124\n",
      "Epoch 479/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7321 - accuracy: 0.5745 - val_loss: 0.6601 - val_accuracy: 0.6124\n",
      "Epoch 480/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7184 - accuracy: 0.5791 - val_loss: 0.6601 - val_accuracy: 0.6124\n",
      "Epoch 481/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7306 - accuracy: 0.5640 - val_loss: 0.6601 - val_accuracy: 0.6124\n",
      "Epoch 482/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7350 - accuracy: 0.5626 - val_loss: 0.6600 - val_accuracy: 0.6124\n",
      "Epoch 483/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7306 - accuracy: 0.5672 - val_loss: 0.6600 - val_accuracy: 0.6124\n",
      "Epoch 484/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7150 - accuracy: 0.5768 - val_loss: 0.6600 - val_accuracy: 0.6124\n",
      "Epoch 485/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7120 - accuracy: 0.5846 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 486/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7117 - accuracy: 0.5882 - val_loss: 0.6600 - val_accuracy: 0.6124\n",
      "Epoch 487/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7349 - accuracy: 0.5640 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 488/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7234 - accuracy: 0.5740 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 489/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7280 - accuracy: 0.5768 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 490/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7304 - accuracy: 0.5649 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 491/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7193 - accuracy: 0.5836 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 492/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7419 - accuracy: 0.5676 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 493/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7362 - accuracy: 0.5663 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 494/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7187 - accuracy: 0.5804 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 495/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7110 - accuracy: 0.5768 - val_loss: 0.6598 - val_accuracy: 0.6124\n",
      "Epoch 496/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7140 - accuracy: 0.5882 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 497/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7164 - accuracy: 0.5809 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 498/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7360 - accuracy: 0.5654 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 499/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7259 - accuracy: 0.5736 - val_loss: 0.6598 - val_accuracy: 0.6124\n",
      "Epoch 500/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7294 - accuracy: 0.5571 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 501/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7298 - accuracy: 0.5910 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 502/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7365 - accuracy: 0.5676 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 503/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7386 - accuracy: 0.5562 - val_loss: 0.6599 - val_accuracy: 0.6124\n",
      "Epoch 504/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7221 - accuracy: 0.5708 - val_loss: 0.6598 - val_accuracy: 0.6124\n",
      "Epoch 505/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7295 - accuracy: 0.5745 - val_loss: 0.6598 - val_accuracy: 0.6124\n",
      "Epoch 506/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7207 - accuracy: 0.5855 - val_loss: 0.6598 - val_accuracy: 0.6124\n",
      "Epoch 507/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7131 - accuracy: 0.5718 - val_loss: 0.6598 - val_accuracy: 0.6124\n",
      "Epoch 508/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7184 - accuracy: 0.5814 - val_loss: 0.6598 - val_accuracy: 0.6124\n",
      "Epoch 509/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7373 - accuracy: 0.5612 - val_loss: 0.6597 - val_accuracy: 0.6124\n",
      "Epoch 510/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7374 - accuracy: 0.5654 - val_loss: 0.6597 - val_accuracy: 0.6124\n",
      "Epoch 511/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7091 - accuracy: 0.5855 - val_loss: 0.6597 - val_accuracy: 0.6124\n",
      "Epoch 512/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7298 - accuracy: 0.5686 - val_loss: 0.6597 - val_accuracy: 0.6124\n",
      "Epoch 513/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7225 - accuracy: 0.5804 - val_loss: 0.6597 - val_accuracy: 0.6124\n",
      "Epoch 514/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7146 - accuracy: 0.5882 - val_loss: 0.6597 - val_accuracy: 0.6124\n",
      "Epoch 515/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7334 - accuracy: 0.5736 - val_loss: 0.6596 - val_accuracy: 0.6124\n",
      "Epoch 516/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.7249 - accuracy: 0.5841 - val_loss: 0.6596 - val_accuracy: 0.6124\n",
      "Epoch 517/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7304 - accuracy: 0.5873 - val_loss: 0.6596 - val_accuracy: 0.6124\n",
      "Epoch 518/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7299 - accuracy: 0.5672 - val_loss: 0.6596 - val_accuracy: 0.6124\n",
      "Epoch 519/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7328 - accuracy: 0.5763 - val_loss: 0.6595 - val_accuracy: 0.6106\n",
      "Epoch 520/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7218 - accuracy: 0.5804 - val_loss: 0.6595 - val_accuracy: 0.6106\n",
      "Epoch 521/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7185 - accuracy: 0.5772 - val_loss: 0.6595 - val_accuracy: 0.6106\n",
      "Epoch 522/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7167 - accuracy: 0.5841 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 523/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7289 - accuracy: 0.5736 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 524/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7304 - accuracy: 0.5836 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 525/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7173 - accuracy: 0.5804 - val_loss: 0.6596 - val_accuracy: 0.6124\n",
      "Epoch 526/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.7237 - accuracy: 0.5654 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 527/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7225 - accuracy: 0.5800 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 528/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7202 - accuracy: 0.5791 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 529/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7133 - accuracy: 0.5791 - val_loss: 0.6595 - val_accuracy: 0.6124\n",
      "Epoch 530/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7330 - accuracy: 0.5631 - val_loss: 0.6594 - val_accuracy: 0.6106\n",
      "Epoch 531/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7227 - accuracy: 0.5855 - val_loss: 0.6594 - val_accuracy: 0.6106\n",
      "Epoch 532/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7279 - accuracy: 0.5681 - val_loss: 0.6594 - val_accuracy: 0.6106\n",
      "Epoch 533/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7191 - accuracy: 0.5763 - val_loss: 0.6594 - val_accuracy: 0.6106\n",
      "Epoch 534/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7194 - accuracy: 0.5795 - val_loss: 0.6594 - val_accuracy: 0.6106\n",
      "Epoch 535/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7316 - accuracy: 0.5704 - val_loss: 0.6594 - val_accuracy: 0.6124\n",
      "Epoch 536/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7102 - accuracy: 0.5841 - val_loss: 0.6594 - val_accuracy: 0.6124\n",
      "Epoch 537/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7224 - accuracy: 0.5818 - val_loss: 0.6593 - val_accuracy: 0.6124\n",
      "Epoch 538/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7238 - accuracy: 0.5695 - val_loss: 0.6593 - val_accuracy: 0.6124\n",
      "Epoch 539/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7165 - accuracy: 0.5841 - val_loss: 0.6593 - val_accuracy: 0.6124\n",
      "Epoch 540/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7167 - accuracy: 0.5795 - val_loss: 0.6593 - val_accuracy: 0.6124\n",
      "Epoch 541/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7139 - accuracy: 0.5713 - val_loss: 0.6593 - val_accuracy: 0.6124\n",
      "Epoch 542/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7173 - accuracy: 0.5736 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 543/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7142 - accuracy: 0.5763 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 544/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7252 - accuracy: 0.5635 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 545/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7149 - accuracy: 0.5887 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 546/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7279 - accuracy: 0.5686 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 547/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7091 - accuracy: 0.5786 - val_loss: 0.6591 - val_accuracy: 0.6124\n",
      "Epoch 548/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7112 - accuracy: 0.5768 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 549/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7050 - accuracy: 0.5992 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 550/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7264 - accuracy: 0.5704 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 551/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7147 - accuracy: 0.5873 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 552/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7059 - accuracy: 0.5836 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 553/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7123 - accuracy: 0.5873 - val_loss: 0.6593 - val_accuracy: 0.6124\n",
      "Epoch 554/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7297 - accuracy: 0.5713 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 555/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7188 - accuracy: 0.5718 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 556/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7254 - accuracy: 0.5722 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 557/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7197 - accuracy: 0.5777 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 558/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7193 - accuracy: 0.5855 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 559/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7200 - accuracy: 0.5782 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 560/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7198 - accuracy: 0.5777 - val_loss: 0.6592 - val_accuracy: 0.6124\n",
      "Epoch 561/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7279 - accuracy: 0.5699 - val_loss: 0.6591 - val_accuracy: 0.6124\n",
      "Epoch 562/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7195 - accuracy: 0.5690 - val_loss: 0.6591 - val_accuracy: 0.6124\n",
      "Epoch 563/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7103 - accuracy: 0.5786 - val_loss: 0.6591 - val_accuracy: 0.6124\n",
      "Epoch 564/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7155 - accuracy: 0.5713 - val_loss: 0.6591 - val_accuracy: 0.6124\n",
      "Epoch 565/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7206 - accuracy: 0.5786 - val_loss: 0.6590 - val_accuracy: 0.6124\n",
      "Epoch 566/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7231 - accuracy: 0.5686 - val_loss: 0.6590 - val_accuracy: 0.6124\n",
      "Epoch 567/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7168 - accuracy: 0.5777 - val_loss: 0.6590 - val_accuracy: 0.6124\n",
      "Epoch 568/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7247 - accuracy: 0.5690 - val_loss: 0.6590 - val_accuracy: 0.6143\n",
      "Epoch 569/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7133 - accuracy: 0.5827 - val_loss: 0.6590 - val_accuracy: 0.6124\n",
      "Epoch 570/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7249 - accuracy: 0.5818 - val_loss: 0.6589 - val_accuracy: 0.6143\n",
      "Epoch 571/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7218 - accuracy: 0.5868 - val_loss: 0.6589 - val_accuracy: 0.6143\n",
      "Epoch 572/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7181 - accuracy: 0.5663 - val_loss: 0.6589 - val_accuracy: 0.6143\n",
      "Epoch 573/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7233 - accuracy: 0.5745 - val_loss: 0.6589 - val_accuracy: 0.6143\n",
      "Epoch 574/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7135 - accuracy: 0.5782 - val_loss: 0.6588 - val_accuracy: 0.6143\n",
      "Epoch 575/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7013 - accuracy: 0.5891 - val_loss: 0.6588 - val_accuracy: 0.6143\n",
      "Epoch 576/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7313 - accuracy: 0.5667 - val_loss: 0.6588 - val_accuracy: 0.6143\n",
      "Epoch 577/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7225 - accuracy: 0.5763 - val_loss: 0.6587 - val_accuracy: 0.6143\n",
      "Epoch 578/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7212 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6143\n",
      "Epoch 579/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7328 - accuracy: 0.5612 - val_loss: 0.6587 - val_accuracy: 0.6124\n",
      "Epoch 580/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7271 - accuracy: 0.5782 - val_loss: 0.6588 - val_accuracy: 0.6124\n",
      "Epoch 581/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7190 - accuracy: 0.5832 - val_loss: 0.6588 - val_accuracy: 0.6124\n",
      "Epoch 582/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7207 - accuracy: 0.5832 - val_loss: 0.6587 - val_accuracy: 0.6124\n",
      "Epoch 583/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7121 - accuracy: 0.5768 - val_loss: 0.6587 - val_accuracy: 0.6124\n",
      "Epoch 584/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7152 - accuracy: 0.5800 - val_loss: 0.6587 - val_accuracy: 0.6124\n",
      "Epoch 585/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7128 - accuracy: 0.5809 - val_loss: 0.6587 - val_accuracy: 0.6143\n",
      "Epoch 586/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7022 - accuracy: 0.5878 - val_loss: 0.6587 - val_accuracy: 0.6143\n",
      "Epoch 587/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7082 - accuracy: 0.5887 - val_loss: 0.6587 - val_accuracy: 0.6143\n",
      "Epoch 588/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7263 - accuracy: 0.5704 - val_loss: 0.6587 - val_accuracy: 0.6143\n",
      "Epoch 589/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7293 - accuracy: 0.5777 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 590/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7150 - accuracy: 0.5754 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 591/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7268 - accuracy: 0.5667 - val_loss: 0.6586 - val_accuracy: 0.6124\n",
      "Epoch 592/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7205 - accuracy: 0.5644 - val_loss: 0.6586 - val_accuracy: 0.6124\n",
      "Epoch 593/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7134 - accuracy: 0.5900 - val_loss: 0.6585 - val_accuracy: 0.6106\n",
      "Epoch 594/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7192 - accuracy: 0.5704 - val_loss: 0.6585 - val_accuracy: 0.6124\n",
      "Epoch 595/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7166 - accuracy: 0.5795 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 596/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7188 - accuracy: 0.5736 - val_loss: 0.6585 - val_accuracy: 0.6106\n",
      "Epoch 597/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7278 - accuracy: 0.5672 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 598/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7090 - accuracy: 0.5722 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 599/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7179 - accuracy: 0.5722 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 600/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7090 - accuracy: 0.5782 - val_loss: 0.6586 - val_accuracy: 0.6124\n",
      "Epoch 601/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7220 - accuracy: 0.5754 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 602/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7125 - accuracy: 0.5859 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 603/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7152 - accuracy: 0.5864 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 604/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7211 - accuracy: 0.5832 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 605/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7047 - accuracy: 0.5882 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 606/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7160 - accuracy: 0.5878 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 607/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7266 - accuracy: 0.5599 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 608/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7176 - accuracy: 0.5795 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 609/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7119 - accuracy: 0.5887 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 610/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7139 - accuracy: 0.5868 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 611/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7207 - accuracy: 0.5777 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 612/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7114 - accuracy: 0.5763 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 613/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7266 - accuracy: 0.5782 - val_loss: 0.6586 - val_accuracy: 0.6143\n",
      "Epoch 614/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7279 - accuracy: 0.5772 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 615/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7125 - accuracy: 0.5900 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 616/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7036 - accuracy: 0.5923 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 617/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7177 - accuracy: 0.5740 - val_loss: 0.6585 - val_accuracy: 0.6124\n",
      "Epoch 618/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7173 - accuracy: 0.5809 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 619/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7148 - accuracy: 0.5878 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 620/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7065 - accuracy: 0.5937 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 621/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7345 - accuracy: 0.5626 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 622/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7282 - accuracy: 0.5690 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 623/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7046 - accuracy: 0.6010 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 624/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7154 - accuracy: 0.5809 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 625/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7306 - accuracy: 0.5731 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 626/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7279 - accuracy: 0.5658 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 627/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7127 - accuracy: 0.5786 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 628/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7196 - accuracy: 0.5818 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 629/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7052 - accuracy: 0.5900 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 630/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7127 - accuracy: 0.5804 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 631/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7028 - accuracy: 0.5905 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 632/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7248 - accuracy: 0.5809 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 633/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7052 - accuracy: 0.5900 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 634/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7112 - accuracy: 0.5782 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 635/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7195 - accuracy: 0.5681 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 636/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7166 - accuracy: 0.5736 - val_loss: 0.6585 - val_accuracy: 0.6179\n",
      "Epoch 637/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7039 - accuracy: 0.5823 - val_loss: 0.6585 - val_accuracy: 0.6179\n",
      "Epoch 638/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7153 - accuracy: 0.5823 - val_loss: 0.6585 - val_accuracy: 0.6179\n",
      "Epoch 639/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7276 - accuracy: 0.5590 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 640/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7259 - accuracy: 0.5676 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 641/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7165 - accuracy: 0.5736 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 642/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7116 - accuracy: 0.5814 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 643/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6999 - accuracy: 0.5937 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 644/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7116 - accuracy: 0.5946 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 645/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7242 - accuracy: 0.5750 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 646/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7102 - accuracy: 0.5887 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 647/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7095 - accuracy: 0.5727 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 648/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7232 - accuracy: 0.5663 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 649/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7131 - accuracy: 0.5727 - val_loss: 0.6585 - val_accuracy: 0.6179\n",
      "Epoch 650/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7146 - accuracy: 0.5736 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 651/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7230 - accuracy: 0.5658 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 652/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7196 - accuracy: 0.5795 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 653/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7027 - accuracy: 0.5827 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 654/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7074 - accuracy: 0.5932 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 655/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7087 - accuracy: 0.5740 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 656/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7109 - accuracy: 0.5750 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 657/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7119 - accuracy: 0.5818 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 658/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7163 - accuracy: 0.5768 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 659/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7041 - accuracy: 0.5882 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 660/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7024 - accuracy: 0.5878 - val_loss: 0.6584 - val_accuracy: 0.6179\n",
      "Epoch 661/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7191 - accuracy: 0.5809 - val_loss: 0.6583 - val_accuracy: 0.6179\n",
      "Epoch 662/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7053 - accuracy: 0.5887 - val_loss: 0.6583 - val_accuracy: 0.6179\n",
      "Epoch 663/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7172 - accuracy: 0.5786 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 664/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7150 - accuracy: 0.5809 - val_loss: 0.6583 - val_accuracy: 0.6179\n",
      "Epoch 665/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7193 - accuracy: 0.5772 - val_loss: 0.6583 - val_accuracy: 0.6179\n",
      "Epoch 666/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7112 - accuracy: 0.5800 - val_loss: 0.6583 - val_accuracy: 0.6179\n",
      "Epoch 667/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7151 - accuracy: 0.5763 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 668/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7164 - accuracy: 0.5823 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 669/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7311 - accuracy: 0.5667 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 670/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7230 - accuracy: 0.5754 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 671/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7146 - accuracy: 0.5686 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 672/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7145 - accuracy: 0.5772 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 673/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7102 - accuracy: 0.5763 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 674/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7044 - accuracy: 0.5873 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 675/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7088 - accuracy: 0.5795 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 676/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7148 - accuracy: 0.5708 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 677/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7027 - accuracy: 0.5836 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 678/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7150 - accuracy: 0.5855 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 679/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7054 - accuracy: 0.5951 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 680/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7071 - accuracy: 0.5887 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 681/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7138 - accuracy: 0.5850 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 682/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6901 - accuracy: 0.5992 - val_loss: 0.6581 - val_accuracy: 0.6197\n",
      "Epoch 683/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7132 - accuracy: 0.5846 - val_loss: 0.6581 - val_accuracy: 0.6197\n",
      "Epoch 684/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7052 - accuracy: 0.5836 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 685/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7202 - accuracy: 0.5722 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 686/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6978 - accuracy: 0.6010 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 687/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7199 - accuracy: 0.5713 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 688/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7187 - accuracy: 0.5887 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 689/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7163 - accuracy: 0.5804 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 690/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7174 - accuracy: 0.5841 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 691/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7227 - accuracy: 0.5699 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 692/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7198 - accuracy: 0.5804 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 693/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7157 - accuracy: 0.5750 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 694/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7099 - accuracy: 0.5836 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 695/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7120 - accuracy: 0.5809 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 696/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7096 - accuracy: 0.5777 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 697/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7161 - accuracy: 0.5750 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 698/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7132 - accuracy: 0.5736 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 699/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7098 - accuracy: 0.5750 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 700/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7199 - accuracy: 0.5777 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 701/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7140 - accuracy: 0.5800 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 702/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7029 - accuracy: 0.5973 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 703/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7104 - accuracy: 0.5782 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 704/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7104 - accuracy: 0.5873 - val_loss: 0.6580 - val_accuracy: 0.6161\n",
      "Epoch 705/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7175 - accuracy: 0.5777 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 706/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7094 - accuracy: 0.5727 - val_loss: 0.6580 - val_accuracy: 0.6161\n",
      "Epoch 707/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7108 - accuracy: 0.5791 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 708/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6979 - accuracy: 0.5987 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 709/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7227 - accuracy: 0.5626 - val_loss: 0.6580 - val_accuracy: 0.6161\n",
      "Epoch 710/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7145 - accuracy: 0.5850 - val_loss: 0.6580 - val_accuracy: 0.6161\n",
      "Epoch 711/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6948 - accuracy: 0.5932 - val_loss: 0.6579 - val_accuracy: 0.6161\n",
      "Epoch 712/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7363 - accuracy: 0.5699 - val_loss: 0.6579 - val_accuracy: 0.6161\n",
      "Epoch 713/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6974 - accuracy: 0.5964 - val_loss: 0.6579 - val_accuracy: 0.6161\n",
      "Epoch 714/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7243 - accuracy: 0.5836 - val_loss: 0.6579 - val_accuracy: 0.6161\n",
      "Epoch 715/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7062 - accuracy: 0.5786 - val_loss: 0.6579 - val_accuracy: 0.6161\n",
      "Epoch 716/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7163 - accuracy: 0.5809 - val_loss: 0.6579 - val_accuracy: 0.6179\n",
      "Epoch 717/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7068 - accuracy: 0.5910 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 718/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7116 - accuracy: 0.5850 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 719/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7056 - accuracy: 0.5859 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 720/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7248 - accuracy: 0.5750 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 721/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7079 - accuracy: 0.5809 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 722/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6999 - accuracy: 0.5978 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 723/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7104 - accuracy: 0.5891 - val_loss: 0.6580 - val_accuracy: 0.6216\n",
      "Epoch 724/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7072 - accuracy: 0.5736 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 725/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7103 - accuracy: 0.5809 - val_loss: 0.6580 - val_accuracy: 0.6216\n",
      "Epoch 726/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6962 - accuracy: 0.5992 - val_loss: 0.6580 - val_accuracy: 0.6216\n",
      "Epoch 727/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7038 - accuracy: 0.5919 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 728/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7188 - accuracy: 0.5754 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 729/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7119 - accuracy: 0.5754 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 730/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7070 - accuracy: 0.5850 - val_loss: 0.6581 - val_accuracy: 0.6197\n",
      "Epoch 731/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7105 - accuracy: 0.5699 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 732/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7079 - accuracy: 0.5836 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 733/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7025 - accuracy: 0.5900 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 734/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7148 - accuracy: 0.5654 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 735/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7067 - accuracy: 0.5786 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 736/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6977 - accuracy: 0.5919 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 737/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7035 - accuracy: 0.5896 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 738/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7074 - accuracy: 0.5878 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 739/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7155 - accuracy: 0.5754 - val_loss: 0.6580 - val_accuracy: 0.6179\n",
      "Epoch 740/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7168 - accuracy: 0.5823 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 741/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7286 - accuracy: 0.5850 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 742/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6932 - accuracy: 0.5983 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 743/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7005 - accuracy: 0.5951 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 744/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7174 - accuracy: 0.5754 - val_loss: 0.6581 - val_accuracy: 0.6197\n",
      "Epoch 745/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7110 - accuracy: 0.5873 - val_loss: 0.6581 - val_accuracy: 0.6197\n",
      "Epoch 746/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7108 - accuracy: 0.5745 - val_loss: 0.6581 - val_accuracy: 0.6197\n",
      "Epoch 747/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7136 - accuracy: 0.5809 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 748/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7019 - accuracy: 0.5836 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 749/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6918 - accuracy: 0.5873 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 750/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7015 - accuracy: 0.6079 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 751/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7110 - accuracy: 0.5855 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 752/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7049 - accuracy: 0.5836 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 753/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7040 - accuracy: 0.5878 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 754/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7257 - accuracy: 0.5745 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 755/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7040 - accuracy: 0.5782 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 756/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6934 - accuracy: 0.5946 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 757/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6946 - accuracy: 0.6019 - val_loss: 0.6582 - val_accuracy: 0.6197\n",
      "Epoch 758/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7049 - accuracy: 0.5823 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 759/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7154 - accuracy: 0.5818 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 760/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7013 - accuracy: 0.5891 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 761/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6946 - accuracy: 0.5955 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 762/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7141 - accuracy: 0.5800 - val_loss: 0.6582 - val_accuracy: 0.6161\n",
      "Epoch 763/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7021 - accuracy: 0.5777 - val_loss: 0.6582 - val_accuracy: 0.6161\n",
      "Epoch 764/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7030 - accuracy: 0.5827 - val_loss: 0.6582 - val_accuracy: 0.6161\n",
      "Epoch 765/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7126 - accuracy: 0.5786 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 766/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7036 - accuracy: 0.5855 - val_loss: 0.6582 - val_accuracy: 0.6161\n",
      "Epoch 767/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7017 - accuracy: 0.5836 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 768/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7188 - accuracy: 0.5745 - val_loss: 0.6581 - val_accuracy: 0.6161\n",
      "Epoch 769/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7057 - accuracy: 0.5772 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 770/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7059 - accuracy: 0.5846 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 771/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6924 - accuracy: 0.5996 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 772/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7046 - accuracy: 0.5896 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 773/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7019 - accuracy: 0.5910 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 774/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6921 - accuracy: 0.6047 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 775/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7063 - accuracy: 0.5937 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 776/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7070 - accuracy: 0.5905 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 777/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7044 - accuracy: 0.5868 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 778/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7041 - accuracy: 0.5969 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 779/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6975 - accuracy: 0.5923 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 780/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7074 - accuracy: 0.5882 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 781/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6972 - accuracy: 0.5978 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 782/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7199 - accuracy: 0.5713 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 783/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7053 - accuracy: 0.5754 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 784/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7068 - accuracy: 0.5809 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 785/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7155 - accuracy: 0.5823 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 786/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7048 - accuracy: 0.5859 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 787/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7083 - accuracy: 0.5768 - val_loss: 0.6581 - val_accuracy: 0.6179\n",
      "Epoch 788/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7249 - accuracy: 0.5777 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 789/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6975 - accuracy: 0.5923 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 790/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7090 - accuracy: 0.5996 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 791/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7153 - accuracy: 0.5772 - val_loss: 0.6582 - val_accuracy: 0.6161\n",
      "Epoch 792/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7057 - accuracy: 0.5960 - val_loss: 0.6582 - val_accuracy: 0.6179\n",
      "Epoch 793/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7204 - accuracy: 0.5704 - val_loss: 0.6582 - val_accuracy: 0.6161\n",
      "Epoch 794/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6986 - accuracy: 0.5919 - val_loss: 0.6582 - val_accuracy: 0.6143\n",
      "Epoch 795/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7054 - accuracy: 0.5919 - val_loss: 0.6582 - val_accuracy: 0.6143\n",
      "Epoch 796/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7043 - accuracy: 0.5905 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 797/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7163 - accuracy: 0.5804 - val_loss: 0.6583 - val_accuracy: 0.6179\n",
      "Epoch 798/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7014 - accuracy: 0.5804 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 799/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7199 - accuracy: 0.5795 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 800/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7107 - accuracy: 0.5754 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 801/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7017 - accuracy: 0.5800 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 802/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7184 - accuracy: 0.5782 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 803/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7117 - accuracy: 0.5795 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 804/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7066 - accuracy: 0.5823 - val_loss: 0.6584 - val_accuracy: 0.6143\n",
      "Epoch 805/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7062 - accuracy: 0.5887 - val_loss: 0.6584 - val_accuracy: 0.6143\n",
      "Epoch 806/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7181 - accuracy: 0.5695 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 807/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7053 - accuracy: 0.5850 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 808/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6975 - accuracy: 0.5878 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 809/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7085 - accuracy: 0.5964 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 810/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7106 - accuracy: 0.5823 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 811/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7157 - accuracy: 0.5686 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 812/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7007 - accuracy: 0.5932 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 813/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7145 - accuracy: 0.5672 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 814/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7054 - accuracy: 0.5818 - val_loss: 0.6583 - val_accuracy: 0.6124\n",
      "Epoch 815/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7074 - accuracy: 0.5708 - val_loss: 0.6583 - val_accuracy: 0.6124\n",
      "Epoch 816/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7054 - accuracy: 0.5900 - val_loss: 0.6583 - val_accuracy: 0.6124\n",
      "Epoch 817/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7104 - accuracy: 0.5763 - val_loss: 0.6584 - val_accuracy: 0.6124\n",
      "Epoch 818/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7100 - accuracy: 0.5841 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 819/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7101 - accuracy: 0.5859 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 820/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7126 - accuracy: 0.5759 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 821/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7073 - accuracy: 0.5836 - val_loss: 0.6583 - val_accuracy: 0.6143\n",
      "Epoch 822/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7067 - accuracy: 0.5827 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 823/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7154 - accuracy: 0.5718 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 824/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7054 - accuracy: 0.5941 - val_loss: 0.6583 - val_accuracy: 0.6161\n",
      "Epoch 825/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7148 - accuracy: 0.5768 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 826/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7141 - accuracy: 0.5800 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 827/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7072 - accuracy: 0.5850 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 828/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6880 - accuracy: 0.5891 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 829/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7008 - accuracy: 0.5878 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 830/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6964 - accuracy: 0.5978 - val_loss: 0.6584 - val_accuracy: 0.6143\n",
      "Epoch 831/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7118 - accuracy: 0.5850 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 832/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7081 - accuracy: 0.5786 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 833/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7005 - accuracy: 0.5987 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 834/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7079 - accuracy: 0.5754 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 835/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7035 - accuracy: 0.5941 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 836/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7117 - accuracy: 0.5759 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 837/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7068 - accuracy: 0.5900 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 838/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7090 - accuracy: 0.5777 - val_loss: 0.6585 - val_accuracy: 0.6143\n",
      "Epoch 839/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7105 - accuracy: 0.5832 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 840/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7010 - accuracy: 0.5823 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 841/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7087 - accuracy: 0.5868 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 842/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7160 - accuracy: 0.5800 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 843/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7088 - accuracy: 0.5859 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 844/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7041 - accuracy: 0.5846 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 845/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7033 - accuracy: 0.5750 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 846/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7123 - accuracy: 0.5864 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 847/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6986 - accuracy: 0.5864 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 848/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7064 - accuracy: 0.5887 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 849/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7057 - accuracy: 0.5846 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 850/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7068 - accuracy: 0.5818 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 851/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6914 - accuracy: 0.5946 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 852/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7066 - accuracy: 0.5878 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 853/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6998 - accuracy: 0.5791 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 854/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7102 - accuracy: 0.5791 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 855/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7055 - accuracy: 0.5878 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 856/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6997 - accuracy: 0.6010 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 857/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7095 - accuracy: 0.5882 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 858/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7173 - accuracy: 0.5727 - val_loss: 0.6585 - val_accuracy: 0.6179\n",
      "Epoch 859/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7122 - accuracy: 0.5754 - val_loss: 0.6585 - val_accuracy: 0.6179\n",
      "Epoch 860/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6986 - accuracy: 0.5836 - val_loss: 0.6585 - val_accuracy: 0.6197\n",
      "Epoch 861/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6935 - accuracy: 0.6019 - val_loss: 0.6585 - val_accuracy: 0.6216\n",
      "Epoch 862/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7142 - accuracy: 0.5718 - val_loss: 0.6585 - val_accuracy: 0.6179\n",
      "Epoch 863/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7108 - accuracy: 0.5681 - val_loss: 0.6585 - val_accuracy: 0.6197\n",
      "Epoch 864/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7005 - accuracy: 0.6015 - val_loss: 0.6585 - val_accuracy: 0.6197\n",
      "Epoch 865/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7048 - accuracy: 0.5832 - val_loss: 0.6585 - val_accuracy: 0.6197\n",
      "Epoch 866/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7124 - accuracy: 0.5868 - val_loss: 0.6585 - val_accuracy: 0.6197\n",
      "Epoch 867/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6997 - accuracy: 0.5855 - val_loss: 0.6586 - val_accuracy: 0.6197\n",
      "Epoch 868/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7237 - accuracy: 0.5759 - val_loss: 0.6586 - val_accuracy: 0.6197\n",
      "Epoch 869/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6964 - accuracy: 0.5951 - val_loss: 0.6586 - val_accuracy: 0.6197\n",
      "Epoch 870/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6899 - accuracy: 0.5964 - val_loss: 0.6587 - val_accuracy: 0.6197\n",
      "Epoch 871/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7016 - accuracy: 0.5791 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 872/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7045 - accuracy: 0.5855 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 873/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7024 - accuracy: 0.5992 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 874/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7097 - accuracy: 0.5814 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 875/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7030 - accuracy: 0.5868 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 876/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7100 - accuracy: 0.5809 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 877/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7089 - accuracy: 0.5795 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 878/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6945 - accuracy: 0.5791 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 879/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6959 - accuracy: 0.5996 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 880/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7052 - accuracy: 0.6037 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 881/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7163 - accuracy: 0.5750 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 882/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7032 - accuracy: 0.5905 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 883/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7159 - accuracy: 0.5736 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 884/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7000 - accuracy: 0.6005 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 885/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7069 - accuracy: 0.5859 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 886/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7172 - accuracy: 0.5676 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 887/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6902 - accuracy: 0.5955 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 888/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6945 - accuracy: 0.5932 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 889/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6982 - accuracy: 0.5919 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 890/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6937 - accuracy: 0.5928 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 891/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7189 - accuracy: 0.5763 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 892/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6988 - accuracy: 0.5937 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 893/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6990 - accuracy: 0.6074 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 894/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6959 - accuracy: 0.5850 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 895/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6979 - accuracy: 0.5882 - val_loss: 0.6588 - val_accuracy: 0.6234\n",
      "Epoch 896/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7144 - accuracy: 0.5690 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 897/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6998 - accuracy: 0.5850 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 898/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7055 - accuracy: 0.5859 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 899/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7137 - accuracy: 0.5740 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 900/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6892 - accuracy: 0.5987 - val_loss: 0.6587 - val_accuracy: 0.6216\n",
      "Epoch 901/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7051 - accuracy: 0.5900 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 902/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6846 - accuracy: 0.6065 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 903/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7066 - accuracy: 0.5873 - val_loss: 0.6588 - val_accuracy: 0.6216\n",
      "Epoch 904/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7090 - accuracy: 0.5859 - val_loss: 0.6589 - val_accuracy: 0.6216\n",
      "Epoch 905/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6936 - accuracy: 0.5923 - val_loss: 0.6589 - val_accuracy: 0.6216\n",
      "Epoch 906/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7136 - accuracy: 0.5745 - val_loss: 0.6589 - val_accuracy: 0.6216\n",
      "Epoch 907/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7043 - accuracy: 0.5718 - val_loss: 0.6589 - val_accuracy: 0.6216\n",
      "Epoch 908/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6947 - accuracy: 0.5914 - val_loss: 0.6589 - val_accuracy: 0.6216\n",
      "Epoch 909/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6991 - accuracy: 0.5887 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 910/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7004 - accuracy: 0.5928 - val_loss: 0.6589 - val_accuracy: 0.6216\n",
      "Epoch 911/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7081 - accuracy: 0.5923 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 912/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6976 - accuracy: 0.5946 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 913/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7029 - accuracy: 0.5987 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 914/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7030 - accuracy: 0.5827 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 915/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7079 - accuracy: 0.5800 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 916/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6894 - accuracy: 0.5905 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 917/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7023 - accuracy: 0.5850 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 918/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6993 - accuracy: 0.5846 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 919/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6944 - accuracy: 0.6019 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 920/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7026 - accuracy: 0.5786 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 921/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7078 - accuracy: 0.5777 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 922/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7075 - accuracy: 0.5809 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 923/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6949 - accuracy: 0.5914 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 924/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7016 - accuracy: 0.5795 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 925/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7132 - accuracy: 0.5896 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 926/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7017 - accuracy: 0.5873 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 927/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6961 - accuracy: 0.5964 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 928/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6997 - accuracy: 0.5964 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 929/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6962 - accuracy: 0.5873 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 930/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7063 - accuracy: 0.5864 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 931/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6965 - accuracy: 0.5987 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 932/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7028 - accuracy: 0.5900 - val_loss: 0.6592 - val_accuracy: 0.6216\n",
      "Epoch 933/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7053 - accuracy: 0.5882 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 934/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6985 - accuracy: 0.5946 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 935/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6896 - accuracy: 0.5951 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 936/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6971 - accuracy: 0.6010 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 937/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7019 - accuracy: 0.5873 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 938/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7072 - accuracy: 0.5827 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 939/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6894 - accuracy: 0.6056 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 940/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6897 - accuracy: 0.5836 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 941/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6994 - accuracy: 0.5946 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 942/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7077 - accuracy: 0.5690 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 943/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7134 - accuracy: 0.5731 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 944/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6946 - accuracy: 0.5923 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 945/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7005 - accuracy: 0.5932 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 946/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6996 - accuracy: 0.5891 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 947/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7123 - accuracy: 0.5855 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 948/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.7059 - accuracy: 0.5896 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 949/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.7001 - accuracy: 0.5795 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 950/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7023 - accuracy: 0.5818 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 951/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6833 - accuracy: 0.5983 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 952/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7125 - accuracy: 0.5708 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 953/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7024 - accuracy: 0.5804 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 954/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6918 - accuracy: 0.5983 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 955/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7090 - accuracy: 0.5823 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 956/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7051 - accuracy: 0.5896 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 957/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7100 - accuracy: 0.5740 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 958/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6979 - accuracy: 0.5887 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 959/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7025 - accuracy: 0.5896 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 960/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6919 - accuracy: 0.5932 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 961/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6914 - accuracy: 0.5969 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 962/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6913 - accuracy: 0.5859 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 963/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7023 - accuracy: 0.5964 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 964/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.7079 - accuracy: 0.5864 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 965/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6987 - accuracy: 0.5836 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 966/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6914 - accuracy: 0.6037 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 967/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6948 - accuracy: 0.5814 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 968/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7033 - accuracy: 0.5777 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 969/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6890 - accuracy: 0.5896 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 970/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6996 - accuracy: 0.5928 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 971/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7201 - accuracy: 0.5722 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 972/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6954 - accuracy: 0.5919 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 973/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7074 - accuracy: 0.5960 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 974/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6938 - accuracy: 0.5996 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 975/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.7042 - accuracy: 0.5887 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 976/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7010 - accuracy: 0.5850 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 977/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7036 - accuracy: 0.5910 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 978/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.7046 - accuracy: 0.5900 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 979/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7077 - accuracy: 0.5960 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 980/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6933 - accuracy: 0.6042 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 981/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7066 - accuracy: 0.5759 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
      "Epoch 982/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6960 - accuracy: 0.5836 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 983/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7164 - accuracy: 0.5745 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 984/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6971 - accuracy: 0.5937 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 985/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7081 - accuracy: 0.5686 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 986/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6939 - accuracy: 0.5973 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 987/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6920 - accuracy: 0.5800 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 988/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7011 - accuracy: 0.5896 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 989/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6974 - accuracy: 0.5836 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 990/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6950 - accuracy: 0.5905 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 991/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6899 - accuracy: 0.6028 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 992/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.7024 - accuracy: 0.5846 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 993/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7020 - accuracy: 0.5932 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 994/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6994 - accuracy: 0.5873 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 995/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6952 - accuracy: 0.5868 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 996/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7094 - accuracy: 0.5777 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 997/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.7074 - accuracy: 0.5859 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 998/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6950 - accuracy: 0.5900 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 999/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6915 - accuracy: 0.5932 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 1000/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6856 - accuracy: 0.6033 - val_loss: 0.6592 - val_accuracy: 0.6197\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 750\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6954 - accuracy: 0.5992 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 2/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6970 - accuracy: 0.6015 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 3/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6933 - accuracy: 0.5855 - val_loss: 0.6591 - val_accuracy: 0.6197\n",
      "Epoch 4/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7050 - accuracy: 0.5800 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 5/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7049 - accuracy: 0.5923 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 6/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7013 - accuracy: 0.5864 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 7/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6969 - accuracy: 0.5873 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 8/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6939 - accuracy: 0.5983 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 9/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5955 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 10/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7044 - accuracy: 0.5882 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 11/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7123 - accuracy: 0.5708 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 12/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6995 - accuracy: 0.5873 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 13/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6988 - accuracy: 0.5868 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 14/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6891 - accuracy: 0.5955 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 15/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.7000 - accuracy: 0.5864 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 16/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7005 - accuracy: 0.5900 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 17/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7099 - accuracy: 0.5827 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 18/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.7028 - accuracy: 0.5878 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 19/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6894 - accuracy: 0.6015 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 20/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7074 - accuracy: 0.5786 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 21/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.7063 - accuracy: 0.5818 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 22/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6965 - accuracy: 0.5900 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 23/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7049 - accuracy: 0.5768 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 24/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6970 - accuracy: 0.5941 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 25/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6775 - accuracy: 0.6138 - val_loss: 0.6592 - val_accuracy: 0.6197\n",
      "Epoch 26/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.7013 - accuracy: 0.5800 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 27/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6999 - accuracy: 0.5841 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 28/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6920 - accuracy: 0.5946 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 29/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7023 - accuracy: 0.5836 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 30/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7018 - accuracy: 0.5795 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 31/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7020 - accuracy: 0.5846 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 32/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7058 - accuracy: 0.5832 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 33/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7044 - accuracy: 0.5955 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 34/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6935 - accuracy: 0.5923 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 35/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7078 - accuracy: 0.5855 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 36/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7022 - accuracy: 0.5786 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 37/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6996 - accuracy: 0.5964 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 38/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6962 - accuracy: 0.5914 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 39/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6926 - accuracy: 0.5969 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 40/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7064 - accuracy: 0.5804 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 41/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7014 - accuracy: 0.6015 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 42/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6987 - accuracy: 0.5850 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 43/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6932 - accuracy: 0.5841 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 44/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5795 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 45/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6976 - accuracy: 0.5914 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 46/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7116 - accuracy: 0.5708 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 47/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6960 - accuracy: 0.5983 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 48/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6976 - accuracy: 0.5932 - val_loss: 0.6593 - val_accuracy: 0.6197\n",
      "Epoch 49/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6861 - accuracy: 0.5919 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 50/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6913 - accuracy: 0.5996 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 51/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6929 - accuracy: 0.6010 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 52/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6962 - accuracy: 0.5951 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 53/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7026 - accuracy: 0.5873 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 54/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6827 - accuracy: 0.5987 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 55/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6998 - accuracy: 0.6001 - val_loss: 0.6594 - val_accuracy: 0.6197\n",
      "Epoch 56/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6965 - accuracy: 0.5923 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 57/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7018 - accuracy: 0.6060 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 58/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7047 - accuracy: 0.5832 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 59/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6851 - accuracy: 0.5964 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 60/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7094 - accuracy: 0.5823 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 61/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6948 - accuracy: 0.5960 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 62/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6875 - accuracy: 0.6037 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 63/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7017 - accuracy: 0.5814 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 64/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7205 - accuracy: 0.5740 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 65/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6935 - accuracy: 0.5923 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 66/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6955 - accuracy: 0.5763 - val_loss: 0.6595 - val_accuracy: 0.6197\n",
      "Epoch 67/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6889 - accuracy: 0.5923 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 68/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6845 - accuracy: 0.5910 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 69/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6984 - accuracy: 0.5873 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 70/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.7030 - accuracy: 0.5969 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 71/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6939 - accuracy: 0.5859 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 72/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7000 - accuracy: 0.5868 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 73/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6997 - accuracy: 0.5795 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 74/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6895 - accuracy: 0.6015 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 75/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6977 - accuracy: 0.5987 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 76/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6907 - accuracy: 0.5996 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 77/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7025 - accuracy: 0.5795 - val_loss: 0.6596 - val_accuracy: 0.6197\n",
      "Epoch 78/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7041 - accuracy: 0.5804 - val_loss: 0.6597 - val_accuracy: 0.6197\n",
      "Epoch 79/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6994 - accuracy: 0.5910 - val_loss: 0.6597 - val_accuracy: 0.6197\n",
      "Epoch 80/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6743 - accuracy: 0.6097 - val_loss: 0.6597 - val_accuracy: 0.6197\n",
      "Epoch 81/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7000 - accuracy: 0.5891 - val_loss: 0.6597 - val_accuracy: 0.6197\n",
      "Epoch 82/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6919 - accuracy: 0.5928 - val_loss: 0.6597 - val_accuracy: 0.6197\n",
      "Epoch 83/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7046 - accuracy: 0.5841 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 84/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7008 - accuracy: 0.5791 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 85/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7077 - accuracy: 0.5686 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 86/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6970 - accuracy: 0.5992 - val_loss: 0.6598 - val_accuracy: 0.6216\n",
      "Epoch 87/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6904 - accuracy: 0.5846 - val_loss: 0.6598 - val_accuracy: 0.6216\n",
      "Epoch 88/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6931 - accuracy: 0.5978 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 89/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6862 - accuracy: 0.5946 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 90/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6984 - accuracy: 0.5836 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 91/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6985 - accuracy: 0.5891 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 92/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6886 - accuracy: 0.6037 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 93/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6869 - accuracy: 0.5905 - val_loss: 0.6599 - val_accuracy: 0.6197\n",
      "Epoch 94/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6851 - accuracy: 0.6047 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 95/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7038 - accuracy: 0.5841 - val_loss: 0.6598 - val_accuracy: 0.6197\n",
      "Epoch 96/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7027 - accuracy: 0.5919 - val_loss: 0.6599 - val_accuracy: 0.6197\n",
      "Epoch 97/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7046 - accuracy: 0.5791 - val_loss: 0.6599 - val_accuracy: 0.6197\n",
      "Epoch 98/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6874 - accuracy: 0.5987 - val_loss: 0.6599 - val_accuracy: 0.6197\n",
      "Epoch 99/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7028 - accuracy: 0.5750 - val_loss: 0.6599 - val_accuracy: 0.6179\n",
      "Epoch 100/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6874 - accuracy: 0.6037 - val_loss: 0.6599 - val_accuracy: 0.6179\n",
      "Epoch 101/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6969 - accuracy: 0.5795 - val_loss: 0.6599 - val_accuracy: 0.6179\n",
      "Epoch 102/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6902 - accuracy: 0.5941 - val_loss: 0.6599 - val_accuracy: 0.6197\n",
      "Epoch 103/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6908 - accuracy: 0.5887 - val_loss: 0.6599 - val_accuracy: 0.6216\n",
      "Epoch 104/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6877 - accuracy: 0.6060 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 105/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7005 - accuracy: 0.5795 - val_loss: 0.6599 - val_accuracy: 0.6179\n",
      "Epoch 106/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6844 - accuracy: 0.5905 - val_loss: 0.6600 - val_accuracy: 0.6179\n",
      "Epoch 107/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6875 - accuracy: 0.6037 - val_loss: 0.6599 - val_accuracy: 0.6179\n",
      "Epoch 108/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7140 - accuracy: 0.5809 - val_loss: 0.6600 - val_accuracy: 0.6179\n",
      "Epoch 109/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6956 - accuracy: 0.6033 - val_loss: 0.6600 - val_accuracy: 0.6197\n",
      "Epoch 110/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6764 - accuracy: 0.6051 - val_loss: 0.6600 - val_accuracy: 0.6197\n",
      "Epoch 111/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6973 - accuracy: 0.5914 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 112/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6945 - accuracy: 0.5809 - val_loss: 0.6600 - val_accuracy: 0.6197\n",
      "Epoch 113/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6947 - accuracy: 0.5809 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 114/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6972 - accuracy: 0.5772 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 115/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6998 - accuracy: 0.6028 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 116/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6996 - accuracy: 0.5777 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 117/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6866 - accuracy: 0.6101 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 118/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6973 - accuracy: 0.5873 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 119/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.5969 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 120/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7002 - accuracy: 0.5846 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 121/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6992 - accuracy: 0.5855 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 122/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7020 - accuracy: 0.5800 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 123/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7034 - accuracy: 0.5827 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 124/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7002 - accuracy: 0.5978 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 125/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7000 - accuracy: 0.5919 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 126/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6994 - accuracy: 0.5946 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 127/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6882 - accuracy: 0.6065 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 128/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6883 - accuracy: 0.6047 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 129/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6898 - accuracy: 0.5951 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 130/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6838 - accuracy: 0.5951 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 131/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6948 - accuracy: 0.5905 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 132/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6921 - accuracy: 0.5859 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 133/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7022 - accuracy: 0.5878 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 134/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6804 - accuracy: 0.6056 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 135/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6860 - accuracy: 0.6024 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 136/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6920 - accuracy: 0.5928 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 137/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6909 - accuracy: 0.5960 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 138/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6866 - accuracy: 0.5983 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 139/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7068 - accuracy: 0.5818 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 140/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6945 - accuracy: 0.5795 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 141/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7018 - accuracy: 0.5809 - val_loss: 0.6602 - val_accuracy: 0.6216\n",
      "Epoch 142/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6936 - accuracy: 0.5932 - val_loss: 0.6602 - val_accuracy: 0.6216\n",
      "Epoch 143/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7005 - accuracy: 0.5804 - val_loss: 0.6602 - val_accuracy: 0.6216\n",
      "Epoch 144/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7029 - accuracy: 0.5823 - val_loss: 0.6602 - val_accuracy: 0.6216\n",
      "Epoch 145/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6996 - accuracy: 0.5960 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 146/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6919 - accuracy: 0.6015 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 147/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6944 - accuracy: 0.5804 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 148/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7070 - accuracy: 0.5772 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 149/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6747 - accuracy: 0.6088 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 150/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7126 - accuracy: 0.5750 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 151/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6845 - accuracy: 0.6079 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 152/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7057 - accuracy: 0.5891 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 153/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6877 - accuracy: 0.5960 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 154/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6871 - accuracy: 0.6024 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 155/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7061 - accuracy: 0.5923 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 156/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.7045 - accuracy: 0.5859 - val_loss: 0.6601 - val_accuracy: 0.6216\n",
      "Epoch 157/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6991 - accuracy: 0.5827 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 158/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7020 - accuracy: 0.5832 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 159/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6994 - accuracy: 0.5987 - val_loss: 0.6602 - val_accuracy: 0.6197\n",
      "Epoch 160/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6823 - accuracy: 0.6129 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 161/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.7070 - accuracy: 0.5777 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 162/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6835 - accuracy: 0.5882 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 163/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6845 - accuracy: 0.5928 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 164/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6994 - accuracy: 0.5750 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 165/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6904 - accuracy: 0.5823 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 166/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6923 - accuracy: 0.5978 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 167/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6811 - accuracy: 0.6060 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 168/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6973 - accuracy: 0.5878 - val_loss: 0.6601 - val_accuracy: 0.6197\n",
      "Epoch 169/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6938 - accuracy: 0.5896 - val_loss: 0.6602 - val_accuracy: 0.6179\n",
      "Epoch 170/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6947 - accuracy: 0.5896 - val_loss: 0.6602 - val_accuracy: 0.6179\n",
      "Epoch 171/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6959 - accuracy: 0.5804 - val_loss: 0.6602 - val_accuracy: 0.6179\n",
      "Epoch 172/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.6015 - val_loss: 0.6602 - val_accuracy: 0.6179\n",
      "Epoch 173/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6914 - accuracy: 0.5905 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 174/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6982 - accuracy: 0.5919 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 175/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6842 - accuracy: 0.6024 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 176/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6978 - accuracy: 0.5891 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 177/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5836 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 178/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6867 - accuracy: 0.5905 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 179/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6760 - accuracy: 0.6120 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 180/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6981 - accuracy: 0.5786 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 181/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6871 - accuracy: 0.6069 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 182/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6886 - accuracy: 0.5937 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 183/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6935 - accuracy: 0.6033 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 184/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6893 - accuracy: 0.5910 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 185/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6901 - accuracy: 0.5891 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 186/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6898 - accuracy: 0.5868 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 187/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7035 - accuracy: 0.5681 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 188/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6837 - accuracy: 0.6001 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 189/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6772 - accuracy: 0.6101 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 190/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5896 - val_loss: 0.6603 - val_accuracy: 0.6179\n",
      "Epoch 191/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6948 - accuracy: 0.5864 - val_loss: 0.6604 - val_accuracy: 0.6179\n",
      "Epoch 192/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7023 - accuracy: 0.5873 - val_loss: 0.6604 - val_accuracy: 0.6179\n",
      "Epoch 193/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6900 - accuracy: 0.5941 - val_loss: 0.6604 - val_accuracy: 0.6179\n",
      "Epoch 194/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6853 - accuracy: 0.6037 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 195/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6879 - accuracy: 0.6015 - val_loss: 0.6604 - val_accuracy: 0.6179\n",
      "Epoch 196/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6896 - accuracy: 0.5969 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 197/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6886 - accuracy: 0.6028 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 198/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7028 - accuracy: 0.5855 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 199/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6896 - accuracy: 0.5992 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 200/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6970 - accuracy: 0.5850 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 201/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6990 - accuracy: 0.5882 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 202/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6860 - accuracy: 0.5969 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 203/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6907 - accuracy: 0.5996 - val_loss: 0.6605 - val_accuracy: 0.6179\n",
      "Epoch 204/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6861 - accuracy: 0.5992 - val_loss: 0.6606 - val_accuracy: 0.6179\n",
      "Epoch 205/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6947 - accuracy: 0.5923 - val_loss: 0.6606 - val_accuracy: 0.6179\n",
      "Epoch 206/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6829 - accuracy: 0.5941 - val_loss: 0.6606 - val_accuracy: 0.6179\n",
      "Epoch 207/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6827 - accuracy: 0.5996 - val_loss: 0.6606 - val_accuracy: 0.6179\n",
      "Epoch 208/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6733 - accuracy: 0.6106 - val_loss: 0.6606 - val_accuracy: 0.6179\n",
      "Epoch 209/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6772 - accuracy: 0.6124 - val_loss: 0.6606 - val_accuracy: 0.6179\n",
      "Epoch 210/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6887 - accuracy: 0.5850 - val_loss: 0.6606 - val_accuracy: 0.6179\n",
      "Epoch 211/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6890 - accuracy: 0.5923 - val_loss: 0.6606 - val_accuracy: 0.6216\n",
      "Epoch 212/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7070 - accuracy: 0.5809 - val_loss: 0.6606 - val_accuracy: 0.6216\n",
      "Epoch 213/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6956 - accuracy: 0.5832 - val_loss: 0.6606 - val_accuracy: 0.6216\n",
      "Epoch 214/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6828 - accuracy: 0.5983 - val_loss: 0.6606 - val_accuracy: 0.6197\n",
      "Epoch 215/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6958 - accuracy: 0.6005 - val_loss: 0.6606 - val_accuracy: 0.6216\n",
      "Epoch 216/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.7061 - accuracy: 0.5814 - val_loss: 0.6607 - val_accuracy: 0.6216\n",
      "Epoch 217/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6858 - accuracy: 0.5969 - val_loss: 0.6607 - val_accuracy: 0.6216\n",
      "Epoch 218/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6912 - accuracy: 0.5850 - val_loss: 0.6607 - val_accuracy: 0.6216\n",
      "Epoch 219/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7009 - accuracy: 0.5859 - val_loss: 0.6607 - val_accuracy: 0.6216\n",
      "Epoch 220/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6954 - accuracy: 0.5964 - val_loss: 0.6607 - val_accuracy: 0.6216\n",
      "Epoch 221/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6934 - accuracy: 0.6047 - val_loss: 0.6607 - val_accuracy: 0.6216\n",
      "Epoch 222/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6845 - accuracy: 0.6115 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 223/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6944 - accuracy: 0.5964 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 224/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6912 - accuracy: 0.5955 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 225/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6895 - accuracy: 0.5891 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 226/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6883 - accuracy: 0.5864 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 227/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6945 - accuracy: 0.5859 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 228/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6920 - accuracy: 0.5905 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 229/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7056 - accuracy: 0.5919 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 230/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6882 - accuracy: 0.5987 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 231/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6925 - accuracy: 0.6001 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 232/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6945 - accuracy: 0.5873 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 233/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6912 - accuracy: 0.5987 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 234/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6954 - accuracy: 0.5900 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 235/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6949 - accuracy: 0.5900 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 236/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6798 - accuracy: 0.6010 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 237/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6825 - accuracy: 0.5951 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 238/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6870 - accuracy: 0.5964 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 239/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6960 - accuracy: 0.5891 - val_loss: 0.6608 - val_accuracy: 0.6216\n",
      "Epoch 240/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6894 - accuracy: 0.6056 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 241/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6867 - accuracy: 0.5978 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 242/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6826 - accuracy: 0.5932 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 243/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6795 - accuracy: 0.6056 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 244/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6891 - accuracy: 0.5937 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 245/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6974 - accuracy: 0.5754 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 246/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6849 - accuracy: 0.5804 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 247/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6920 - accuracy: 0.5891 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 248/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.5964 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 249/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6979 - accuracy: 0.5864 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 250/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6881 - accuracy: 0.6028 - val_loss: 0.6610 - val_accuracy: 0.6216\n",
      "Epoch 251/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6875 - accuracy: 0.5987 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 252/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6786 - accuracy: 0.6001 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 253/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7031 - accuracy: 0.5850 - val_loss: 0.6609 - val_accuracy: 0.6216\n",
      "Epoch 254/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6874 - accuracy: 0.5910 - val_loss: 0.6610 - val_accuracy: 0.6216\n",
      "Epoch 255/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6885 - accuracy: 0.5896 - val_loss: 0.6610 - val_accuracy: 0.6216\n",
      "Epoch 256/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6920 - accuracy: 0.5891 - val_loss: 0.6610 - val_accuracy: 0.6216\n",
      "Epoch 257/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6989 - accuracy: 0.5914 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 258/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6984 - accuracy: 0.5946 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 259/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6982 - accuracy: 0.5795 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 260/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6931 - accuracy: 0.6001 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 261/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6953 - accuracy: 0.5850 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 262/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6911 - accuracy: 0.5960 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 263/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6974 - accuracy: 0.5804 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 264/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7073 - accuracy: 0.5868 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 265/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6816 - accuracy: 0.5941 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 266/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6896 - accuracy: 0.5960 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 267/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6950 - accuracy: 0.6047 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 268/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7035 - accuracy: 0.5859 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 269/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6996 - accuracy: 0.5804 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 270/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6973 - accuracy: 0.5941 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 271/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6881 - accuracy: 0.5910 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 272/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6918 - accuracy: 0.5919 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 273/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6882 - accuracy: 0.6056 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 274/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6911 - accuracy: 0.5941 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 275/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6735 - accuracy: 0.6042 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 276/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6794 - accuracy: 0.6133 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 277/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6936 - accuracy: 0.5786 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 278/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6956 - accuracy: 0.5923 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 279/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6870 - accuracy: 0.5850 - val_loss: 0.6611 - val_accuracy: 0.6216\n",
      "Epoch 280/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6921 - accuracy: 0.5914 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 281/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7026 - accuracy: 0.5864 - val_loss: 0.6613 - val_accuracy: 0.6216\n",
      "Epoch 282/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.7011 - accuracy: 0.5827 - val_loss: 0.6613 - val_accuracy: 0.6216\n",
      "Epoch 283/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6847 - accuracy: 0.5973 - val_loss: 0.6612 - val_accuracy: 0.6216\n",
      "Epoch 284/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6932 - accuracy: 0.5983 - val_loss: 0.6613 - val_accuracy: 0.6216\n",
      "Epoch 285/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6961 - accuracy: 0.5900 - val_loss: 0.6613 - val_accuracy: 0.6216\n",
      "Epoch 286/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6945 - accuracy: 0.5923 - val_loss: 0.6613 - val_accuracy: 0.6216\n",
      "Epoch 287/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6953 - accuracy: 0.5818 - val_loss: 0.6613 - val_accuracy: 0.6216\n",
      "Epoch 288/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6877 - accuracy: 0.6001 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 289/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6767 - accuracy: 0.6047 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 290/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6833 - accuracy: 0.6024 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 291/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6775 - accuracy: 0.6047 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 292/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6938 - accuracy: 0.5878 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 293/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6892 - accuracy: 0.5955 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 294/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6902 - accuracy: 0.5887 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 295/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6888 - accuracy: 0.5887 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 296/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6965 - accuracy: 0.5914 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 297/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6938 - accuracy: 0.5987 - val_loss: 0.6615 - val_accuracy: 0.6216\n",
      "Epoch 298/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6871 - accuracy: 0.5900 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 299/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6784 - accuracy: 0.6005 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 300/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6929 - accuracy: 0.5919 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 301/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6915 - accuracy: 0.5992 - val_loss: 0.6614 - val_accuracy: 0.6216\n",
      "Epoch 302/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7029 - accuracy: 0.5827 - val_loss: 0.6615 - val_accuracy: 0.6234\n",
      "Epoch 303/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6868 - accuracy: 0.5983 - val_loss: 0.6615 - val_accuracy: 0.6216\n",
      "Epoch 304/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6921 - accuracy: 0.5782 - val_loss: 0.6616 - val_accuracy: 0.6216\n",
      "Epoch 305/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6828 - accuracy: 0.5896 - val_loss: 0.6616 - val_accuracy: 0.6216\n",
      "Epoch 306/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6935 - accuracy: 0.5941 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 307/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6924 - accuracy: 0.5864 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 308/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7014 - accuracy: 0.5891 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 309/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6850 - accuracy: 0.5983 - val_loss: 0.6617 - val_accuracy: 0.6234\n",
      "Epoch 310/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7029 - accuracy: 0.5928 - val_loss: 0.6617 - val_accuracy: 0.6234\n",
      "Epoch 311/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6879 - accuracy: 0.5951 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 312/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6860 - accuracy: 0.6047 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 313/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6904 - accuracy: 0.5932 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 314/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6837 - accuracy: 0.6056 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 315/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6810 - accuracy: 0.6097 - val_loss: 0.6617 - val_accuracy: 0.6234\n",
      "Epoch 316/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6915 - accuracy: 0.5905 - val_loss: 0.6617 - val_accuracy: 0.6234\n",
      "Epoch 317/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6888 - accuracy: 0.5910 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 318/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6853 - accuracy: 0.5992 - val_loss: 0.6617 - val_accuracy: 0.6234\n",
      "Epoch 319/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6945 - accuracy: 0.5850 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
      "Epoch 320/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6931 - accuracy: 0.5896 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 321/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6907 - accuracy: 0.5951 - val_loss: 0.6618 - val_accuracy: 0.6234\n",
      "Epoch 322/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6902 - accuracy: 0.5923 - val_loss: 0.6618 - val_accuracy: 0.6234\n",
      "Epoch 323/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6860 - accuracy: 0.6033 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 324/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.7026 - accuracy: 0.5823 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 325/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6837 - accuracy: 0.5992 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 326/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6941 - accuracy: 0.5887 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 327/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6973 - accuracy: 0.5964 - val_loss: 0.6618 - val_accuracy: 0.6234\n",
      "Epoch 328/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6828 - accuracy: 0.6051 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 329/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6872 - accuracy: 0.5937 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 330/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6818 - accuracy: 0.6015 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 331/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6929 - accuracy: 0.5987 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 332/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6806 - accuracy: 0.5983 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 333/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6774 - accuracy: 0.6037 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 334/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6897 - accuracy: 0.5951 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 335/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.7042 - accuracy: 0.5777 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 336/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6849 - accuracy: 0.5996 - val_loss: 0.6618 - val_accuracy: 0.6216\n",
      "Epoch 337/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6786 - accuracy: 0.6111 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 338/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6893 - accuracy: 0.5914 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 339/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6763 - accuracy: 0.6019 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 340/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6894 - accuracy: 0.5973 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 341/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6895 - accuracy: 0.6028 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 342/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6890 - accuracy: 0.5992 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 343/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6893 - accuracy: 0.5937 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 344/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6933 - accuracy: 0.5973 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 345/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6908 - accuracy: 0.5768 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 346/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6875 - accuracy: 0.5996 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 347/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6834 - accuracy: 0.6047 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 348/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6872 - accuracy: 0.5987 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 349/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6955 - accuracy: 0.5896 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 350/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6941 - accuracy: 0.5951 - val_loss: 0.6621 - val_accuracy: 0.6216\n",
      "Epoch 351/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6844 - accuracy: 0.6074 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 352/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6914 - accuracy: 0.5914 - val_loss: 0.6621 - val_accuracy: 0.6216\n",
      "Epoch 353/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6767 - accuracy: 0.6197 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 354/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6862 - accuracy: 0.6069 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 355/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6959 - accuracy: 0.5841 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 356/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6818 - accuracy: 0.6083 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 357/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6921 - accuracy: 0.5750 - val_loss: 0.6620 - val_accuracy: 0.6234\n",
      "Epoch 358/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6891 - accuracy: 0.5973 - val_loss: 0.6620 - val_accuracy: 0.6234\n",
      "Epoch 359/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6794 - accuracy: 0.6060 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 360/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6758 - accuracy: 0.6042 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 361/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6870 - accuracy: 0.6074 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 362/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6829 - accuracy: 0.5964 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 363/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6802 - accuracy: 0.6033 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 364/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6883 - accuracy: 0.5964 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 365/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6979 - accuracy: 0.5910 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 366/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6843 - accuracy: 0.6047 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 367/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6816 - accuracy: 0.6010 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 368/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6756 - accuracy: 0.6184 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 369/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6914 - accuracy: 0.5923 - val_loss: 0.6620 - val_accuracy: 0.6234\n",
      "Epoch 370/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6893 - accuracy: 0.6047 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 371/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6865 - accuracy: 0.5841 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 372/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6941 - accuracy: 0.5919 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 373/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6907 - accuracy: 0.5827 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 374/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6899 - accuracy: 0.5964 - val_loss: 0.6619 - val_accuracy: 0.6234\n",
      "Epoch 375/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6854 - accuracy: 0.6019 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 376/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6965 - accuracy: 0.5864 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 377/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6834 - accuracy: 0.6024 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 378/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6799 - accuracy: 0.6033 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 379/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6952 - accuracy: 0.5905 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 380/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6917 - accuracy: 0.5900 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 381/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6897 - accuracy: 0.5919 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 382/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6976 - accuracy: 0.5873 - val_loss: 0.6620 - val_accuracy: 0.6216\n",
      "Epoch 383/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6808 - accuracy: 0.6129 - val_loss: 0.6621 - val_accuracy: 0.6216\n",
      "Epoch 384/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6929 - accuracy: 0.5873 - val_loss: 0.6621 - val_accuracy: 0.6234\n",
      "Epoch 385/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6941 - accuracy: 0.5973 - val_loss: 0.6621 - val_accuracy: 0.6234\n",
      "Epoch 386/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6800 - accuracy: 0.6079 - val_loss: 0.6621 - val_accuracy: 0.6216\n",
      "Epoch 387/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6845 - accuracy: 0.6033 - val_loss: 0.6621 - val_accuracy: 0.6234\n",
      "Epoch 388/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6897 - accuracy: 0.5946 - val_loss: 0.6621 - val_accuracy: 0.6234\n",
      "Epoch 389/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6836 - accuracy: 0.6001 - val_loss: 0.6621 - val_accuracy: 0.6234\n",
      "Epoch 390/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6907 - accuracy: 0.5868 - val_loss: 0.6621 - val_accuracy: 0.6234\n",
      "Epoch 391/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6716 - accuracy: 0.6120 - val_loss: 0.6622 - val_accuracy: 0.6234\n",
      "Epoch 392/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6781 - accuracy: 0.6005 - val_loss: 0.6622 - val_accuracy: 0.6234\n",
      "Epoch 393/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6904 - accuracy: 0.6005 - val_loss: 0.6622 - val_accuracy: 0.6216\n",
      "Epoch 394/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6953 - accuracy: 0.5955 - val_loss: 0.6622 - val_accuracy: 0.6216\n",
      "Epoch 395/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6965 - accuracy: 0.5919 - val_loss: 0.6622 - val_accuracy: 0.6216\n",
      "Epoch 396/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6915 - accuracy: 0.5937 - val_loss: 0.6622 - val_accuracy: 0.6216\n",
      "Epoch 397/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6837 - accuracy: 0.6001 - val_loss: 0.6622 - val_accuracy: 0.6216\n",
      "Epoch 398/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6949 - accuracy: 0.5905 - val_loss: 0.6622 - val_accuracy: 0.6216\n",
      "Epoch 399/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6888 - accuracy: 0.5978 - val_loss: 0.6623 - val_accuracy: 0.6216\n",
      "Epoch 400/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6866 - accuracy: 0.5955 - val_loss: 0.6623 - val_accuracy: 0.6216\n",
      "Epoch 401/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6897 - accuracy: 0.6010 - val_loss: 0.6623 - val_accuracy: 0.6216\n",
      "Epoch 402/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6834 - accuracy: 0.5914 - val_loss: 0.6623 - val_accuracy: 0.6216\n",
      "Epoch 403/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6766 - accuracy: 0.6037 - val_loss: 0.6623 - val_accuracy: 0.6234\n",
      "Epoch 404/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6697 - accuracy: 0.6060 - val_loss: 0.6622 - val_accuracy: 0.6234\n",
      "Epoch 405/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6836 - accuracy: 0.6042 - val_loss: 0.6622 - val_accuracy: 0.6234\n",
      "Epoch 406/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6769 - accuracy: 0.6133 - val_loss: 0.6622 - val_accuracy: 0.6234\n",
      "Epoch 407/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6789 - accuracy: 0.6138 - val_loss: 0.6623 - val_accuracy: 0.6234\n",
      "Epoch 408/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6843 - accuracy: 0.5955 - val_loss: 0.6622 - val_accuracy: 0.6234\n",
      "Epoch 409/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6866 - accuracy: 0.5964 - val_loss: 0.6623 - val_accuracy: 0.6234\n",
      "Epoch 410/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6905 - accuracy: 0.5955 - val_loss: 0.6623 - val_accuracy: 0.6234\n",
      "Epoch 411/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6884 - accuracy: 0.6092 - val_loss: 0.6623 - val_accuracy: 0.6234\n",
      "Epoch 412/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6850 - accuracy: 0.6019 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 413/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.7079 - accuracy: 0.5859 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 414/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6819 - accuracy: 0.5960 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 415/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6937 - accuracy: 0.5823 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 416/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6797 - accuracy: 0.6051 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 417/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6947 - accuracy: 0.5919 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 418/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6736 - accuracy: 0.6069 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 419/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6831 - accuracy: 0.5996 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 420/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6879 - accuracy: 0.5905 - val_loss: 0.6625 - val_accuracy: 0.6234\n",
      "Epoch 421/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6781 - accuracy: 0.5955 - val_loss: 0.6625 - val_accuracy: 0.6234\n",
      "Epoch 422/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6721 - accuracy: 0.6124 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 423/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6868 - accuracy: 0.5823 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 424/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6985 - accuracy: 0.5900 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 425/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6866 - accuracy: 0.6010 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 426/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6905 - accuracy: 0.5905 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 427/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6798 - accuracy: 0.6010 - val_loss: 0.6624 - val_accuracy: 0.6234\n",
      "Epoch 428/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.7049 - accuracy: 0.5818 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 429/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6919 - accuracy: 0.5983 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 430/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6809 - accuracy: 0.6037 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 431/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6908 - accuracy: 0.5937 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 432/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6883 - accuracy: 0.6024 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 433/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6838 - accuracy: 0.6010 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 434/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6917 - accuracy: 0.5900 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 435/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6948 - accuracy: 0.6019 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 436/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6847 - accuracy: 0.6079 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 437/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6864 - accuracy: 0.5914 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 438/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6807 - accuracy: 0.6101 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 439/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6947 - accuracy: 0.5951 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 440/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6871 - accuracy: 0.5996 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 441/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6990 - accuracy: 0.5846 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 442/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6830 - accuracy: 0.5932 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 443/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6917 - accuracy: 0.5772 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 444/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6895 - accuracy: 0.5919 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 445/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6893 - accuracy: 0.5873 - val_loss: 0.6626 - val_accuracy: 0.6216\n",
      "Epoch 446/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6904 - accuracy: 0.5973 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 447/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6708 - accuracy: 0.6033 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 448/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6875 - accuracy: 0.5882 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 449/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6844 - accuracy: 0.5914 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 450/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6911 - accuracy: 0.5955 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 451/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6749 - accuracy: 0.6065 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 452/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6810 - accuracy: 0.6015 - val_loss: 0.6624 - val_accuracy: 0.6216\n",
      "Epoch 453/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6752 - accuracy: 0.6074 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 454/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6842 - accuracy: 0.6015 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 455/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6705 - accuracy: 0.6156 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 456/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6907 - accuracy: 0.5864 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 457/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6954 - accuracy: 0.5882 - val_loss: 0.6626 - val_accuracy: 0.6216\n",
      "Epoch 458/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7045 - accuracy: 0.5818 - val_loss: 0.6626 - val_accuracy: 0.6216\n",
      "Epoch 459/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6719 - accuracy: 0.6106 - val_loss: 0.6626 - val_accuracy: 0.6216\n",
      "Epoch 460/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6938 - accuracy: 0.5951 - val_loss: 0.6626 - val_accuracy: 0.6216\n",
      "Epoch 461/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6923 - accuracy: 0.5868 - val_loss: 0.6626 - val_accuracy: 0.6216\n",
      "Epoch 462/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6828 - accuracy: 0.5973 - val_loss: 0.6626 - val_accuracy: 0.6216\n",
      "Epoch 463/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6954 - accuracy: 0.5983 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 464/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6818 - accuracy: 0.5960 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 465/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6890 - accuracy: 0.5855 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 466/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6745 - accuracy: 0.6115 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 467/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6757 - accuracy: 0.6083 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 468/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6835 - accuracy: 0.5937 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 469/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6810 - accuracy: 0.5964 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 470/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6920 - accuracy: 0.5973 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 471/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6895 - accuracy: 0.5992 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 472/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7039 - accuracy: 0.5896 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 473/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6951 - accuracy: 0.5905 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 474/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6756 - accuracy: 0.5983 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 475/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6867 - accuracy: 0.5928 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 476/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6954 - accuracy: 0.5923 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 477/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6907 - accuracy: 0.6065 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 478/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6853 - accuracy: 0.5960 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 479/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6975 - accuracy: 0.5955 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 480/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6848 - accuracy: 0.6028 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 481/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6999 - accuracy: 0.5882 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 482/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6864 - accuracy: 0.5973 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 483/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6909 - accuracy: 0.6005 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 484/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5951 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 485/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6810 - accuracy: 0.5978 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 486/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6795 - accuracy: 0.6056 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 487/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6851 - accuracy: 0.5905 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 488/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6880 - accuracy: 0.6001 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 489/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6853 - accuracy: 0.5955 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 490/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6929 - accuracy: 0.5983 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 491/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6947 - accuracy: 0.5750 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 492/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6736 - accuracy: 0.6193 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 493/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6863 - accuracy: 0.5910 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 494/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6879 - accuracy: 0.6037 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 495/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6852 - accuracy: 0.6019 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 496/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.7037 - accuracy: 0.5964 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 497/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6680 - accuracy: 0.6165 - val_loss: 0.6628 - val_accuracy: 0.6216\n",
      "Epoch 498/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6912 - accuracy: 0.5859 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 499/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6890 - accuracy: 0.5987 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 500/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6814 - accuracy: 0.6019 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 501/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6971 - accuracy: 0.5987 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 502/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6886 - accuracy: 0.5914 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 503/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6858 - accuracy: 0.6092 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 504/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6912 - accuracy: 0.5873 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 505/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6877 - accuracy: 0.5951 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 506/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6772 - accuracy: 0.6051 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 507/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6933 - accuracy: 0.5996 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 508/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6923 - accuracy: 0.5937 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 509/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6858 - accuracy: 0.6005 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 510/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6899 - accuracy: 0.5887 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 511/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6855 - accuracy: 0.6074 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 512/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6839 - accuracy: 0.5987 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 513/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6833 - accuracy: 0.6065 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 514/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6767 - accuracy: 0.6065 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 515/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6948 - accuracy: 0.5841 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 516/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6846 - accuracy: 0.5932 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 517/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6753 - accuracy: 0.5973 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 518/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6829 - accuracy: 0.5973 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 519/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.7001 - accuracy: 0.5818 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 520/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6949 - accuracy: 0.5937 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 521/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6956 - accuracy: 0.5905 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 522/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6923 - accuracy: 0.5873 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 523/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6830 - accuracy: 0.5978 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 524/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6922 - accuracy: 0.5919 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 525/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6822 - accuracy: 0.6056 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 526/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6848 - accuracy: 0.6069 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 527/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6825 - accuracy: 0.6033 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 528/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6793 - accuracy: 0.5891 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 529/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6762 - accuracy: 0.6092 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 530/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6866 - accuracy: 0.6051 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 531/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6828 - accuracy: 0.6079 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 532/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6757 - accuracy: 0.5996 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 533/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6873 - accuracy: 0.6019 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 534/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6843 - accuracy: 0.6083 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 535/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6792 - accuracy: 0.6056 - val_loss: 0.6629 - val_accuracy: 0.6216\n",
      "Epoch 536/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6785 - accuracy: 0.5973 - val_loss: 0.6630 - val_accuracy: 0.6216\n",
      "Epoch 537/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6821 - accuracy: 0.5987 - val_loss: 0.6629 - val_accuracy: 0.6234\n",
      "Epoch 538/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6774 - accuracy: 0.5937 - val_loss: 0.6629 - val_accuracy: 0.6234\n",
      "Epoch 539/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6867 - accuracy: 0.5882 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 540/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6866 - accuracy: 0.5951 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 541/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6993 - accuracy: 0.5791 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 542/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6757 - accuracy: 0.5992 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 543/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6827 - accuracy: 0.5973 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 544/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6811 - accuracy: 0.6010 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 545/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6756 - accuracy: 0.6065 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 546/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6788 - accuracy: 0.6065 - val_loss: 0.6630 - val_accuracy: 0.6234\n",
      "Epoch 547/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6885 - accuracy: 0.5941 - val_loss: 0.6631 - val_accuracy: 0.6234\n",
      "Epoch 548/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6932 - accuracy: 0.5832 - val_loss: 0.6631 - val_accuracy: 0.6234\n",
      "Epoch 549/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6864 - accuracy: 0.5987 - val_loss: 0.6631 - val_accuracy: 0.6234\n",
      "Epoch 550/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6844 - accuracy: 0.6065 - val_loss: 0.6631 - val_accuracy: 0.6234\n",
      "Epoch 551/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6839 - accuracy: 0.5941 - val_loss: 0.6631 - val_accuracy: 0.6234\n",
      "Epoch 552/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6885 - accuracy: 0.5955 - val_loss: 0.6631 - val_accuracy: 0.6234\n",
      "Epoch 553/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6824 - accuracy: 0.6024 - val_loss: 0.6631 - val_accuracy: 0.6234\n",
      "Epoch 554/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6881 - accuracy: 0.5864 - val_loss: 0.6632 - val_accuracy: 0.6234\n",
      "Epoch 555/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6864 - accuracy: 0.5978 - val_loss: 0.6632 - val_accuracy: 0.6234\n",
      "Epoch 556/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6868 - accuracy: 0.5955 - val_loss: 0.6633 - val_accuracy: 0.6234\n",
      "Epoch 557/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6971 - accuracy: 0.5873 - val_loss: 0.6633 - val_accuracy: 0.6234\n",
      "Epoch 558/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6767 - accuracy: 0.5973 - val_loss: 0.6633 - val_accuracy: 0.6234\n",
      "Epoch 559/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6810 - accuracy: 0.5978 - val_loss: 0.6633 - val_accuracy: 0.6234\n",
      "Epoch 560/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6791 - accuracy: 0.6033 - val_loss: 0.6634 - val_accuracy: 0.6234\n",
      "Epoch 561/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6703 - accuracy: 0.6156 - val_loss: 0.6634 - val_accuracy: 0.6234\n",
      "Epoch 562/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6763 - accuracy: 0.6097 - val_loss: 0.6634 - val_accuracy: 0.6234\n",
      "Epoch 563/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6905 - accuracy: 0.5795 - val_loss: 0.6634 - val_accuracy: 0.6234\n",
      "Epoch 564/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6886 - accuracy: 0.5887 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 565/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6822 - accuracy: 0.6111 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 566/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6853 - accuracy: 0.5987 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 567/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6827 - accuracy: 0.6015 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 568/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6768 - accuracy: 0.5987 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 569/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6902 - accuracy: 0.5914 - val_loss: 0.6635 - val_accuracy: 0.6216\n",
      "Epoch 570/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6950 - accuracy: 0.6015 - val_loss: 0.6636 - val_accuracy: 0.6216\n",
      "Epoch 571/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6667 - accuracy: 0.6133 - val_loss: 0.6635 - val_accuracy: 0.6216\n",
      "Epoch 572/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6775 - accuracy: 0.6088 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 573/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6730 - accuracy: 0.6037 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 574/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6874 - accuracy: 0.5941 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 575/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6916 - accuracy: 0.5964 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 576/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6903 - accuracy: 0.5887 - val_loss: 0.6635 - val_accuracy: 0.6234\n",
      "Epoch 577/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6853 - accuracy: 0.5973 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 578/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6767 - accuracy: 0.6056 - val_loss: 0.6636 - val_accuracy: 0.6216\n",
      "Epoch 579/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6933 - accuracy: 0.5969 - val_loss: 0.6636 - val_accuracy: 0.6216\n",
      "Epoch 580/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6950 - accuracy: 0.6001 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 581/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6845 - accuracy: 0.5941 - val_loss: 0.6636 - val_accuracy: 0.6216\n",
      "Epoch 582/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6859 - accuracy: 0.5987 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 583/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6776 - accuracy: 0.6101 - val_loss: 0.6637 - val_accuracy: 0.6216\n",
      "Epoch 584/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6807 - accuracy: 0.6047 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 585/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6842 - accuracy: 0.6024 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 586/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6731 - accuracy: 0.6088 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 587/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6886 - accuracy: 0.5973 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 588/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6902 - accuracy: 0.5896 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 589/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6847 - accuracy: 0.5969 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 590/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6851 - accuracy: 0.5900 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 591/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6807 - accuracy: 0.6037 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 592/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6991 - accuracy: 0.5900 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 593/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6855 - accuracy: 0.5964 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 594/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6801 - accuracy: 0.6097 - val_loss: 0.6636 - val_accuracy: 0.6234\n",
      "Epoch 595/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6828 - accuracy: 0.6015 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 596/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6842 - accuracy: 0.5978 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 597/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6819 - accuracy: 0.5951 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 598/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6789 - accuracy: 0.5937 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 599/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6827 - accuracy: 0.6037 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 600/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6765 - accuracy: 0.5964 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 601/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6868 - accuracy: 0.5932 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 602/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6901 - accuracy: 0.6051 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 603/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6761 - accuracy: 0.6106 - val_loss: 0.6637 - val_accuracy: 0.6234\n",
      "Epoch 604/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6998 - accuracy: 0.5928 - val_loss: 0.6637 - val_accuracy: 0.6216\n",
      "Epoch 605/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6824 - accuracy: 0.6015 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 606/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6777 - accuracy: 0.6101 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 607/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6872 - accuracy: 0.5878 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 608/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6814 - accuracy: 0.6069 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 609/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6735 - accuracy: 0.6019 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 610/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6901 - accuracy: 0.5928 - val_loss: 0.6638 - val_accuracy: 0.6197\n",
      "Epoch 611/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6896 - accuracy: 0.5983 - val_loss: 0.6638 - val_accuracy: 0.6197\n",
      "Epoch 612/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6746 - accuracy: 0.6010 - val_loss: 0.6638 - val_accuracy: 0.6197\n",
      "Epoch 613/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6730 - accuracy: 0.6060 - val_loss: 0.6637 - val_accuracy: 0.6197\n",
      "Epoch 614/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6920 - accuracy: 0.6010 - val_loss: 0.6638 - val_accuracy: 0.6197\n",
      "Epoch 615/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6916 - accuracy: 0.6060 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 616/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6810 - accuracy: 0.5887 - val_loss: 0.6638 - val_accuracy: 0.6197\n",
      "Epoch 617/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6820 - accuracy: 0.5964 - val_loss: 0.6638 - val_accuracy: 0.6197\n",
      "Epoch 618/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6929 - accuracy: 0.5932 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 619/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6829 - accuracy: 0.6028 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 620/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6912 - accuracy: 0.6001 - val_loss: 0.6638 - val_accuracy: 0.6216\n",
      "Epoch 621/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6941 - accuracy: 0.5846 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 622/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6797 - accuracy: 0.6028 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 623/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6707 - accuracy: 0.6092 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 624/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6829 - accuracy: 0.5992 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 625/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6817 - accuracy: 0.6001 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 626/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6852 - accuracy: 0.5960 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 627/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6773 - accuracy: 0.6037 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 628/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6822 - accuracy: 0.6092 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 629/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6864 - accuracy: 0.6033 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 630/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6854 - accuracy: 0.5969 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 631/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6705 - accuracy: 0.6184 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 632/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6834 - accuracy: 0.6074 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 633/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6819 - accuracy: 0.5941 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 634/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6828 - accuracy: 0.5905 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 635/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6782 - accuracy: 0.6028 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 636/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6877 - accuracy: 0.5996 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 637/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6802 - accuracy: 0.5960 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 638/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6885 - accuracy: 0.5923 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 639/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6781 - accuracy: 0.6101 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 640/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6782 - accuracy: 0.6024 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 641/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6853 - accuracy: 0.5910 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 642/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6810 - accuracy: 0.5941 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 643/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6781 - accuracy: 0.6028 - val_loss: 0.6641 - val_accuracy: 0.6197\n",
      "Epoch 644/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6876 - accuracy: 0.5910 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 645/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6813 - accuracy: 0.5987 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 646/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6847 - accuracy: 0.5969 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 647/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6806 - accuracy: 0.6037 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 648/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6853 - accuracy: 0.6143 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 649/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6812 - accuracy: 0.6092 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 650/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6748 - accuracy: 0.6069 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 651/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6861 - accuracy: 0.6033 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 652/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6899 - accuracy: 0.5969 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 653/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6812 - accuracy: 0.6024 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 654/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6828 - accuracy: 0.5978 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 655/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6789 - accuracy: 0.6133 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 656/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6797 - accuracy: 0.6083 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 657/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6828 - accuracy: 0.5983 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 658/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6630 - accuracy: 0.6156 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 659/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6841 - accuracy: 0.6111 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 660/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6701 - accuracy: 0.6156 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 661/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6876 - accuracy: 0.6065 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 662/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6880 - accuracy: 0.5996 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 663/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6783 - accuracy: 0.6028 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 664/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6740 - accuracy: 0.6202 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 665/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6848 - accuracy: 0.6092 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 666/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6755 - accuracy: 0.6092 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 667/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6733 - accuracy: 0.6056 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 668/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6811 - accuracy: 0.6019 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 669/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.7087 - accuracy: 0.5809 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 670/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6859 - accuracy: 0.5996 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 671/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6797 - accuracy: 0.6024 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 672/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6780 - accuracy: 0.5987 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 673/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6814 - accuracy: 0.6033 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 674/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6789 - accuracy: 0.6079 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 675/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6808 - accuracy: 0.6079 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 676/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6704 - accuracy: 0.6161 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 677/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6907 - accuracy: 0.5873 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 678/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6902 - accuracy: 0.5928 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 679/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6803 - accuracy: 0.5964 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 680/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6855 - accuracy: 0.6051 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 681/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6778 - accuracy: 0.6074 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 682/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6824 - accuracy: 0.5960 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 683/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6727 - accuracy: 0.6024 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 684/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6784 - accuracy: 0.6010 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 685/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6874 - accuracy: 0.5969 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 686/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6728 - accuracy: 0.6019 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 687/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6831 - accuracy: 0.6047 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 688/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6950 - accuracy: 0.5937 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 689/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6717 - accuracy: 0.6138 - val_loss: 0.6640 - val_accuracy: 0.6197\n",
      "Epoch 690/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6830 - accuracy: 0.6010 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 691/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6846 - accuracy: 0.6060 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 692/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6836 - accuracy: 0.5923 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 693/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6877 - accuracy: 0.5914 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 694/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6756 - accuracy: 0.6079 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 695/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6883 - accuracy: 0.6010 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 696/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6842 - accuracy: 0.5973 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 697/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6813 - accuracy: 0.5964 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 698/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6765 - accuracy: 0.6165 - val_loss: 0.6639 - val_accuracy: 0.6216\n",
      "Epoch 699/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6833 - accuracy: 0.6047 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 700/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6884 - accuracy: 0.6051 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 701/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6803 - accuracy: 0.6069 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 702/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6829 - accuracy: 0.6019 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 703/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6821 - accuracy: 0.6005 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 704/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6835 - accuracy: 0.5951 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 705/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6638 - accuracy: 0.6124 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 706/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6773 - accuracy: 0.6143 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 707/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6823 - accuracy: 0.5955 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 708/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6837 - accuracy: 0.5960 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 709/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6754 - accuracy: 0.6051 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 710/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6797 - accuracy: 0.5964 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 711/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6777 - accuracy: 0.6024 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 712/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6733 - accuracy: 0.6074 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 713/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6888 - accuracy: 0.5969 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 714/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6840 - accuracy: 0.5987 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 715/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6761 - accuracy: 0.6074 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 716/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6845 - accuracy: 0.5951 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 717/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6830 - accuracy: 0.5992 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 718/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6894 - accuracy: 0.5978 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 719/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6779 - accuracy: 0.5973 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 720/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6870 - accuracy: 0.5955 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 721/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6855 - accuracy: 0.6024 - val_loss: 0.6640 - val_accuracy: 0.6216\n",
      "Epoch 722/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6796 - accuracy: 0.6069 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 723/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6844 - accuracy: 0.5955 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 724/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6789 - accuracy: 0.6060 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 725/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5973 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 726/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6865 - accuracy: 0.5905 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 727/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6811 - accuracy: 0.6088 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 728/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6913 - accuracy: 0.5960 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 729/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6727 - accuracy: 0.6079 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 730/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6761 - accuracy: 0.5996 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 731/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6829 - accuracy: 0.5992 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 732/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6767 - accuracy: 0.6051 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 733/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6775 - accuracy: 0.6124 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 734/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6895 - accuracy: 0.5841 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 735/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6881 - accuracy: 0.5973 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 736/1000\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6767 - accuracy: 0.6161 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 737/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6816 - accuracy: 0.6015 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 738/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6796 - accuracy: 0.6056 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 739/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6823 - accuracy: 0.6056 - val_loss: 0.6640 - val_accuracy: 0.6234\n",
      "Epoch 740/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6632 - accuracy: 0.6220 - val_loss: 0.6640 - val_accuracy: 0.6234\n",
      "Epoch 741/1000\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6876 - accuracy: 0.5951 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 742/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6784 - accuracy: 0.6005 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 743/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6771 - accuracy: 0.6079 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 744/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6768 - accuracy: 0.6033 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 745/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6788 - accuracy: 0.6092 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 746/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6781 - accuracy: 0.6074 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 747/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6753 - accuracy: 0.6101 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 748/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6916 - accuracy: 0.5937 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 749/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6797 - accuracy: 0.5937 - val_loss: 0.6641 - val_accuracy: 0.6234\n",
      "Epoch 750/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6781 - accuracy: 0.5951 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 751/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6695 - accuracy: 0.6188 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 752/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6806 - accuracy: 0.6092 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 753/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6828 - accuracy: 0.5905 - val_loss: 0.6641 - val_accuracy: 0.6216\n",
      "Epoch 754/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6756 - accuracy: 0.5964 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 755/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6954 - accuracy: 0.5791 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 756/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6841 - accuracy: 0.5969 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 757/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6800 - accuracy: 0.6042 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 758/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6821 - accuracy: 0.5992 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 759/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6820 - accuracy: 0.5987 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 760/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6764 - accuracy: 0.6124 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 761/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6858 - accuracy: 0.6010 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 762/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6784 - accuracy: 0.5996 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 763/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6776 - accuracy: 0.6001 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 764/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6764 - accuracy: 0.6001 - val_loss: 0.6642 - val_accuracy: 0.6234\n",
      "Epoch 765/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6900 - accuracy: 0.5932 - val_loss: 0.6642 - val_accuracy: 0.6234\n",
      "Epoch 766/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6689 - accuracy: 0.6079 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 767/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6812 - accuracy: 0.6065 - val_loss: 0.6642 - val_accuracy: 0.6216\n",
      "Epoch 768/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6780 - accuracy: 0.6019 - val_loss: 0.6642 - val_accuracy: 0.6234\n",
      "Epoch 769/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6803 - accuracy: 0.5873 - val_loss: 0.6642 - val_accuracy: 0.6234\n",
      "Epoch 770/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6893 - accuracy: 0.5914 - val_loss: 0.6642 - val_accuracy: 0.6234\n",
      "Epoch 771/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6820 - accuracy: 0.6065 - val_loss: 0.6643 - val_accuracy: 0.6234\n",
      "Epoch 772/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6829 - accuracy: 0.5973 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 773/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6820 - accuracy: 0.6028 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 774/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6830 - accuracy: 0.5932 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 775/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6770 - accuracy: 0.6069 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 776/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6759 - accuracy: 0.6161 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 777/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6872 - accuracy: 0.5900 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 778/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6814 - accuracy: 0.6042 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 779/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6815 - accuracy: 0.5973 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 780/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6856 - accuracy: 0.5973 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 781/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6882 - accuracy: 0.5941 - val_loss: 0.6643 - val_accuracy: 0.6216\n",
      "Epoch 782/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6795 - accuracy: 0.6101 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 783/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6760 - accuracy: 0.5978 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 784/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6791 - accuracy: 0.6065 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 785/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6792 - accuracy: 0.6083 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 786/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6810 - accuracy: 0.6019 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 787/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6779 - accuracy: 0.5882 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 788/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6742 - accuracy: 0.6147 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 789/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6732 - accuracy: 0.6060 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 790/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6870 - accuracy: 0.5983 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 791/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6752 - accuracy: 0.6202 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 792/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6776 - accuracy: 0.6042 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 793/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6802 - accuracy: 0.5992 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 794/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6816 - accuracy: 0.5814 - val_loss: 0.6644 - val_accuracy: 0.6216\n",
      "Epoch 795/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6827 - accuracy: 0.5937 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 796/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6727 - accuracy: 0.6074 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 797/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6790 - accuracy: 0.6074 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 798/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6698 - accuracy: 0.6133 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 799/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6785 - accuracy: 0.6047 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 800/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6865 - accuracy: 0.5795 - val_loss: 0.6645 - val_accuracy: 0.6216\n",
      "Epoch 801/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6778 - accuracy: 0.6047 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 802/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6792 - accuracy: 0.6138 - val_loss: 0.6645 - val_accuracy: 0.6234\n",
      "Epoch 803/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6753 - accuracy: 0.6175 - val_loss: 0.6645 - val_accuracy: 0.6234\n",
      "Epoch 804/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6855 - accuracy: 0.5887 - val_loss: 0.6645 - val_accuracy: 0.6234\n",
      "Epoch 805/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6826 - accuracy: 0.6069 - val_loss: 0.6645 - val_accuracy: 0.6234\n",
      "Epoch 806/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6830 - accuracy: 0.5951 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 807/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6865 - accuracy: 0.5973 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 808/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6776 - accuracy: 0.6188 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 809/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6747 - accuracy: 0.6120 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 810/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6789 - accuracy: 0.5996 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 811/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6766 - accuracy: 0.6088 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 812/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6731 - accuracy: 0.5996 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 813/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6767 - accuracy: 0.6079 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 814/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6781 - accuracy: 0.6037 - val_loss: 0.6646 - val_accuracy: 0.6234\n",
      "Epoch 815/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6718 - accuracy: 0.6101 - val_loss: 0.6646 - val_accuracy: 0.6216\n",
      "Epoch 816/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6750 - accuracy: 0.6069 - val_loss: 0.6647 - val_accuracy: 0.6234\n",
      "Epoch 817/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6850 - accuracy: 0.5859 - val_loss: 0.6647 - val_accuracy: 0.6234\n",
      "Epoch 818/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6805 - accuracy: 0.6069 - val_loss: 0.6648 - val_accuracy: 0.6234\n",
      "Epoch 819/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6748 - accuracy: 0.6037 - val_loss: 0.6647 - val_accuracy: 0.6234\n",
      "Epoch 820/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6736 - accuracy: 0.6129 - val_loss: 0.6647 - val_accuracy: 0.6216\n",
      "Epoch 821/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6698 - accuracy: 0.6028 - val_loss: 0.6647 - val_accuracy: 0.6216\n",
      "Epoch 822/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6751 - accuracy: 0.5973 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 823/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6751 - accuracy: 0.5978 - val_loss: 0.6647 - val_accuracy: 0.6216\n",
      "Epoch 824/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6955 - accuracy: 0.5946 - val_loss: 0.6647 - val_accuracy: 0.6197\n",
      "Epoch 825/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6743 - accuracy: 0.6152 - val_loss: 0.6647 - val_accuracy: 0.6197\n",
      "Epoch 826/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6757 - accuracy: 0.6129 - val_loss: 0.6647 - val_accuracy: 0.6197\n",
      "Epoch 827/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6724 - accuracy: 0.6179 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 828/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6672 - accuracy: 0.6165 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 829/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6753 - accuracy: 0.6042 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 830/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6707 - accuracy: 0.6074 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 831/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6753 - accuracy: 0.6161 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 832/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6811 - accuracy: 0.5941 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 833/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6849 - accuracy: 0.6074 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 834/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6790 - accuracy: 0.5932 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 835/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6899 - accuracy: 0.5987 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 836/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6799 - accuracy: 0.6120 - val_loss: 0.6647 - val_accuracy: 0.6197\n",
      "Epoch 837/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6718 - accuracy: 0.6079 - val_loss: 0.6647 - val_accuracy: 0.6197\n",
      "Epoch 838/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6863 - accuracy: 0.6005 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 839/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6716 - accuracy: 0.5969 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 840/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6805 - accuracy: 0.6083 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 841/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6858 - accuracy: 0.5946 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 842/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6777 - accuracy: 0.6156 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 843/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6828 - accuracy: 0.6060 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 844/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6771 - accuracy: 0.6037 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 845/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6793 - accuracy: 0.6015 - val_loss: 0.6649 - val_accuracy: 0.6197\n",
      "Epoch 846/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6701 - accuracy: 0.6143 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 847/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6790 - accuracy: 0.6060 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 848/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6875 - accuracy: 0.6010 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 849/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6866 - accuracy: 0.5987 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 850/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6777 - accuracy: 0.6143 - val_loss: 0.6648 - val_accuracy: 0.6197\n",
      "Epoch 851/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6849 - accuracy: 0.6033 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 852/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6796 - accuracy: 0.5914 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 853/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6712 - accuracy: 0.6120 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 854/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6763 - accuracy: 0.5955 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 855/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6875 - accuracy: 0.5928 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 856/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6745 - accuracy: 0.6092 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 857/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6856 - accuracy: 0.6074 - val_loss: 0.6649 - val_accuracy: 0.6197\n",
      "Epoch 858/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6929 - accuracy: 0.5914 - val_loss: 0.6649 - val_accuracy: 0.6197\n",
      "Epoch 859/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6761 - accuracy: 0.5978 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 860/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6883 - accuracy: 0.5960 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 861/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6850 - accuracy: 0.6001 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 862/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6703 - accuracy: 0.6143 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 863/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6796 - accuracy: 0.6015 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 864/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6775 - accuracy: 0.6042 - val_loss: 0.6648 - val_accuracy: 0.6216\n",
      "Epoch 865/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6857 - accuracy: 0.6074 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 866/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6736 - accuracy: 0.6092 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 867/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6777 - accuracy: 0.6005 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 868/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6859 - accuracy: 0.5905 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 869/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6830 - accuracy: 0.5969 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 870/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6838 - accuracy: 0.6083 - val_loss: 0.6649 - val_accuracy: 0.6216\n",
      "Epoch 871/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6824 - accuracy: 0.5964 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 872/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6858 - accuracy: 0.5937 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 873/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6758 - accuracy: 0.6111 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 874/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6771 - accuracy: 0.6051 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 875/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6843 - accuracy: 0.5969 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 876/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6886 - accuracy: 0.5896 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 877/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6814 - accuracy: 0.6001 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 878/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6683 - accuracy: 0.6056 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 879/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6757 - accuracy: 0.6047 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 880/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6750 - accuracy: 0.5992 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 881/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6744 - accuracy: 0.5996 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 882/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6746 - accuracy: 0.6115 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 883/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6673 - accuracy: 0.6124 - val_loss: 0.6650 - val_accuracy: 0.6216\n",
      "Epoch 884/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6710 - accuracy: 0.6202 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 885/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6679 - accuracy: 0.6019 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 886/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6758 - accuracy: 0.6024 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 887/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6757 - accuracy: 0.6101 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 888/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6693 - accuracy: 0.6147 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 889/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6781 - accuracy: 0.6028 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 890/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6785 - accuracy: 0.5973 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 891/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6837 - accuracy: 0.5987 - val_loss: 0.6652 - val_accuracy: 0.6216\n",
      "Epoch 892/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6796 - accuracy: 0.6156 - val_loss: 0.6652 - val_accuracy: 0.6216\n",
      "Epoch 893/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6787 - accuracy: 0.5937 - val_loss: 0.6651 - val_accuracy: 0.6216\n",
      "Epoch 894/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6724 - accuracy: 0.6101 - val_loss: 0.6652 - val_accuracy: 0.6216\n",
      "Epoch 895/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6811 - accuracy: 0.5960 - val_loss: 0.6652 - val_accuracy: 0.6216\n",
      "Epoch 896/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6763 - accuracy: 0.5978 - val_loss: 0.6652 - val_accuracy: 0.6216\n",
      "Epoch 897/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6731 - accuracy: 0.6170 - val_loss: 0.6652 - val_accuracy: 0.6216\n",
      "Epoch 898/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6852 - accuracy: 0.5964 - val_loss: 0.6652 - val_accuracy: 0.6216\n",
      "Epoch 899/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6760 - accuracy: 0.5951 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 900/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6766 - accuracy: 0.6133 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 901/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6878 - accuracy: 0.5932 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 902/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6823 - accuracy: 0.6005 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 903/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6689 - accuracy: 0.6097 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 904/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6628 - accuracy: 0.6216 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 905/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6884 - accuracy: 0.5928 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 906/1000\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6764 - accuracy: 0.5836 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 907/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6754 - accuracy: 0.6138 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 908/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6723 - accuracy: 0.6097 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 909/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6694 - accuracy: 0.6092 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 910/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6715 - accuracy: 0.6101 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 911/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6787 - accuracy: 0.6111 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 912/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6782 - accuracy: 0.6124 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 913/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6719 - accuracy: 0.6165 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 914/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6701 - accuracy: 0.6083 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 915/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6814 - accuracy: 0.6010 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 916/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6804 - accuracy: 0.6028 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 917/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6889 - accuracy: 0.6047 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 918/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6746 - accuracy: 0.6161 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 919/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6799 - accuracy: 0.6147 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 920/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6822 - accuracy: 0.6056 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 921/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6710 - accuracy: 0.6179 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 922/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6687 - accuracy: 0.6092 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 923/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6745 - accuracy: 0.6060 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 924/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6804 - accuracy: 0.6083 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 925/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6840 - accuracy: 0.5941 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 926/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6766 - accuracy: 0.6124 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 927/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6822 - accuracy: 0.6120 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 928/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6820 - accuracy: 0.6019 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 929/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6741 - accuracy: 0.6083 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 930/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6832 - accuracy: 0.5960 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 931/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6740 - accuracy: 0.6015 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 932/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6790 - accuracy: 0.6028 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 933/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6825 - accuracy: 0.6042 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 934/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6757 - accuracy: 0.6097 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 935/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6863 - accuracy: 0.6028 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 936/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6717 - accuracy: 0.6069 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 937/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6708 - accuracy: 0.6028 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 938/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6688 - accuracy: 0.6047 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 939/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6762 - accuracy: 0.6115 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 940/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6661 - accuracy: 0.6184 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 941/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6746 - accuracy: 0.6001 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 942/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6731 - accuracy: 0.6092 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 943/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6702 - accuracy: 0.5960 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 944/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6714 - accuracy: 0.6106 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 945/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6716 - accuracy: 0.5951 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 946/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6763 - accuracy: 0.6015 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 947/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6884 - accuracy: 0.5987 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 948/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6685 - accuracy: 0.6115 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 949/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6847 - accuracy: 0.6028 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 950/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6785 - accuracy: 0.6097 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 951/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6721 - accuracy: 0.6152 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 952/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6850 - accuracy: 0.5923 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 953/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6893 - accuracy: 0.5923 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 954/1000\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6817 - accuracy: 0.6001 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 955/1000\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6777 - accuracy: 0.6079 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 956/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6762 - accuracy: 0.6051 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 957/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6761 - accuracy: 0.5978 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 958/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6919 - accuracy: 0.5992 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 959/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6754 - accuracy: 0.6101 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 960/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6906 - accuracy: 0.5983 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 961/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6801 - accuracy: 0.6083 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 962/1000\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6826 - accuracy: 0.5868 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 963/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6715 - accuracy: 0.6202 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 964/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6786 - accuracy: 0.5964 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 965/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6821 - accuracy: 0.6005 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 966/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6752 - accuracy: 0.5973 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 967/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6805 - accuracy: 0.5955 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 968/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6731 - accuracy: 0.6120 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 969/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6593 - accuracy: 0.6179 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 970/1000\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6752 - accuracy: 0.6060 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 971/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6764 - accuracy: 0.6097 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 972/1000\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6793 - accuracy: 0.5973 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 973/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6697 - accuracy: 0.6092 - val_loss: 0.6653 - val_accuracy: 0.6216\n",
      "Epoch 974/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6741 - accuracy: 0.6037 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 975/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6704 - accuracy: 0.6069 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 976/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6805 - accuracy: 0.6051 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 977/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6804 - accuracy: 0.5951 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 978/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6848 - accuracy: 0.5987 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 979/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6742 - accuracy: 0.5996 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 980/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6736 - accuracy: 0.6088 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 981/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6794 - accuracy: 0.6015 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 982/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6827 - accuracy: 0.6129 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 983/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6750 - accuracy: 0.6074 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 984/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6775 - accuracy: 0.6047 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 985/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6624 - accuracy: 0.6028 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 986/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6757 - accuracy: 0.6120 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 987/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6734 - accuracy: 0.6042 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 988/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6786 - accuracy: 0.6069 - val_loss: 0.6656 - val_accuracy: 0.6216\n",
      "Epoch 989/1000\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.6697 - accuracy: 0.6143 - val_loss: 0.6656 - val_accuracy: 0.6216\n",
      "Epoch 990/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6646 - accuracy: 0.6060 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 991/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6699 - accuracy: 0.6111 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 992/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6727 - accuracy: 0.6152 - val_loss: 0.6656 - val_accuracy: 0.6216\n",
      "Epoch 993/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6860 - accuracy: 0.5955 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 994/1000\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6776 - accuracy: 0.5987 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 995/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6743 - accuracy: 0.6161 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 996/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6755 - accuracy: 0.6133 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
      "Epoch 997/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6807 - accuracy: 0.6060 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 998/1000\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6690 - accuracy: 0.6083 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 999/1000\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6749 - accuracy: 0.6060 - val_loss: 0.6654 - val_accuracy: 0.6216\n",
      "Epoch 1000/1000\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6750 - accuracy: 0.6033 - val_loss: 0.6654 - val_accuracy: 0.6234\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.488889  0.086275  0.146667       255\n",
      "           1   0.635368  0.946387  0.760300       429\n",
      "\n",
      "    accuracy                       0.625731       684\n",
      "   macro avg   0.562128  0.516331  0.453483       684\n",
      "weighted avg   0.580759  0.625731  0.531533       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('/Users/eddie/SSTP-Injury/Agriculture/Deep/RNN_Weights')\n",
    "res = model.predict(X_test)\n",
    "res.round()\n",
    "actual = []\n",
    "for num in res:\n",
    "    if num>0.5:\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,actual,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2050d56c490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "confusionmatrix = confusion_matrix(Y_test, actual)\n",
    "cm_display = ConfusionMatrixDisplay(confusionmatrix, display_labels=[0,1])\n",
    "cm_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PermutationExplainer explainer: 301it [08:01,  1.60s/it]                         \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 301it [16:30,  3.32s/it]                         \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "X_test_shap = shap.sample(X_train,nsamples = 300)\n",
    "explainer = shap.Explainer(model, X_test_shap)\n",
    "shap_values = explainer.shap_values(X_test_shap)\n",
    "shap.summary_plot(shap_values, feature_names=features, plot_type=\"bar\", plot_size=(20,15))\n",
    "explanation = explainer(X_test_shap)\n",
    "explanation = shap.Explanation(\n",
    "    values=explanation, \n",
    "    feature_names=features\n",
    ")\n",
    "shap.plots.beeswarm(explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
