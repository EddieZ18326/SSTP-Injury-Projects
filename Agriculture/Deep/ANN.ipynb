{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0      3   2   2  25   0   3  10   0   0   0   0   0   0   0   0   0   1   1\n",
      "1      3   3   1  61   0   3  10   0   0   0   0   0   0   0   0   0   7   1\n",
      "2      3   3   1  65   0   3  10   0   0   0   0   0   0   0   0   0   6   1\n",
      "3      3   2   1  49   0   3  10   0   0   0   1   0   0   0   0   0   5   1\n",
      "4      3   1   1  54   0   5   2   1   1   0   0   0   0   0   0   1   5   1\n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "3414   1   2   1  57   0   6   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3415   1   1   1  24   0   3   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3416   1   1   1  50   0   3  10   0   0   0   0   0   0   0   0   0   6   4\n",
      "3417   1   2   1  58   0   3   9   0   0   0   0   0   0   0   0   0   6   4\n",
      "3418   1   2   1   3   0   4  10   0   0   0   0   0   0   0   0   0   5   4\n",
      "\n",
      "[3419 rows x 18 columns]\n",
      "      0\n",
      "0     0\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "...  ..\n",
      "3414  1\n",
      "3415  1\n",
      "3416  1\n",
      "3417  0\n",
      "3418  1\n",
      "\n",
      "[3419 rows x 1 columns]\n",
      "(2735, 18)\n",
      "(2735, 1)\n",
      "Index(['Location of Incident', 'Time', 'Sex', 'Age', 'Intentional', 'Role',\n",
      "       'Injury Agent', 'Confined Space', 'Grain Involved', 'Alcohol/Drugs',\n",
      "       'Seatbelt', 'Helmet', 'ROPS', 'Agritourism', 'Other PPE',\n",
      "       'Drowning/Suffocation', 'Day', 'Season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('/Users/eddie/Downloads/Log In - AgInjuryNews (1).xlsx - Sheet1 (1) - Log In - AgInjuryNews (1).xlsx - Sheet1 (1).csv')\n",
    "\n",
    "X = pd.DataFrame(dataset.iloc[:,:18].values)\n",
    "Y = pd.DataFrame(dataset.iloc[:,18:].values)\n",
    "print(X)\n",
    "print(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=0)\n",
    "X_train, X_train_val, Y_train, Y_train_val = train_test_split(X,Y,test_size=0.2)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "features = pd.DataFrame(dataset.iloc[:,:18])\n",
    "features = features.columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 5ms/step - loss: 0.6649 - accuracy: 0.6230 - val_loss: 3.9257 - val_accuracy: 0.6301\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6307 - val_loss: 11.1186 - val_accuracy: 0.6301\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6347 - val_loss: 10.0214 - val_accuracy: 0.6301\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6428 - val_loss: 15.7352 - val_accuracy: 0.6287\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6523 - val_loss: 15.2594 - val_accuracy: 0.6301\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6494 - val_loss: 19.8654 - val_accuracy: 0.6287\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6585 - val_loss: 24.2365 - val_accuracy: 0.6301\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6527 - val_loss: 24.9830 - val_accuracy: 0.6330\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6570 - val_loss: 27.0488 - val_accuracy: 0.6301\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6654 - val_loss: 31.2947 - val_accuracy: 0.6301\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6614 - val_loss: 31.7414 - val_accuracy: 0.6301\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6658 - val_loss: 32.8207 - val_accuracy: 0.6301\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6654 - val_loss: 33.2660 - val_accuracy: 0.6301\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6629 - val_loss: 40.1509 - val_accuracy: 0.6301\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6717 - val_loss: 53.2566 - val_accuracy: 0.6301\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6790 - val_loss: 48.2083 - val_accuracy: 0.6301\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6698 - val_loss: 58.5010 - val_accuracy: 0.6301\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6782 - val_loss: 52.7726 - val_accuracy: 0.6301\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6768 - val_loss: 62.3291 - val_accuracy: 0.6301\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6867 - val_loss: 60.1846 - val_accuracy: 0.6301\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6892 - val_loss: 51.9015 - val_accuracy: 0.6301\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.6885 - val_loss: 67.6705 - val_accuracy: 0.6301\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.6969 - val_loss: 68.2143 - val_accuracy: 0.6301\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.6965 - val_loss: 74.6548 - val_accuracy: 0.6301\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.6976 - val_loss: 99.1522 - val_accuracy: 0.6301\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7027 - val_loss: 87.1347 - val_accuracy: 0.6301\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7108 - val_loss: 106.8145 - val_accuracy: 0.6301\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7112 - val_loss: 97.6326 - val_accuracy: 0.6301\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7075 - val_loss: 100.3801 - val_accuracy: 0.6301\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7188 - val_loss: 110.6646 - val_accuracy: 0.6301\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7141 - val_loss: 95.3076 - val_accuracy: 0.6301\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7133 - val_loss: 109.3169 - val_accuracy: 0.6301\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7236 - val_loss: 116.7774 - val_accuracy: 0.6287\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7265 - val_loss: 107.7648 - val_accuracy: 0.6287\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7250 - val_loss: 124.2861 - val_accuracy: 0.6287\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7346 - val_loss: 116.0867 - val_accuracy: 0.6272\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7247 - val_loss: 125.0321 - val_accuracy: 0.6257\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7280 - val_loss: 102.8853 - val_accuracy: 0.6272\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7408 - val_loss: 123.4682 - val_accuracy: 0.6257\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7397 - val_loss: 115.3712 - val_accuracy: 0.6257\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7499 - val_loss: 131.8399 - val_accuracy: 0.6228\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7393 - val_loss: 127.8317 - val_accuracy: 0.6272\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7455 - val_loss: 146.7023 - val_accuracy: 0.6272\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7481 - val_loss: 161.8281 - val_accuracy: 0.6272\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7561 - val_loss: 136.7962 - val_accuracy: 0.6243\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7484 - val_loss: 160.9064 - val_accuracy: 0.6199\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7656 - val_loss: 160.3105 - val_accuracy: 0.6228\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7693 - val_loss: 143.5811 - val_accuracy: 0.6272\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7550 - val_loss: 183.5669 - val_accuracy: 0.6199\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7671 - val_loss: 174.0749 - val_accuracy: 0.6199\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7726 - val_loss: 205.0397 - val_accuracy: 0.6228\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7759 - val_loss: 189.6465 - val_accuracy: 0.6243\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7612 - val_loss: 135.2216 - val_accuracy: 0.6272\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7744 - val_loss: 186.1592 - val_accuracy: 0.6199\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7784 - val_loss: 165.9051 - val_accuracy: 0.6184\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7770 - val_loss: 195.1051 - val_accuracy: 0.6213\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.7894 - val_loss: 240.6553 - val_accuracy: 0.6213\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7879 - val_loss: 234.1142 - val_accuracy: 0.6243\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.7934 - val_loss: 235.7202 - val_accuracy: 0.6199\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.7916 - val_loss: 232.6830 - val_accuracy: 0.6243\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.7941 - val_loss: 259.9030 - val_accuracy: 0.6228\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8022 - val_loss: 255.9489 - val_accuracy: 0.6199\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8004 - val_loss: 311.8230 - val_accuracy: 0.6272\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.7967 - val_loss: 321.4081 - val_accuracy: 0.6257\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.7974 - val_loss: 304.2520 - val_accuracy: 0.6199\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8004 - val_loss: 304.6138 - val_accuracy: 0.6287\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8062 - val_loss: 322.9559 - val_accuracy: 0.6213\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8066 - val_loss: 357.1468 - val_accuracy: 0.6199\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8077 - val_loss: 343.2187 - val_accuracy: 0.6199\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8124 - val_loss: 370.4417 - val_accuracy: 0.6228\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8051 - val_loss: 281.8554 - val_accuracy: 0.6199\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8124 - val_loss: 368.1916 - val_accuracy: 0.6272\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8121 - val_loss: 386.8937 - val_accuracy: 0.6243\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8190 - val_loss: 395.2157 - val_accuracy: 0.6272\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8245 - val_loss: 439.4080 - val_accuracy: 0.6257\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8128 - val_loss: 480.4874 - val_accuracy: 0.6184\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8037 - val_loss: 364.5099 - val_accuracy: 0.6257\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8124 - val_loss: 431.7003 - val_accuracy: 0.6243\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8271 - val_loss: 487.0340 - val_accuracy: 0.6272\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8307 - val_loss: 514.4328 - val_accuracy: 0.6257\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8146 - val_loss: 403.1921 - val_accuracy: 0.6228\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8274 - val_loss: 471.0338 - val_accuracy: 0.6257\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8212 - val_loss: 537.1176 - val_accuracy: 0.6228\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8267 - val_loss: 600.9073 - val_accuracy: 0.6213\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8336 - val_loss: 652.4211 - val_accuracy: 0.6257\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8351 - val_loss: 636.0424 - val_accuracy: 0.6213\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8296 - val_loss: 660.0566 - val_accuracy: 0.6243\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8322 - val_loss: 661.7178 - val_accuracy: 0.6257\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8380 - val_loss: 659.3058 - val_accuracy: 0.6257\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8413 - val_loss: 651.6749 - val_accuracy: 0.6243\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8358 - val_loss: 630.0336 - val_accuracy: 0.6257\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8479 - val_loss: 725.2845 - val_accuracy: 0.6257\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8318 - val_loss: 581.5824 - val_accuracy: 0.6243\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8347 - val_loss: 704.6978 - val_accuracy: 0.6243\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8424 - val_loss: 769.3898 - val_accuracy: 0.6257\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8428 - val_loss: 894.2227 - val_accuracy: 0.6257\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8366 - val_loss: 761.8721 - val_accuracy: 0.6243\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8340 - val_loss: 852.0341 - val_accuracy: 0.6272\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8442 - val_loss: 807.4341 - val_accuracy: 0.6287\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8475 - val_loss: 782.3969 - val_accuracy: 0.6257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d083807d30>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape = (18,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs = 100, validation_data=(X_train_val,Y_train_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.761364  0.788235  0.774566       255\n",
      "           1   0.871429  0.853147  0.862191       429\n",
      "\n",
      "    accuracy                       0.828947       684\n",
      "   macro avg   0.816396  0.820691  0.818379       684\n",
      "weighted avg   0.830396  0.828947  0.829524       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "res.round()\n",
    "actual = []\n",
    "for num in res:\n",
    "    if num>0.5:\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,actual,digits=6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
