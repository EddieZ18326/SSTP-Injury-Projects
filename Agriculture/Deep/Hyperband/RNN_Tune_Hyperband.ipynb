{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0      3   2   2  25   0   3  10   0   0   0   0   0   0   0   0   0   1   1\n",
      "1      3   3   1  61   0   3  10   0   0   0   0   0   0   0   0   0   7   1\n",
      "2      3   3   1  65   0   3  10   0   0   0   0   0   0   0   0   0   6   1\n",
      "3      3   2   1  49   0   3  10   0   0   0   1   0   0   0   0   0   5   1\n",
      "4      3   1   1  54   0   5   2   1   1   0   0   0   0   0   0   1   5   1\n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "3414   1   2   1  57   0   6   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3415   1   1   1  24   0   3   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3416   1   1   1  50   0   3  10   0   0   0   0   0   0   0   0   0   6   4\n",
      "3417   1   2   1  58   0   3   9   0   0   0   0   0   0   0   0   0   6   4\n",
      "3418   1   2   1   3   0   4  10   0   0   0   0   0   0   0   0   0   5   4\n",
      "\n",
      "[3419 rows x 18 columns]\n",
      "      0\n",
      "0     0\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "...  ..\n",
      "3414  1\n",
      "3415  1\n",
      "3416  1\n",
      "3417  0\n",
      "3418  1\n",
      "\n",
      "[3419 rows x 1 columns]\n",
      "(2735, 18)\n",
      "(2735, 1)\n",
      "(684, 18)\n",
      "Index(['Location of Incident', 'Time', 'Sex', 'Age', 'Intentional', 'Role',\n",
      "       'Injury Agent', 'Confined Space', 'Grain Involved', 'Alcohol/Drugs',\n",
      "       'Seatbelt', 'Helmet', 'ROPS', 'Agritourism', 'Other PPE',\n",
      "       'Drowning/Suffocation', 'Day', 'Season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('/Users/eddie/Downloads/Log In - AgInjuryNews (1).xlsx - Sheet1 (1) - Log In - AgInjuryNews (1).xlsx - Sheet1 (1).csv')\n",
    "\n",
    "X = pd.DataFrame(dataset.iloc[:,:18].values)\n",
    "Y = pd.DataFrame(dataset.iloc[:,18:].values)\n",
    "print(X)\n",
    "print(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=0)\n",
    "X_train, X_train_val, Y_train, Y_train_val = train_test_split(X,Y,test_size=0.2)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.reshape(2735,18,1)\n",
    "X_test.reshape(684,18,1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "features = pd.DataFrame(dataset.iloc[:,:18])\n",
    "features = features.columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, SimpleRNN, Dropout \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=96, max_value=256, step=16)\n",
    "  model.add(SimpleRNN(hp_units, input_shape=(18, 1), return_sequences=True))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Second SimpleRNN layer\n",
    "  hp_units2 = hp.Int('units2', min_value=16, max_value=96, step=8)\n",
    "  model.add(SimpleRNN(hp_units2, return_sequences=True))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Third SimpleRNN layer\n",
    "  model.add(SimpleRNN(hp_units2, return_sequences=False))  # This will output a single vector for the next layer\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Dense layer with more units\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(keras.layers.Dense(1))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4,1e-5,1e-6])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape = (18,)))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from rnn_hyper\\rnn_hyper\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='rnn_hyper',\n",
    "                     project_name='rnn_hyper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 208 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(X_train, Y_train, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "69/69 [==============================] - 8s 30ms/step - loss: 0.7710 - accuracy: 0.5183 - val_loss: 0.6554 - val_accuracy: 0.6435\n",
      "Epoch 2/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.7202 - accuracy: 0.4995 - val_loss: 0.6629 - val_accuracy: 0.3565\n",
      "Epoch 3/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6951 - accuracy: 0.4867 - val_loss: 0.6601 - val_accuracy: 0.3565\n",
      "Epoch 4/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6851 - accuracy: 0.4794 - val_loss: 0.6601 - val_accuracy: 0.3565\n",
      "Epoch 5/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6766 - accuracy: 0.4790 - val_loss: 0.6592 - val_accuracy: 0.3565\n",
      "Epoch 6/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6720 - accuracy: 0.4918 - val_loss: 0.6669 - val_accuracy: 0.3565\n",
      "Epoch 7/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6679 - accuracy: 0.4767 - val_loss: 0.6636 - val_accuracy: 0.3565\n",
      "Epoch 8/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6722 - accuracy: 0.4749 - val_loss: 0.6590 - val_accuracy: 0.3565\n",
      "Epoch 9/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6685 - accuracy: 0.4694 - val_loss: 0.6639 - val_accuracy: 0.3565\n",
      "Epoch 10/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6681 - accuracy: 0.4822 - val_loss: 0.6577 - val_accuracy: 0.3565\n",
      "Epoch 11/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6713 - accuracy: 0.5055 - val_loss: 0.6608 - val_accuracy: 0.3565\n",
      "Epoch 12/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6683 - accuracy: 0.4273 - val_loss: 0.6529 - val_accuracy: 0.3565\n",
      "Epoch 13/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6691 - accuracy: 0.4676 - val_loss: 0.6546 - val_accuracy: 0.3565\n",
      "Epoch 14/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6667 - accuracy: 0.4584 - val_loss: 0.6608 - val_accuracy: 0.3565\n",
      "Epoch 15/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6655 - accuracy: 0.4685 - val_loss: 0.6551 - val_accuracy: 0.3565\n",
      "Epoch 16/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6619 - accuracy: 0.4689 - val_loss: 0.6550 - val_accuracy: 0.3565\n",
      "Epoch 17/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6627 - accuracy: 0.4950 - val_loss: 0.6542 - val_accuracy: 0.3565\n",
      "Epoch 18/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6646 - accuracy: 0.4968 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 19/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6628 - accuracy: 0.5123 - val_loss: 0.6561 - val_accuracy: 0.3565\n",
      "Epoch 20/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6621 - accuracy: 0.4612 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 21/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6637 - accuracy: 0.5050 - val_loss: 0.6569 - val_accuracy: 0.3565\n",
      "Epoch 22/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6662 - accuracy: 0.4671 - val_loss: 0.6562 - val_accuracy: 0.3565\n",
      "Epoch 23/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6659 - accuracy: 0.4580 - val_loss: 0.6567 - val_accuracy: 0.3565\n",
      "Epoch 24/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6613 - accuracy: 0.4941 - val_loss: 0.6546 - val_accuracy: 0.3565\n",
      "Epoch 25/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6659 - accuracy: 0.4854 - val_loss: 0.6580 - val_accuracy: 0.3565\n",
      "Epoch 26/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6657 - accuracy: 0.4296 - val_loss: 0.6560 - val_accuracy: 0.3565\n",
      "Epoch 27/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6655 - accuracy: 0.4529 - val_loss: 0.6559 - val_accuracy: 0.3565\n",
      "Epoch 28/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6635 - accuracy: 0.4735 - val_loss: 0.6558 - val_accuracy: 0.3565\n",
      "Epoch 29/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6629 - accuracy: 0.4785 - val_loss: 0.6538 - val_accuracy: 0.3565\n",
      "Epoch 30/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6649 - accuracy: 0.4369 - val_loss: 0.6532 - val_accuracy: 0.3565\n",
      "Epoch 31/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6628 - accuracy: 0.4895 - val_loss: 0.6545 - val_accuracy: 0.3565\n",
      "Epoch 32/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6635 - accuracy: 0.4502 - val_loss: 0.6551 - val_accuracy: 0.3565\n",
      "Epoch 33/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6641 - accuracy: 0.4817 - val_loss: 0.6551 - val_accuracy: 0.3565\n",
      "Epoch 34/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6636 - accuracy: 0.4461 - val_loss: 0.6562 - val_accuracy: 0.3565\n",
      "Epoch 35/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6617 - accuracy: 0.4941 - val_loss: 0.6543 - val_accuracy: 0.3565\n",
      "Epoch 36/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6626 - accuracy: 0.4753 - val_loss: 0.6557 - val_accuracy: 0.3565\n",
      "Epoch 37/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6626 - accuracy: 0.4561 - val_loss: 0.6536 - val_accuracy: 0.3565\n",
      "Epoch 38/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6623 - accuracy: 0.4612 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 39/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6635 - accuracy: 0.4982 - val_loss: 0.6547 - val_accuracy: 0.3565\n",
      "Epoch 40/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6632 - accuracy: 0.4831 - val_loss: 0.6542 - val_accuracy: 0.3565\n",
      "Epoch 41/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6628 - accuracy: 0.4497 - val_loss: 0.6548 - val_accuracy: 0.3565\n",
      "Epoch 42/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6621 - accuracy: 0.4771 - val_loss: 0.6535 - val_accuracy: 0.3565\n",
      "Epoch 43/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6621 - accuracy: 0.4570 - val_loss: 0.6530 - val_accuracy: 0.3565\n",
      "Epoch 44/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6624 - accuracy: 0.4776 - val_loss: 0.6539 - val_accuracy: 0.3565\n",
      "Epoch 45/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6628 - accuracy: 0.4790 - val_loss: 0.6537 - val_accuracy: 0.3565\n",
      "Epoch 46/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6643 - accuracy: 0.4424 - val_loss: 0.6547 - val_accuracy: 0.3565\n",
      "Epoch 47/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6628 - accuracy: 0.4502 - val_loss: 0.6541 - val_accuracy: 0.3565\n",
      "Epoch 48/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6608 - accuracy: 0.4890 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 49/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6626 - accuracy: 0.5046 - val_loss: 0.6531 - val_accuracy: 0.3565\n",
      "Epoch 50/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6608 - accuracy: 0.5329 - val_loss: 0.6538 - val_accuracy: 0.3565\n",
      "Epoch 51/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6623 - accuracy: 0.4401 - val_loss: 0.6542 - val_accuracy: 0.3565\n",
      "Epoch 52/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6626 - accuracy: 0.4063 - val_loss: 0.6534 - val_accuracy: 0.3565\n",
      "Epoch 53/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6621 - accuracy: 0.5005 - val_loss: 0.6542 - val_accuracy: 0.3565\n",
      "Epoch 54/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6614 - accuracy: 0.4461 - val_loss: 0.6541 - val_accuracy: 0.3565\n",
      "Epoch 55/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6625 - accuracy: 0.4657 - val_loss: 0.6543 - val_accuracy: 0.3565\n",
      "Epoch 56/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6622 - accuracy: 0.4913 - val_loss: 0.6530 - val_accuracy: 0.3565\n",
      "Epoch 57/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6628 - accuracy: 0.4881 - val_loss: 0.6539 - val_accuracy: 0.3565\n",
      "Epoch 58/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6620 - accuracy: 0.4045 - val_loss: 0.6544 - val_accuracy: 0.3565\n",
      "Epoch 59/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6622 - accuracy: 0.4378 - val_loss: 0.6534 - val_accuracy: 0.3565\n",
      "Epoch 60/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6606 - accuracy: 0.4822 - val_loss: 0.6528 - val_accuracy: 0.3565\n",
      "Epoch 61/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6599 - accuracy: 0.5242 - val_loss: 0.6525 - val_accuracy: 0.3565\n",
      "Epoch 62/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6618 - accuracy: 0.4890 - val_loss: 0.6534 - val_accuracy: 0.3565\n",
      "Epoch 63/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6625 - accuracy: 0.4351 - val_loss: 0.6536 - val_accuracy: 0.3565\n",
      "Epoch 64/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6620 - accuracy: 0.4602 - val_loss: 0.6536 - val_accuracy: 0.3565\n",
      "Epoch 65/500\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6625 - accuracy: 0.4319 - val_loss: 0.6537 - val_accuracy: 0.3565\n",
      "Epoch 66/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6620 - accuracy: 0.4397 - val_loss: 0.6534 - val_accuracy: 0.3565\n",
      "Epoch 67/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6614 - accuracy: 0.4612 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 68/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6620 - accuracy: 0.5155 - val_loss: 0.6532 - val_accuracy: 0.3565\n",
      "Epoch 69/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.4470 - val_loss: 0.6534 - val_accuracy: 0.3565\n",
      "Epoch 70/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6609 - accuracy: 0.5160 - val_loss: 0.6529 - val_accuracy: 0.3565\n",
      "Epoch 71/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6614 - accuracy: 0.4904 - val_loss: 0.6530 - val_accuracy: 0.3565\n",
      "Epoch 72/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.5009 - val_loss: 0.6531 - val_accuracy: 0.3565\n",
      "Epoch 73/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6620 - accuracy: 0.4762 - val_loss: 0.6531 - val_accuracy: 0.3565\n",
      "Epoch 74/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6615 - accuracy: 0.4342 - val_loss: 0.6528 - val_accuracy: 0.3565\n",
      "Epoch 75/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6615 - accuracy: 0.4433 - val_loss: 0.6528 - val_accuracy: 0.3565\n",
      "Epoch 76/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6614 - accuracy: 0.4228 - val_loss: 0.6528 - val_accuracy: 0.3565\n",
      "Epoch 77/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6615 - accuracy: 0.4077 - val_loss: 0.6529 - val_accuracy: 0.3565\n",
      "Epoch 78/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6612 - accuracy: 0.4260 - val_loss: 0.6527 - val_accuracy: 0.3565\n",
      "Epoch 79/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6615 - accuracy: 0.4086 - val_loss: 0.6526 - val_accuracy: 0.3565\n",
      "Epoch 80/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.4241 - val_loss: 0.6525 - val_accuracy: 0.3565\n",
      "Epoch 81/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6619 - accuracy: 0.4890 - val_loss: 0.6530 - val_accuracy: 0.3565\n",
      "Epoch 82/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6615 - accuracy: 0.4694 - val_loss: 0.6527 - val_accuracy: 0.3565\n",
      "Epoch 83/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6608 - accuracy: 0.5101 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 84/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6619 - accuracy: 0.4995 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 85/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6611 - accuracy: 0.5306 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 86/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6611 - accuracy: 0.5146 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 87/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6619 - accuracy: 0.4470 - val_loss: 0.6525 - val_accuracy: 0.3565\n",
      "Epoch 88/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.4196 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 89/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6611 - accuracy: 0.5366 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 90/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6611 - accuracy: 0.5736 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 91/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6619 - accuracy: 0.5279 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 92/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6617 - accuracy: 0.5594 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 93/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6613 - accuracy: 0.5238 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 94/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6611 - accuracy: 0.5334 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 95/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6608 - accuracy: 0.6156 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 96/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6079 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 97/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6620 - accuracy: 0.5882 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 98/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6612 - accuracy: 0.5846 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 99/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6607 - accuracy: 0.6037 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 100/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.5987 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 101/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6607 - accuracy: 0.6161 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 102/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.5841 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 103/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6610 - accuracy: 0.5941 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 104/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6056 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 105/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6608 - accuracy: 0.5914 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 106/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6615 - accuracy: 0.5242 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 107/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.4726 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 108/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.5859 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 109/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6616 - accuracy: 0.5887 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 110/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6608 - accuracy: 0.6097 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 111/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6614 - accuracy: 0.6193 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 112/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6609 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 113/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 114/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6616 - accuracy: 0.5704 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 115/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6613 - accuracy: 0.6143 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 116/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6611 - accuracy: 0.6115 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 117/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6612 - accuracy: 0.5983 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 118/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 119/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6611 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 120/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6243 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 121/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6612 - accuracy: 0.5987 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 122/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6611 - accuracy: 0.6175 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 123/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6147 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 124/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6047 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 125/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.5786 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 126/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6613 - accuracy: 0.6133 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 127/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6611 - accuracy: 0.6252 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 128/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6092 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 129/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6147 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 130/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6610 - accuracy: 0.6083 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 131/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6611 - accuracy: 0.6129 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 132/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6188 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 133/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6612 - accuracy: 0.6015 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 134/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6243 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 135/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6207 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 136/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6170 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 137/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6611 - accuracy: 0.6216 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 138/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6609 - accuracy: 0.6229 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 139/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6611 - accuracy: 0.6060 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 140/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6179 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 141/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6609 - accuracy: 0.6138 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 142/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.6015 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 143/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6614 - accuracy: 0.6069 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 144/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6239 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 145/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6612 - accuracy: 0.6179 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 146/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6610 - accuracy: 0.6243 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 147/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6610 - accuracy: 0.6202 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 148/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6615 - accuracy: 0.6184 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 149/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6622 - accuracy: 0.5896 - val_loss: 0.6516 - val_accuracy: 0.6435\n",
      "Epoch 150/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6619 - accuracy: 0.5814 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 151/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6612 - accuracy: 0.5928 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 152/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6619 - accuracy: 0.5955 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 153/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.6179 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 154/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6613 - accuracy: 0.6115 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 155/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6609 - accuracy: 0.6152 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 156/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6611 - accuracy: 0.6069 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 157/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6612 - accuracy: 0.6069 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 158/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6229 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 159/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6211 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 160/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6611 - accuracy: 0.6234 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 161/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6613 - accuracy: 0.6216 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 162/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6612 - accuracy: 0.6202 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 163/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6225 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 164/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6612 - accuracy: 0.6207 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 165/500\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6611 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 166/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6220 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 167/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6610 - accuracy: 0.6234 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 168/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 169/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6609 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 170/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6607 - accuracy: 0.6115 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 171/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6616 - accuracy: 0.5969 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 172/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6197 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 173/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6175 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 174/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6188 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 175/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6609 - accuracy: 0.6243 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 176/500\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6611 - accuracy: 0.6229 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 177/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6608 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 178/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.6248 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 179/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6248 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 180/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6202 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 181/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6243 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 182/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6609 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 183/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6609 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 184/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 185/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 186/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6611 - accuracy: 0.6280 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 187/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 188/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6610 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 189/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6220 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 190/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 191/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6610 - accuracy: 0.6243 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 192/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6610 - accuracy: 0.6243 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 193/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6613 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 194/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 195/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 196/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 197/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 198/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6612 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 199/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 200/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 201/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 202/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6609 - accuracy: 0.6266 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 203/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6607 - accuracy: 0.6220 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 204/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6614 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 205/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6608 - accuracy: 0.6234 - val_loss: 0.6517 - val_accuracy: 0.6435\n",
      "Epoch 206/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6616 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 207/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6617 - accuracy: 0.6092 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 208/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6617 - accuracy: 0.6207 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 209/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6621 - accuracy: 0.6133 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 210/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6621 - accuracy: 0.5914 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 211/500\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6619 - accuracy: 0.5562 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 212/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6610 - accuracy: 0.6019 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 213/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6612 - accuracy: 0.6005 - val_loss: 0.6518 - val_accuracy: 0.6435\n",
      "Epoch 214/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6088 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 215/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6610 - accuracy: 0.6079 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 216/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6613 - accuracy: 0.6097 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 217/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6613 - accuracy: 0.6115 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 218/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6613 - accuracy: 0.6060 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 219/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6220 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 220/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6608 - accuracy: 0.6252 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 221/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6616 - accuracy: 0.5960 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 222/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6610 - accuracy: 0.6175 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 223/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6188 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 224/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6609 - accuracy: 0.6234 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 225/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6615 - accuracy: 0.6234 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 226/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 227/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.6234 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 228/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6608 - accuracy: 0.6170 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 229/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6165 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 230/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6175 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 231/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.6617 - accuracy: 0.6257 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 232/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.6184 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 233/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6612 - accuracy: 0.6229 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 234/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6197 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 235/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6106 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 236/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6170 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 237/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6615 - accuracy: 0.6229 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 238/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6611 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 239/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6608 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 240/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6610 - accuracy: 0.6266 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 241/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6609 - accuracy: 0.6184 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 242/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6197 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 243/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6609 - accuracy: 0.6229 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 244/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6202 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 245/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6211 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 246/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 247/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6225 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 248/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6606 - accuracy: 0.6234 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 249/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6615 - accuracy: 0.6179 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 250/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 251/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6225 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 252/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6175 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 253/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 254/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 255/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6615 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 256/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6608 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 257/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6613 - accuracy: 0.6156 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 258/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6193 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 259/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6613 - accuracy: 0.6184 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 260/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6608 - accuracy: 0.6193 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 261/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6047 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 262/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6065 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 263/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6611 - accuracy: 0.6120 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 264/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6613 - accuracy: 0.6106 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 265/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6170 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 266/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6207 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 267/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 268/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6165 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 269/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6613 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 270/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6175 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 271/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6193 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 272/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6165 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 273/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6220 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 274/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6609 - accuracy: 0.6202 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 275/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6614 - accuracy: 0.6175 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 276/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.6037 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 277/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.6608 - accuracy: 0.6197 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 278/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6614 - accuracy: 0.6101 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 279/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6216 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 280/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6611 - accuracy: 0.6220 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 281/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6211 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 282/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6610 - accuracy: 0.6266 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 283/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.6275 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 284/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6612 - accuracy: 0.6101 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 285/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.6610 - accuracy: 0.6019 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 286/500\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6614 - accuracy: 0.5900 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 287/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6612 - accuracy: 0.6138 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 288/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.6193 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 289/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.6106 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 290/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6612 - accuracy: 0.6079 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 291/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6609 - accuracy: 0.6165 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 292/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.5951 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 293/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6614 - accuracy: 0.6106 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 294/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6197 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 295/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6613 - accuracy: 0.6083 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 296/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6611 - accuracy: 0.6124 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 297/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6610 - accuracy: 0.6188 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 298/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6609 - accuracy: 0.6097 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 299/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6001 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 300/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.5969 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 301/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6612 - accuracy: 0.6143 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 302/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6033 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 303/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6156 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 304/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6152 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 305/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6143 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 306/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6202 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 307/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6179 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 308/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6207 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 309/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6197 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 310/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6239 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 311/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6611 - accuracy: 0.6211 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 312/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6612 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 313/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 314/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6225 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 315/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6266 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 316/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 317/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 318/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 319/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6616 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 320/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6275 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 321/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 322/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6225 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 323/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 324/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6243 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 325/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6225 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 326/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 327/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 328/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6220 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 329/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6239 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 330/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 331/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6234 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 332/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 333/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6609 - accuracy: 0.6271 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 334/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 335/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 336/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 337/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6248 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 338/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6604 - accuracy: 0.6266 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 339/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6614 - accuracy: 0.6234 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 340/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 341/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 342/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 343/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6613 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 344/500\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 345/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6612 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 346/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6612 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 347/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 348/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 349/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.6266 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 350/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 351/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6261 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 352/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 353/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 354/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 355/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 356/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6610 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 357/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 358/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6608 - accuracy: 0.6271 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 359/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6033 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 360/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6207 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 361/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6243 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 362/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6234 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 363/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 364/500\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 365/500\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6609 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 366/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6266 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 367/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6619 - accuracy: 0.6243 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 368/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6610 - accuracy: 0.6202 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 369/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6617 - accuracy: 0.5951 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 370/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6621 - accuracy: 0.4269 - val_loss: 0.6523 - val_accuracy: 0.3565\n",
      "Epoch 371/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6613 - accuracy: 0.5941 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 372/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6607 - accuracy: 0.5768 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 373/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6613 - accuracy: 0.6207 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 374/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6613 - accuracy: 0.6216 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 375/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6234 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 376/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6613 - accuracy: 0.6170 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 377/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6152 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 378/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6124 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 379/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.6229 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 380/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6602 - accuracy: 0.6225 - val_loss: 0.6514 - val_accuracy: 0.6435\n",
      "Epoch 381/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6635 - accuracy: 0.5768 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 382/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6615 - accuracy: 0.6207 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 383/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6207 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 384/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6614 - accuracy: 0.6033 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 385/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6614 - accuracy: 0.6129 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 386/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6161 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 387/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6143 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 388/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6611 - accuracy: 0.6266 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 389/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6225 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 390/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6188 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 391/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6613 - accuracy: 0.6115 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 392/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6609 - accuracy: 0.5777 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 393/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6607 - accuracy: 0.5832 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 394/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6609 - accuracy: 0.5658 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 395/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6614 - accuracy: 0.5841 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 396/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6608 - accuracy: 0.5658 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 397/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6019 - val_loss: 0.6518 - val_accuracy: 0.6435\n",
      "Epoch 398/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.5745 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 399/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6613 - accuracy: 0.6015 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 400/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6170 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 401/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.5987 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 402/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6613 - accuracy: 0.6083 - val_loss: 0.6518 - val_accuracy: 0.6435\n",
      "Epoch 403/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.5900 - val_loss: 0.6518 - val_accuracy: 0.6435\n",
      "Epoch 404/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6065 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 405/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6613 - accuracy: 0.6079 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 406/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6211 - val_loss: 0.6518 - val_accuracy: 0.6435\n",
      "Epoch 407/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.6156 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 408/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6609 - accuracy: 0.6161 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 409/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6056 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 410/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6015 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 411/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6612 - accuracy: 0.6115 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 412/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6207 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 413/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6606 - accuracy: 0.6115 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 414/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6618 - accuracy: 0.6097 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 415/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6129 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 416/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6024 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 417/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.6175 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 418/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6124 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 419/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6616 - accuracy: 0.6165 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 420/500\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6612 - accuracy: 0.5731 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 421/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.5612 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 422/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6614 - accuracy: 0.5809 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 423/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.5987 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 424/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6202 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 425/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6613 - accuracy: 0.6211 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 426/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6184 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 427/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6019 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 428/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6120 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 429/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6138 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 430/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6612 - accuracy: 0.6225 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 431/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6266 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 432/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6621 - accuracy: 0.6133 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 433/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6601 - accuracy: 0.6138 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 434/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6613 - accuracy: 0.5827 - val_loss: 0.6524 - val_accuracy: 0.3565\n",
      "Epoch 435/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6618 - accuracy: 0.5814 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 436/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6607 - accuracy: 0.5978 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 437/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6606 - accuracy: 0.5941 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 438/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6616 - accuracy: 0.5987 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 439/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.6106 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 440/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6175 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 441/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6152 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 442/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6612 - accuracy: 0.6197 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 443/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6613 - accuracy: 0.6216 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 444/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6609 - accuracy: 0.6248 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 445/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6229 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 446/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6608 - accuracy: 0.6248 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 447/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6188 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 448/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6207 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 449/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6612 - accuracy: 0.6207 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 450/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6608 - accuracy: 0.6079 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 451/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6613 - accuracy: 0.5941 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 452/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6175 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 453/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6120 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 454/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6608 - accuracy: 0.5960 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 455/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6152 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 456/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6610 - accuracy: 0.6074 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 457/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6611 - accuracy: 0.6165 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 458/500\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6611 - accuracy: 0.6202 - val_loss: 0.6519 - val_accuracy: 0.6435\n",
      "Epoch 459/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6611 - accuracy: 0.6197 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 460/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6608 - accuracy: 0.6211 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 461/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6248 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 462/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6211 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 463/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6617 - accuracy: 0.6184 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 464/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6605 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 465/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6615 - accuracy: 0.6234 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 466/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6607 - accuracy: 0.6229 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 467/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6602 - accuracy: 0.5818 - val_loss: 0.6516 - val_accuracy: 0.6435\n",
      "Epoch 468/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6616 - accuracy: 0.6229 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 469/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6614 - accuracy: 0.6207 - val_loss: 0.6523 - val_accuracy: 0.6435\n",
      "Epoch 470/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6202 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 471/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6613 - accuracy: 0.6211 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 472/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6610 - accuracy: 0.6229 - val_loss: 0.6522 - val_accuracy: 0.6435\n",
      "Epoch 473/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 474/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6609 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 475/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6161 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 476/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6607 - accuracy: 0.6202 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 477/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6614 - accuracy: 0.6060 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 478/500\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6613 - accuracy: 0.6188 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 479/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6612 - accuracy: 0.6229 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 480/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 481/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6243 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 482/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 483/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6261 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 484/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 485/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6610 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 486/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 487/500\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6611 - accuracy: 0.6243 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 488/500\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6611 - accuracy: 0.6257 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 489/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6266 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 490/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 491/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6266 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 492/500\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6610 - accuracy: 0.6239 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 493/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 494/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6612 - accuracy: 0.6266 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 495/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6608 - accuracy: 0.6252 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 496/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6612 - accuracy: 0.6280 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 497/500\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6611 - accuracy: 0.6051 - val_loss: 0.6521 - val_accuracy: 0.6435\n",
      "Epoch 498/500\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6609 - accuracy: 0.6111 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 499/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6610 - accuracy: 0.6170 - val_loss: 0.6520 - val_accuracy: 0.6435\n",
      "Epoch 500/500\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6611 - accuracy: 0.6088 - val_loss: 0.6520 - val_accuracy: 0.6435\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 186\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# hypermodel.fit(X_train, Y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.000000  0.000000  0.000000       255\n",
      "           1   0.627193  1.000000  0.770889       429\n",
      "\n",
      "    accuracy                       0.627193       684\n",
      "   macro avg   0.313596  0.500000  0.385445       684\n",
      "weighted avg   0.393371  0.627193  0.483496       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "res.round()\n",
    "actual = []\n",
    "for num in res:\n",
    "    if num>0.5:\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,actual,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14f9e9c7fa0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "confusionmatrix = confusion_matrix(Y_test, actual)\n",
    "cm_display = ConfusionMatrixDisplay(confusionmatrix, display_labels=[0,1])\n",
    "cm_display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
