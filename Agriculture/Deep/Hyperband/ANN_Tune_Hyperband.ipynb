{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0      3   2   2  25   0   3  10   0   0   0   0   0   0   0   0   0   1   1\n",
      "1      3   3   1  61   0   3  10   0   0   0   0   0   0   0   0   0   7   1\n",
      "2      3   3   1  65   0   3  10   0   0   0   0   0   0   0   0   0   6   1\n",
      "3      3   2   1  49   0   3  10   0   0   0   1   0   0   0   0   0   5   1\n",
      "4      3   1   1  54   0   5   2   1   1   0   0   0   0   0   0   1   5   1\n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "3414   1   2   1  57   0   6   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3415   1   1   1  24   0   3   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3416   1   1   1  50   0   3  10   0   0   0   0   0   0   0   0   0   6   4\n",
      "3417   1   2   1  58   0   3   9   0   0   0   0   0   0   0   0   0   6   4\n",
      "3418   1   2   1   3   0   4  10   0   0   0   0   0   0   0   0   0   5   4\n",
      "\n",
      "[3419 rows x 18 columns]\n",
      "      0\n",
      "0     0\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "...  ..\n",
      "3414  1\n",
      "3415  1\n",
      "3416  1\n",
      "3417  0\n",
      "3418  1\n",
      "\n",
      "[3419 rows x 1 columns]\n",
      "(2735, 18)\n",
      "(2735, 1)\n",
      "Index(['Location of Incident', 'Time', 'Sex', 'Age', 'Intentional', 'Role',\n",
      "       'Injury Agent', 'Confined Space', 'Grain Involved', 'Alcohol/Drugs',\n",
      "       'Seatbelt', 'Helmet', 'ROPS', 'Agritourism', 'Other PPE',\n",
      "       'Drowning/Suffocation', 'Day', 'Season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('/Users/eddie/Downloads/Log In - AgInjuryNews (1).xlsx - Sheet1 (1) - Log In - AgInjuryNews (1).xlsx - Sheet1 (1).csv')\n",
    "\n",
    "X = pd.DataFrame(dataset.iloc[:,:18].values)\n",
    "Y = pd.DataFrame(dataset.iloc[:,18:].values)\n",
    "print(X)\n",
    "print(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=0)\n",
    "X_train, X_train_val, Y_train, Y_train_val = train_test_split(X,Y,test_size=0.2)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "features = pd.DataFrame(dataset.iloc[:,:18])\n",
    "features = features.columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(18,)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "\n",
    "  hp_units2 = hp.Int('units2', min_value=24, max_value=64, step=8)\n",
    "  model.add(keras.layers.Dense(units=hp_units2, activation='relu'))\n",
    "  model.add(keras.layers.Dense(units=hp_units2, activation='relu'))\n",
    "  model.add(keras.layers.Dense(units=hp_units2, activation='relu'))\n",
    "\n",
    "  hp_units3 = hp.Int('units3', min_value=4, max_value=24, step=4)\n",
    "  model.add(keras.layers.Dense(units=hp_units3, activation='relu'))\n",
    "  model.add(keras.layers.Dense(units=hp_units3, activation='relu'))\n",
    "  model.add(keras.layers.Dense(units=hp_units3, activation='relu'))\n",
    "  model.add(keras.layers.Dense(1))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4,1e-5,1e-6])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape = (18,)))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='ann_hyper',\n",
    "                     project_name='ann_hyper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 22s]\n",
      "val_accuracy: 0.4003656208515167\n",
      "\n",
      "Best val_accuracy So Far: 0.6435100436210632\n",
      "Total elapsed time: 00h 03m 21s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 256 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(X_train, Y_train, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "69/69 [==============================] - 15s 24ms/step - loss: 0.6865 - accuracy: 0.3684 - val_loss: 0.6828 - val_accuracy: 0.4004\n",
      "Epoch 2/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.6726 - accuracy: 0.3684 - val_loss: 0.6747 - val_accuracy: 0.4004\n",
      "Epoch 3/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.6596 - accuracy: 0.4013 - val_loss: 0.6695 - val_accuracy: 0.6271\n",
      "Epoch 4/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.6478 - accuracy: 0.5946 - val_loss: 0.6488 - val_accuracy: 0.6325\n",
      "Epoch 5/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.6367 - accuracy: 0.6079 - val_loss: 0.6538 - val_accuracy: 0.6325\n",
      "Epoch 6/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6370 - accuracy: 0.6257 - val_loss: 0.6455 - val_accuracy: 0.6380\n",
      "Epoch 7/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6343 - accuracy: 0.6042 - val_loss: 0.6520 - val_accuracy: 0.5795\n",
      "Epoch 8/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6284 - accuracy: 0.6120 - val_loss: 0.6517 - val_accuracy: 0.6508\n",
      "Epoch 9/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.6267 - accuracy: 0.6156 - val_loss: 0.6443 - val_accuracy: 0.6435\n",
      "Epoch 10/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.6237 - accuracy: 0.6069 - val_loss: 0.6511 - val_accuracy: 0.6325\n",
      "Epoch 11/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6221 - accuracy: 0.6330 - val_loss: 0.6473 - val_accuracy: 0.6307\n",
      "Epoch 12/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6177 - accuracy: 0.6252 - val_loss: 0.6485 - val_accuracy: 0.6252\n",
      "Epoch 13/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6192 - accuracy: 0.6284 - val_loss: 0.6443 - val_accuracy: 0.5777\n",
      "Epoch 14/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.6136 - accuracy: 0.6024 - val_loss: 0.6578 - val_accuracy: 0.6252\n",
      "Epoch 15/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.6126 - accuracy: 0.6403 - val_loss: 0.6568 - val_accuracy: 0.5887\n",
      "Epoch 16/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.6079 - accuracy: 0.6257 - val_loss: 0.6511 - val_accuracy: 0.6161\n",
      "Epoch 17/500\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.6040 - accuracy: 0.6344 - val_loss: 0.6553 - val_accuracy: 0.5704\n",
      "Epoch 18/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.5967 - accuracy: 0.6362 - val_loss: 0.6828 - val_accuracy: 0.6143\n",
      "Epoch 19/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6041 - accuracy: 0.6417 - val_loss: 0.6563 - val_accuracy: 0.6252\n",
      "Epoch 20/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5879 - accuracy: 0.6581 - val_loss: 0.6691 - val_accuracy: 0.5923\n",
      "Epoch 21/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.5932 - accuracy: 0.6408 - val_loss: 0.6596 - val_accuracy: 0.6069\n",
      "Epoch 22/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.5815 - accuracy: 0.6600 - val_loss: 0.6694 - val_accuracy: 0.6179\n",
      "Epoch 23/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.5789 - accuracy: 0.6622 - val_loss: 0.6648 - val_accuracy: 0.6106\n",
      "Epoch 24/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5692 - accuracy: 0.6718 - val_loss: 0.6891 - val_accuracy: 0.6179\n",
      "Epoch 25/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.5654 - accuracy: 0.6737 - val_loss: 0.7008 - val_accuracy: 0.6033\n",
      "Epoch 26/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.5545 - accuracy: 0.6782 - val_loss: 0.6832 - val_accuracy: 0.6179\n",
      "Epoch 27/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.5554 - accuracy: 0.6915 - val_loss: 0.6831 - val_accuracy: 0.6179\n",
      "Epoch 28/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.5587 - accuracy: 0.6700 - val_loss: 0.7041 - val_accuracy: 0.6106\n",
      "Epoch 29/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.6906 - val_loss: 0.7157 - val_accuracy: 0.6015\n",
      "Epoch 30/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.5303 - accuracy: 0.7057 - val_loss: 0.7262 - val_accuracy: 0.6216\n",
      "Epoch 31/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5333 - accuracy: 0.7139 - val_loss: 0.7344 - val_accuracy: 0.6033\n",
      "Epoch 32/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.5250 - accuracy: 0.7148 - val_loss: 0.7354 - val_accuracy: 0.5832\n",
      "Epoch 33/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.5173 - accuracy: 0.7134 - val_loss: 0.7484 - val_accuracy: 0.5832\n",
      "Epoch 34/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.5099 - accuracy: 0.7125 - val_loss: 0.7965 - val_accuracy: 0.6380\n",
      "Epoch 35/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.5133 - accuracy: 0.7125 - val_loss: 0.7769 - val_accuracy: 0.5960\n",
      "Epoch 36/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7340 - val_loss: 0.7716 - val_accuracy: 0.6197\n",
      "Epoch 37/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.4869 - accuracy: 0.7395 - val_loss: 0.8218 - val_accuracy: 0.5868\n",
      "Epoch 38/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.4811 - accuracy: 0.7450 - val_loss: 0.8864 - val_accuracy: 0.6033\n",
      "Epoch 39/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.4855 - accuracy: 0.7349 - val_loss: 0.8732 - val_accuracy: 0.6051\n",
      "Epoch 40/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4898 - accuracy: 0.7317 - val_loss: 0.8758 - val_accuracy: 0.6252\n",
      "Epoch 41/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7431 - val_loss: 0.8752 - val_accuracy: 0.6289\n",
      "Epoch 42/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.4643 - accuracy: 0.7422 - val_loss: 0.9252 - val_accuracy: 0.6307\n",
      "Epoch 43/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4743 - accuracy: 0.7317 - val_loss: 0.9232 - val_accuracy: 0.6143\n",
      "Epoch 44/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.4522 - accuracy: 0.7610 - val_loss: 0.9401 - val_accuracy: 0.6143\n",
      "Epoch 45/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.4470 - accuracy: 0.7601 - val_loss: 0.8851 - val_accuracy: 0.5795\n",
      "Epoch 46/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.4452 - accuracy: 0.7591 - val_loss: 0.9581 - val_accuracy: 0.5923\n",
      "Epoch 47/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7756 - val_loss: 1.1219 - val_accuracy: 0.6051\n",
      "Epoch 48/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7633 - val_loss: 1.1678 - val_accuracy: 0.5777\n",
      "Epoch 49/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.7715 - val_loss: 1.1270 - val_accuracy: 0.5814\n",
      "Epoch 50/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.4260 - accuracy: 0.7797 - val_loss: 1.0894 - val_accuracy: 0.5539\n",
      "Epoch 51/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4080 - accuracy: 0.7751 - val_loss: 1.1128 - val_accuracy: 0.5740\n",
      "Epoch 52/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.4064 - accuracy: 0.7719 - val_loss: 1.0803 - val_accuracy: 0.5777\n",
      "Epoch 53/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.3865 - accuracy: 0.7847 - val_loss: 1.2936 - val_accuracy: 0.5740\n",
      "Epoch 54/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.7802 - val_loss: 1.3697 - val_accuracy: 0.5887\n",
      "Epoch 55/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.7788 - val_loss: 1.7512 - val_accuracy: 0.5832\n",
      "Epoch 56/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.7907 - val_loss: 1.2324 - val_accuracy: 0.5612\n",
      "Epoch 57/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.7948 - val_loss: 1.3408 - val_accuracy: 0.6197\n",
      "Epoch 58/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.3708 - accuracy: 0.7943 - val_loss: 1.3347 - val_accuracy: 0.5960\n",
      "Epoch 59/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.3509 - accuracy: 0.8176 - val_loss: 1.5468 - val_accuracy: 0.6143\n",
      "Epoch 60/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.3648 - accuracy: 0.7975 - val_loss: 1.4291 - val_accuracy: 0.5996\n",
      "Epoch 61/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.3476 - accuracy: 0.8021 - val_loss: 1.5027 - val_accuracy: 0.5832\n",
      "Epoch 62/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3386 - accuracy: 0.8108 - val_loss: 1.5723 - val_accuracy: 0.5777\n",
      "Epoch 63/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.3584 - accuracy: 0.7998 - val_loss: 1.5119 - val_accuracy: 0.5338\n",
      "Epoch 64/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3353 - accuracy: 0.8108 - val_loss: 1.6319 - val_accuracy: 0.5740\n",
      "Epoch 65/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.3298 - accuracy: 0.8186 - val_loss: 1.7705 - val_accuracy: 0.5759\n",
      "Epoch 66/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3255 - accuracy: 0.8231 - val_loss: 1.7350 - val_accuracy: 0.5777\n",
      "Epoch 67/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.3230 - accuracy: 0.8236 - val_loss: 1.7114 - val_accuracy: 0.5558\n",
      "Epoch 68/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.3027 - accuracy: 0.8309 - val_loss: 1.8750 - val_accuracy: 0.5814\n",
      "Epoch 69/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.3205 - accuracy: 0.8240 - val_loss: 2.0004 - val_accuracy: 0.5960\n",
      "Epoch 70/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.3195 - accuracy: 0.8272 - val_loss: 1.6587 - val_accuracy: 0.5814\n",
      "Epoch 71/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.3122 - accuracy: 0.8368 - val_loss: 1.8083 - val_accuracy: 0.5759\n",
      "Epoch 72/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.3260 - accuracy: 0.8236 - val_loss: 1.9077 - val_accuracy: 0.5996\n",
      "Epoch 73/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2958 - accuracy: 0.8410 - val_loss: 2.0146 - val_accuracy: 0.5539\n",
      "Epoch 74/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.8318 - val_loss: 1.6576 - val_accuracy: 0.6051\n",
      "Epoch 75/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.3017 - accuracy: 0.8391 - val_loss: 1.9051 - val_accuracy: 0.5777\n",
      "Epoch 76/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2885 - accuracy: 0.8428 - val_loss: 1.9342 - val_accuracy: 0.5722\n",
      "Epoch 77/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2739 - accuracy: 0.8487 - val_loss: 2.0906 - val_accuracy: 0.5576\n",
      "Epoch 78/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2840 - accuracy: 0.8560 - val_loss: 1.7818 - val_accuracy: 0.5576\n",
      "Epoch 79/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2908 - accuracy: 0.8492 - val_loss: 1.8384 - val_accuracy: 0.5722\n",
      "Epoch 80/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2820 - accuracy: 0.8437 - val_loss: 2.1736 - val_accuracy: 0.5923\n",
      "Epoch 81/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2560 - accuracy: 0.8638 - val_loss: 2.2990 - val_accuracy: 0.5503\n",
      "Epoch 82/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2691 - accuracy: 0.8487 - val_loss: 2.2154 - val_accuracy: 0.5338\n",
      "Epoch 83/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2936 - accuracy: 0.8419 - val_loss: 1.9830 - val_accuracy: 0.5795\n",
      "Epoch 84/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2784 - accuracy: 0.8565 - val_loss: 1.9725 - val_accuracy: 0.5795\n",
      "Epoch 85/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2607 - accuracy: 0.8697 - val_loss: 2.0151 - val_accuracy: 0.5759\n",
      "Epoch 86/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2576 - accuracy: 0.8647 - val_loss: 2.0886 - val_accuracy: 0.5704\n",
      "Epoch 87/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2525 - accuracy: 0.8633 - val_loss: 1.9975 - val_accuracy: 0.5539\n",
      "Epoch 88/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2456 - accuracy: 0.8638 - val_loss: 2.3970 - val_accuracy: 0.5850\n",
      "Epoch 89/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2755 - accuracy: 0.8505 - val_loss: 2.1208 - val_accuracy: 0.5740\n",
      "Epoch 90/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2390 - accuracy: 0.8835 - val_loss: 2.1751 - val_accuracy: 0.5484\n",
      "Epoch 91/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2659 - accuracy: 0.8647 - val_loss: 2.2738 - val_accuracy: 0.5612\n",
      "Epoch 92/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2653 - accuracy: 0.8643 - val_loss: 1.8636 - val_accuracy: 0.5484\n",
      "Epoch 93/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2524 - accuracy: 0.8725 - val_loss: 2.1833 - val_accuracy: 0.5795\n",
      "Epoch 94/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2640 - accuracy: 0.8716 - val_loss: 1.8548 - val_accuracy: 0.5832\n",
      "Epoch 95/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.2285 - accuracy: 0.8848 - val_loss: 2.2876 - val_accuracy: 0.5740\n",
      "Epoch 96/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2181 - accuracy: 0.8867 - val_loss: 2.4864 - val_accuracy: 0.5503\n",
      "Epoch 97/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2208 - accuracy: 0.8780 - val_loss: 2.5841 - val_accuracy: 0.5576\n",
      "Epoch 98/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2152 - accuracy: 0.8949 - val_loss: 2.9139 - val_accuracy: 0.5905\n",
      "Epoch 99/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.8803 - val_loss: 2.7293 - val_accuracy: 0.5722\n",
      "Epoch 100/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2246 - accuracy: 0.8816 - val_loss: 2.5130 - val_accuracy: 0.5503\n",
      "Epoch 101/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2385 - accuracy: 0.8725 - val_loss: 2.2504 - val_accuracy: 0.5759\n",
      "Epoch 102/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2224 - accuracy: 0.8848 - val_loss: 2.5454 - val_accuracy: 0.5649\n",
      "Epoch 103/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2198 - accuracy: 0.8821 - val_loss: 2.7450 - val_accuracy: 0.5594\n",
      "Epoch 104/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2120 - accuracy: 0.8903 - val_loss: 2.7772 - val_accuracy: 0.5868\n",
      "Epoch 105/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2000 - accuracy: 0.8935 - val_loss: 2.9507 - val_accuracy: 0.5887\n",
      "Epoch 106/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2293 - accuracy: 0.8807 - val_loss: 2.2241 - val_accuracy: 0.5631\n",
      "Epoch 107/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2386 - accuracy: 0.8752 - val_loss: 2.4849 - val_accuracy: 0.5594\n",
      "Epoch 108/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2092 - accuracy: 0.8921 - val_loss: 2.5840 - val_accuracy: 0.5759\n",
      "Epoch 109/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2298 - accuracy: 0.8752 - val_loss: 2.5360 - val_accuracy: 0.5594\n",
      "Epoch 110/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2134 - accuracy: 0.8935 - val_loss: 2.7924 - val_accuracy: 0.5649\n",
      "Epoch 111/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2050 - accuracy: 0.8917 - val_loss: 2.9076 - val_accuracy: 0.5430\n",
      "Epoch 112/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2215 - accuracy: 0.8880 - val_loss: 2.8233 - val_accuracy: 0.5503\n",
      "Epoch 113/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2196 - accuracy: 0.8894 - val_loss: 2.5811 - val_accuracy: 0.5521\n",
      "Epoch 114/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1880 - accuracy: 0.9008 - val_loss: 3.1021 - val_accuracy: 0.5686\n",
      "Epoch 115/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1883 - accuracy: 0.9045 - val_loss: 3.1673 - val_accuracy: 0.5814\n",
      "Epoch 116/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1885 - accuracy: 0.9031 - val_loss: 3.3823 - val_accuracy: 0.5868\n",
      "Epoch 117/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2064 - accuracy: 0.8899 - val_loss: 2.7912 - val_accuracy: 0.5996\n",
      "Epoch 118/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1782 - accuracy: 0.9027 - val_loss: 3.4446 - val_accuracy: 0.5905\n",
      "Epoch 119/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.2007 - accuracy: 0.8972 - val_loss: 3.0052 - val_accuracy: 0.5649\n",
      "Epoch 120/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2031 - accuracy: 0.8990 - val_loss: 2.9548 - val_accuracy: 0.5905\n",
      "Epoch 121/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2218 - accuracy: 0.8894 - val_loss: 2.6673 - val_accuracy: 0.5941\n",
      "Epoch 122/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1842 - accuracy: 0.9104 - val_loss: 3.0045 - val_accuracy: 0.5795\n",
      "Epoch 123/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1975 - accuracy: 0.8995 - val_loss: 2.9124 - val_accuracy: 0.5923\n",
      "Epoch 124/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1736 - accuracy: 0.9122 - val_loss: 3.3572 - val_accuracy: 0.5722\n",
      "Epoch 125/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1762 - accuracy: 0.9118 - val_loss: 3.1939 - val_accuracy: 0.5631\n",
      "Epoch 126/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1825 - accuracy: 0.9045 - val_loss: 2.9736 - val_accuracy: 0.5594\n",
      "Epoch 127/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.1861 - accuracy: 0.9054 - val_loss: 3.0660 - val_accuracy: 0.5594\n",
      "Epoch 128/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1693 - accuracy: 0.9100 - val_loss: 3.3505 - val_accuracy: 0.5539\n",
      "Epoch 129/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1807 - accuracy: 0.9068 - val_loss: 3.6685 - val_accuracy: 0.5704\n",
      "Epoch 130/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1575 - accuracy: 0.9132 - val_loss: 3.9842 - val_accuracy: 0.5686\n",
      "Epoch 131/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1786 - accuracy: 0.9150 - val_loss: 3.2620 - val_accuracy: 0.5832\n",
      "Epoch 132/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2021 - accuracy: 0.8999 - val_loss: 2.7813 - val_accuracy: 0.5941\n",
      "Epoch 133/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2090 - accuracy: 0.8876 - val_loss: 3.0879 - val_accuracy: 0.5850\n",
      "Epoch 134/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1881 - accuracy: 0.9017 - val_loss: 3.2707 - val_accuracy: 0.5850\n",
      "Epoch 135/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1632 - accuracy: 0.9173 - val_loss: 3.7387 - val_accuracy: 0.5795\n",
      "Epoch 136/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1690 - accuracy: 0.9122 - val_loss: 3.2697 - val_accuracy: 0.5795\n",
      "Epoch 137/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1542 - accuracy: 0.9218 - val_loss: 3.4483 - val_accuracy: 0.5960\n",
      "Epoch 138/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1573 - accuracy: 0.9168 - val_loss: 3.6817 - val_accuracy: 0.5631\n",
      "Epoch 139/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1664 - accuracy: 0.9090 - val_loss: 3.6111 - val_accuracy: 0.5686\n",
      "Epoch 140/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1726 - accuracy: 0.9054 - val_loss: 3.2427 - val_accuracy: 0.5704\n",
      "Epoch 141/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1741 - accuracy: 0.9100 - val_loss: 3.7037 - val_accuracy: 0.6069\n",
      "Epoch 142/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1943 - accuracy: 0.8976 - val_loss: 3.0026 - val_accuracy: 0.5777\n",
      "Epoch 143/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1970 - accuracy: 0.9031 - val_loss: 2.4653 - val_accuracy: 0.5868\n",
      "Epoch 144/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1931 - accuracy: 0.9081 - val_loss: 2.8238 - val_accuracy: 0.5722\n",
      "Epoch 145/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1645 - accuracy: 0.9154 - val_loss: 2.6631 - val_accuracy: 0.5832\n",
      "Epoch 146/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1754 - accuracy: 0.9095 - val_loss: 2.6123 - val_accuracy: 0.6069\n",
      "Epoch 147/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1472 - accuracy: 0.9164 - val_loss: 3.3113 - val_accuracy: 0.5832\n",
      "Epoch 148/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1476 - accuracy: 0.9250 - val_loss: 3.3457 - val_accuracy: 0.5960\n",
      "Epoch 149/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.1557 - accuracy: 0.9232 - val_loss: 3.3148 - val_accuracy: 0.5612\n",
      "Epoch 150/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1975 - accuracy: 0.9059 - val_loss: 2.3330 - val_accuracy: 0.5814\n",
      "Epoch 151/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1592 - accuracy: 0.9218 - val_loss: 2.9975 - val_accuracy: 0.5740\n",
      "Epoch 152/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.2236 - accuracy: 0.8976 - val_loss: 2.2545 - val_accuracy: 0.5941\n",
      "Epoch 153/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1675 - accuracy: 0.9196 - val_loss: 2.7245 - val_accuracy: 0.5777\n",
      "Epoch 154/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1608 - accuracy: 0.9200 - val_loss: 2.7705 - val_accuracy: 0.5667\n",
      "Epoch 155/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1494 - accuracy: 0.9200 - val_loss: 3.0655 - val_accuracy: 0.5740\n",
      "Epoch 156/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1721 - accuracy: 0.9173 - val_loss: 2.7608 - val_accuracy: 0.5795\n",
      "Epoch 157/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1600 - accuracy: 0.9164 - val_loss: 2.6630 - val_accuracy: 0.6216\n",
      "Epoch 158/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1556 - accuracy: 0.9145 - val_loss: 2.9081 - val_accuracy: 0.5868\n",
      "Epoch 159/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1418 - accuracy: 0.9250 - val_loss: 3.0475 - val_accuracy: 0.5868\n",
      "Epoch 160/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.9232 - val_loss: 2.9644 - val_accuracy: 0.5850\n",
      "Epoch 161/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.1580 - accuracy: 0.9141 - val_loss: 2.8745 - val_accuracy: 0.5905\n",
      "Epoch 162/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1369 - accuracy: 0.9296 - val_loss: 3.3609 - val_accuracy: 0.5814\n",
      "Epoch 163/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1398 - accuracy: 0.9255 - val_loss: 3.2976 - val_accuracy: 0.5832\n",
      "Epoch 164/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1385 - accuracy: 0.9214 - val_loss: 3.6074 - val_accuracy: 0.5777\n",
      "Epoch 165/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1386 - accuracy: 0.9228 - val_loss: 3.6484 - val_accuracy: 0.5868\n",
      "Epoch 166/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1498 - accuracy: 0.9255 - val_loss: 3.1782 - val_accuracy: 0.5868\n",
      "Epoch 167/500\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 0.9159 - val_loss: 2.7009 - val_accuracy: 0.5923\n",
      "Epoch 168/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1614 - accuracy: 0.9200 - val_loss: 2.9280 - val_accuracy: 0.5850\n",
      "Epoch 169/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1401 - accuracy: 0.9273 - val_loss: 3.1764 - val_accuracy: 0.6143\n",
      "Epoch 170/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1626 - accuracy: 0.9214 - val_loss: 2.8801 - val_accuracy: 0.6033\n",
      "Epoch 171/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1680 - accuracy: 0.9136 - val_loss: 2.5799 - val_accuracy: 0.5832\n",
      "Epoch 172/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1401 - accuracy: 0.9186 - val_loss: 2.7719 - val_accuracy: 0.5850\n",
      "Epoch 173/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1513 - accuracy: 0.9191 - val_loss: 2.8689 - val_accuracy: 0.5887\n",
      "Epoch 174/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1546 - accuracy: 0.9246 - val_loss: 2.5200 - val_accuracy: 0.5667\n",
      "Epoch 175/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1428 - accuracy: 0.9228 - val_loss: 3.0919 - val_accuracy: 0.5795\n",
      "Epoch 176/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1477 - accuracy: 0.9196 - val_loss: 2.8071 - val_accuracy: 0.5430\n",
      "Epoch 177/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1540 - accuracy: 0.9228 - val_loss: 3.2854 - val_accuracy: 0.5759\n",
      "Epoch 178/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1546 - accuracy: 0.9168 - val_loss: 3.1903 - val_accuracy: 0.5740\n",
      "Epoch 179/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1439 - accuracy: 0.9228 - val_loss: 3.3880 - val_accuracy: 0.5722\n",
      "Epoch 180/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1532 - accuracy: 0.9209 - val_loss: 3.0181 - val_accuracy: 0.5777\n",
      "Epoch 181/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1698 - accuracy: 0.9127 - val_loss: 2.7370 - val_accuracy: 0.5740\n",
      "Epoch 182/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1491 - accuracy: 0.9209 - val_loss: 2.8940 - val_accuracy: 0.6015\n",
      "Epoch 183/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1326 - accuracy: 0.9260 - val_loss: 3.4012 - val_accuracy: 0.5923\n",
      "Epoch 184/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1251 - accuracy: 0.9324 - val_loss: 3.1145 - val_accuracy: 0.5941\n",
      "Epoch 185/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1348 - accuracy: 0.9241 - val_loss: 3.0642 - val_accuracy: 0.5704\n",
      "Epoch 186/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1410 - accuracy: 0.9269 - val_loss: 3.8220 - val_accuracy: 0.5612\n",
      "Epoch 187/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1570 - accuracy: 0.9141 - val_loss: 2.8234 - val_accuracy: 0.5759\n",
      "Epoch 188/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1450 - accuracy: 0.9255 - val_loss: 3.0915 - val_accuracy: 0.5740\n",
      "Epoch 189/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1426 - accuracy: 0.9241 - val_loss: 3.2366 - val_accuracy: 0.5850\n",
      "Epoch 190/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1519 - accuracy: 0.9200 - val_loss: 3.1558 - val_accuracy: 0.5832\n",
      "Epoch 191/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1528 - accuracy: 0.9223 - val_loss: 2.9619 - val_accuracy: 0.6015\n",
      "Epoch 192/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1480 - accuracy: 0.9269 - val_loss: 3.0879 - val_accuracy: 0.5850\n",
      "Epoch 193/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1384 - accuracy: 0.9218 - val_loss: 3.2128 - val_accuracy: 0.6015\n",
      "Epoch 194/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1203 - accuracy: 0.9369 - val_loss: 3.8417 - val_accuracy: 0.5759\n",
      "Epoch 195/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1239 - accuracy: 0.9282 - val_loss: 4.0132 - val_accuracy: 0.5795\n",
      "Epoch 196/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1733 - accuracy: 0.9090 - val_loss: 2.4121 - val_accuracy: 0.5558\n",
      "Epoch 197/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1769 - accuracy: 0.9132 - val_loss: 2.5518 - val_accuracy: 0.5814\n",
      "Epoch 198/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1326 - accuracy: 0.9337 - val_loss: 2.9585 - val_accuracy: 0.5631\n",
      "Epoch 199/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1582 - accuracy: 0.9132 - val_loss: 2.6065 - val_accuracy: 0.5850\n",
      "Epoch 200/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1422 - accuracy: 0.9232 - val_loss: 2.6258 - val_accuracy: 0.5631\n",
      "Epoch 201/500\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.1326 - accuracy: 0.9319 - val_loss: 3.3188 - val_accuracy: 0.6088\n",
      "Epoch 202/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1381 - accuracy: 0.9250 - val_loss: 3.3736 - val_accuracy: 0.5795\n",
      "Epoch 203/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1302 - accuracy: 0.9324 - val_loss: 3.2173 - val_accuracy: 0.5887\n",
      "Epoch 204/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1224 - accuracy: 0.9333 - val_loss: 3.2302 - val_accuracy: 0.5996\n",
      "Epoch 205/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1135 - accuracy: 0.9388 - val_loss: 3.5942 - val_accuracy: 0.5704\n",
      "Epoch 206/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1279 - accuracy: 0.9328 - val_loss: 3.2800 - val_accuracy: 0.5960\n",
      "Epoch 207/500\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.1256 - accuracy: 0.9319 - val_loss: 3.4594 - val_accuracy: 0.5850\n",
      "Epoch 208/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1444 - accuracy: 0.9250 - val_loss: 2.5329 - val_accuracy: 0.6069\n",
      "Epoch 209/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1229 - accuracy: 0.9351 - val_loss: 3.4598 - val_accuracy: 0.6051\n",
      "Epoch 210/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1064 - accuracy: 0.9383 - val_loss: 3.4393 - val_accuracy: 0.6143\n",
      "Epoch 211/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1107 - accuracy: 0.9401 - val_loss: 3.8729 - val_accuracy: 0.6234\n",
      "Epoch 212/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1306 - accuracy: 0.9328 - val_loss: 3.3445 - val_accuracy: 0.6033\n",
      "Epoch 213/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1284 - accuracy: 0.9310 - val_loss: 3.4348 - val_accuracy: 0.5832\n",
      "Epoch 214/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1646 - accuracy: 0.9072 - val_loss: 2.6303 - val_accuracy: 0.5868\n",
      "Epoch 215/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1617 - accuracy: 0.9223 - val_loss: 2.4929 - val_accuracy: 0.5759\n",
      "Epoch 216/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1396 - accuracy: 0.9255 - val_loss: 2.8222 - val_accuracy: 0.5941\n",
      "Epoch 217/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1191 - accuracy: 0.9328 - val_loss: 3.5867 - val_accuracy: 0.6124\n",
      "Epoch 218/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1253 - accuracy: 0.9351 - val_loss: 3.6574 - val_accuracy: 0.5978\n",
      "Epoch 219/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1336 - accuracy: 0.9260 - val_loss: 3.4864 - val_accuracy: 0.5850\n",
      "Epoch 220/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1241 - accuracy: 0.9324 - val_loss: 3.5755 - val_accuracy: 0.5686\n",
      "Epoch 221/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1262 - accuracy: 0.9250 - val_loss: 3.6989 - val_accuracy: 0.5759\n",
      "Epoch 222/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1603 - accuracy: 0.9182 - val_loss: 2.7908 - val_accuracy: 0.5704\n",
      "Epoch 223/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1271 - accuracy: 0.9324 - val_loss: 3.7920 - val_accuracy: 0.5759\n",
      "Epoch 224/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1458 - accuracy: 0.9250 - val_loss: 2.8363 - val_accuracy: 0.5814\n",
      "Epoch 225/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1275 - accuracy: 0.9305 - val_loss: 3.2574 - val_accuracy: 0.5795\n",
      "Epoch 226/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1180 - accuracy: 0.9351 - val_loss: 3.5686 - val_accuracy: 0.5704\n",
      "Epoch 227/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1176 - accuracy: 0.9378 - val_loss: 3.4066 - val_accuracy: 0.5832\n",
      "Epoch 228/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1280 - accuracy: 0.9287 - val_loss: 2.8724 - val_accuracy: 0.5923\n",
      "Epoch 229/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1147 - accuracy: 0.9337 - val_loss: 3.4951 - val_accuracy: 0.5996\n",
      "Epoch 230/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1193 - accuracy: 0.9310 - val_loss: 3.7312 - val_accuracy: 0.5960\n",
      "Epoch 231/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1218 - accuracy: 0.9333 - val_loss: 3.7160 - val_accuracy: 0.6069\n",
      "Epoch 232/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1105 - accuracy: 0.9397 - val_loss: 3.5782 - val_accuracy: 0.5832\n",
      "Epoch 233/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1054 - accuracy: 0.9365 - val_loss: 4.1859 - val_accuracy: 0.5978\n",
      "Epoch 234/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1146 - accuracy: 0.9337 - val_loss: 3.5147 - val_accuracy: 0.5887\n",
      "Epoch 235/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0948 - accuracy: 0.9433 - val_loss: 4.3610 - val_accuracy: 0.5887\n",
      "Epoch 236/500\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.1320 - accuracy: 0.9328 - val_loss: 3.6779 - val_accuracy: 0.5667\n",
      "Epoch 237/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1313 - accuracy: 0.9273 - val_loss: 3.7653 - val_accuracy: 0.5795\n",
      "Epoch 238/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1324 - accuracy: 0.9342 - val_loss: 3.3675 - val_accuracy: 0.5905\n",
      "Epoch 239/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1349 - accuracy: 0.9337 - val_loss: 2.9787 - val_accuracy: 0.5996\n",
      "Epoch 240/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1182 - accuracy: 0.9328 - val_loss: 3.2945 - val_accuracy: 0.5905\n",
      "Epoch 241/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1344 - accuracy: 0.9278 - val_loss: 2.9218 - val_accuracy: 0.5868\n",
      "Epoch 242/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1200 - accuracy: 0.9333 - val_loss: 3.6266 - val_accuracy: 0.5850\n",
      "Epoch 243/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1191 - accuracy: 0.9351 - val_loss: 3.6419 - val_accuracy: 0.5832\n",
      "Epoch 244/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1497 - accuracy: 0.9241 - val_loss: 2.7411 - val_accuracy: 0.5941\n",
      "Epoch 245/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1364 - accuracy: 0.9269 - val_loss: 2.8451 - val_accuracy: 0.5777\n",
      "Epoch 246/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1463 - accuracy: 0.9177 - val_loss: 3.7323 - val_accuracy: 0.5649\n",
      "Epoch 247/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1709 - accuracy: 0.9122 - val_loss: 2.6233 - val_accuracy: 0.5795\n",
      "Epoch 248/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1227 - accuracy: 0.9310 - val_loss: 3.6414 - val_accuracy: 0.5850\n",
      "Epoch 249/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1164 - accuracy: 0.9383 - val_loss: 4.0981 - val_accuracy: 0.6015\n",
      "Epoch 250/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1543 - accuracy: 0.9237 - val_loss: 2.8784 - val_accuracy: 0.5795\n",
      "Epoch 251/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1257 - accuracy: 0.9319 - val_loss: 3.1871 - val_accuracy: 0.5759\n",
      "Epoch 252/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1269 - accuracy: 0.9333 - val_loss: 2.8619 - val_accuracy: 0.5850\n",
      "Epoch 253/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1268 - accuracy: 0.9292 - val_loss: 2.9414 - val_accuracy: 0.5868\n",
      "Epoch 254/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1223 - accuracy: 0.9392 - val_loss: 3.2321 - val_accuracy: 0.5868\n",
      "Epoch 255/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1287 - accuracy: 0.9301 - val_loss: 2.8608 - val_accuracy: 0.5759\n",
      "Epoch 256/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1090 - accuracy: 0.9360 - val_loss: 3.2983 - val_accuracy: 0.5868\n",
      "Epoch 257/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1203 - accuracy: 0.9392 - val_loss: 2.9198 - val_accuracy: 0.5759\n",
      "Epoch 258/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1424 - accuracy: 0.9305 - val_loss: 3.1403 - val_accuracy: 0.5960\n",
      "Epoch 259/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1180 - accuracy: 0.9356 - val_loss: 3.0802 - val_accuracy: 0.5850\n",
      "Epoch 260/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1183 - accuracy: 0.9392 - val_loss: 3.2456 - val_accuracy: 0.5795\n",
      "Epoch 261/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1385 - accuracy: 0.9287 - val_loss: 2.6870 - val_accuracy: 0.5905\n",
      "Epoch 262/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1211 - accuracy: 0.9351 - val_loss: 3.1426 - val_accuracy: 0.5777\n",
      "Epoch 263/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1241 - accuracy: 0.9365 - val_loss: 2.7725 - val_accuracy: 0.5814\n",
      "Epoch 264/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1293 - accuracy: 0.9328 - val_loss: 3.0407 - val_accuracy: 0.5978\n",
      "Epoch 265/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1198 - accuracy: 0.9356 - val_loss: 2.7026 - val_accuracy: 0.5631\n",
      "Epoch 266/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1218 - accuracy: 0.9278 - val_loss: 3.1503 - val_accuracy: 0.6051\n",
      "Epoch 267/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1146 - accuracy: 0.9406 - val_loss: 3.5355 - val_accuracy: 0.5960\n",
      "Epoch 268/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1194 - accuracy: 0.9383 - val_loss: 3.0210 - val_accuracy: 0.5960\n",
      "Epoch 269/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0992 - accuracy: 0.9378 - val_loss: 3.5753 - val_accuracy: 0.5923\n",
      "Epoch 270/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1302 - accuracy: 0.9324 - val_loss: 2.7156 - val_accuracy: 0.5649\n",
      "Epoch 271/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1144 - accuracy: 0.9346 - val_loss: 3.0633 - val_accuracy: 0.5832\n",
      "Epoch 272/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1117 - accuracy: 0.9388 - val_loss: 2.9972 - val_accuracy: 0.5686\n",
      "Epoch 273/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1311 - accuracy: 0.9314 - val_loss: 2.9849 - val_accuracy: 0.5686\n",
      "Epoch 274/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1377 - accuracy: 0.9260 - val_loss: 2.4579 - val_accuracy: 0.5832\n",
      "Epoch 275/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1257 - accuracy: 0.9296 - val_loss: 2.9209 - val_accuracy: 0.5832\n",
      "Epoch 276/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1363 - accuracy: 0.9246 - val_loss: 3.0194 - val_accuracy: 0.5887\n",
      "Epoch 277/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1088 - accuracy: 0.9369 - val_loss: 3.3516 - val_accuracy: 0.5722\n",
      "Epoch 278/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0964 - accuracy: 0.9452 - val_loss: 3.6599 - val_accuracy: 0.5686\n",
      "Epoch 279/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0918 - accuracy: 0.9452 - val_loss: 4.0918 - val_accuracy: 0.5740\n",
      "Epoch 280/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0977 - accuracy: 0.9438 - val_loss: 4.5002 - val_accuracy: 0.6069\n",
      "Epoch 281/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1213 - accuracy: 0.9301 - val_loss: 3.8503 - val_accuracy: 0.6015\n",
      "Epoch 282/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1160 - accuracy: 0.9374 - val_loss: 3.7082 - val_accuracy: 0.5941\n",
      "Epoch 283/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1381 - accuracy: 0.9292 - val_loss: 2.8458 - val_accuracy: 0.5777\n",
      "Epoch 284/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1311 - accuracy: 0.9324 - val_loss: 2.5378 - val_accuracy: 0.5814\n",
      "Epoch 285/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1080 - accuracy: 0.9442 - val_loss: 2.7585 - val_accuracy: 0.5832\n",
      "Epoch 286/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1049 - accuracy: 0.9470 - val_loss: 2.9912 - val_accuracy: 0.5978\n",
      "Epoch 287/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1233 - accuracy: 0.9337 - val_loss: 2.7948 - val_accuracy: 0.6088\n",
      "Epoch 288/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1210 - accuracy: 0.9360 - val_loss: 2.9302 - val_accuracy: 0.5832\n",
      "Epoch 289/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1063 - accuracy: 0.9447 - val_loss: 3.2113 - val_accuracy: 0.5941\n",
      "Epoch 290/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1063 - accuracy: 0.9442 - val_loss: 3.6159 - val_accuracy: 0.6069\n",
      "Epoch 291/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9383 - val_loss: 3.4186 - val_accuracy: 0.5923\n",
      "Epoch 292/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1094 - accuracy: 0.9328 - val_loss: 3.4137 - val_accuracy: 0.5795\n",
      "Epoch 293/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1167 - accuracy: 0.9346 - val_loss: 3.5146 - val_accuracy: 0.5941\n",
      "Epoch 294/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1016 - accuracy: 0.9447 - val_loss: 3.1513 - val_accuracy: 0.5795\n",
      "Epoch 295/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0987 - accuracy: 0.9433 - val_loss: 3.3563 - val_accuracy: 0.5704\n",
      "Epoch 296/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1037 - accuracy: 0.9378 - val_loss: 3.6646 - val_accuracy: 0.5722\n",
      "Epoch 297/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0920 - accuracy: 0.9452 - val_loss: 4.6622 - val_accuracy: 0.5996\n",
      "Epoch 298/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1604 - accuracy: 0.9132 - val_loss: 3.1094 - val_accuracy: 0.5759\n",
      "Epoch 299/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.1108 - accuracy: 0.9433 - val_loss: 3.6621 - val_accuracy: 0.5814\n",
      "Epoch 300/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1271 - accuracy: 0.9310 - val_loss: 3.2571 - val_accuracy: 0.5704\n",
      "Epoch 301/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1112 - accuracy: 0.9401 - val_loss: 3.2484 - val_accuracy: 0.5887\n",
      "Epoch 302/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9378 - val_loss: 2.9212 - val_accuracy: 0.5887\n",
      "Epoch 303/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1030 - accuracy: 0.9433 - val_loss: 3.4491 - val_accuracy: 0.5759\n",
      "Epoch 304/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1017 - accuracy: 0.9442 - val_loss: 3.4170 - val_accuracy: 0.6124\n",
      "Epoch 305/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1214 - accuracy: 0.9346 - val_loss: 2.7455 - val_accuracy: 0.6015\n",
      "Epoch 306/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1301 - accuracy: 0.9324 - val_loss: 2.6036 - val_accuracy: 0.5704\n",
      "Epoch 307/500\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1184 - accuracy: 0.9383 - val_loss: 3.0656 - val_accuracy: 0.5868\n",
      "Epoch 308/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0966 - accuracy: 0.9461 - val_loss: 3.4192 - val_accuracy: 0.6015\n",
      "Epoch 309/500\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1238 - accuracy: 0.9360 - val_loss: 2.5452 - val_accuracy: 0.5868\n",
      "Epoch 310/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0920 - accuracy: 0.9493 - val_loss: 3.4206 - val_accuracy: 0.5905\n",
      "Epoch 311/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0950 - accuracy: 0.9474 - val_loss: 3.5025 - val_accuracy: 0.5887\n",
      "Epoch 312/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1016 - accuracy: 0.9397 - val_loss: 3.5584 - val_accuracy: 0.6088\n",
      "Epoch 313/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 0.9461 - val_loss: 3.9685 - val_accuracy: 0.6015\n",
      "Epoch 314/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.1107 - accuracy: 0.9406 - val_loss: 3.5206 - val_accuracy: 0.5795\n",
      "Epoch 315/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1224 - accuracy: 0.9401 - val_loss: 2.8264 - val_accuracy: 0.5832\n",
      "Epoch 316/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1267 - accuracy: 0.9333 - val_loss: 2.8820 - val_accuracy: 0.5960\n",
      "Epoch 317/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1664 - accuracy: 0.9136 - val_loss: 2.1438 - val_accuracy: 0.5996\n",
      "Epoch 318/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0975 - accuracy: 0.9461 - val_loss: 3.5564 - val_accuracy: 0.5960\n",
      "Epoch 319/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1088 - accuracy: 0.9383 - val_loss: 2.7356 - val_accuracy: 0.5795\n",
      "Epoch 320/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1113 - accuracy: 0.9410 - val_loss: 3.0585 - val_accuracy: 0.5850\n",
      "Epoch 321/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1040 - accuracy: 0.9424 - val_loss: 3.3150 - val_accuracy: 0.5941\n",
      "Epoch 322/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1119 - accuracy: 0.9337 - val_loss: 3.2100 - val_accuracy: 0.5996\n",
      "Epoch 323/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0997 - accuracy: 0.9415 - val_loss: 3.5678 - val_accuracy: 0.6088\n",
      "Epoch 324/500\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1120 - accuracy: 0.9356 - val_loss: 3.5598 - val_accuracy: 0.5941\n",
      "Epoch 325/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1122 - accuracy: 0.9410 - val_loss: 3.7081 - val_accuracy: 0.6051\n",
      "Epoch 326/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0987 - accuracy: 0.9474 - val_loss: 3.7262 - val_accuracy: 0.5887\n",
      "Epoch 327/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1080 - accuracy: 0.9388 - val_loss: 3.4448 - val_accuracy: 0.5941\n",
      "Epoch 328/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0971 - accuracy: 0.9502 - val_loss: 3.4144 - val_accuracy: 0.5814\n",
      "Epoch 329/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0845 - accuracy: 0.9493 - val_loss: 4.2004 - val_accuracy: 0.6124\n",
      "Epoch 330/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1157 - accuracy: 0.9305 - val_loss: 3.3700 - val_accuracy: 0.5905\n",
      "Epoch 331/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1106 - accuracy: 0.9420 - val_loss: 3.4358 - val_accuracy: 0.5978\n",
      "Epoch 332/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.9461 - val_loss: 4.0331 - val_accuracy: 0.6051\n",
      "Epoch 333/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1405 - accuracy: 0.9301 - val_loss: 2.4184 - val_accuracy: 0.5649\n",
      "Epoch 334/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1237 - accuracy: 0.9356 - val_loss: 3.2316 - val_accuracy: 0.6015\n",
      "Epoch 335/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1312 - accuracy: 0.9351 - val_loss: 2.6247 - val_accuracy: 0.5941\n",
      "Epoch 336/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1235 - accuracy: 0.9365 - val_loss: 2.9044 - val_accuracy: 0.5978\n",
      "Epoch 337/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1100 - accuracy: 0.9401 - val_loss: 2.9319 - val_accuracy: 0.5996\n",
      "Epoch 338/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1165 - accuracy: 0.9383 - val_loss: 2.8778 - val_accuracy: 0.5996\n",
      "Epoch 339/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1142 - accuracy: 0.9410 - val_loss: 2.9221 - val_accuracy: 0.5941\n",
      "Epoch 340/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1241 - accuracy: 0.9360 - val_loss: 2.4892 - val_accuracy: 0.6033\n",
      "Epoch 341/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1124 - accuracy: 0.9420 - val_loss: 2.6408 - val_accuracy: 0.6033\n",
      "Epoch 342/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0910 - accuracy: 0.9461 - val_loss: 3.2357 - val_accuracy: 0.5795\n",
      "Epoch 343/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0932 - accuracy: 0.9420 - val_loss: 3.4835 - val_accuracy: 0.5923\n",
      "Epoch 344/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0972 - accuracy: 0.9456 - val_loss: 3.3955 - val_accuracy: 0.5868\n",
      "Epoch 345/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1315 - accuracy: 0.9365 - val_loss: 2.9453 - val_accuracy: 0.5905\n",
      "Epoch 346/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0881 - accuracy: 0.9516 - val_loss: 3.0844 - val_accuracy: 0.6124\n",
      "Epoch 347/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1005 - accuracy: 0.9447 - val_loss: 3.0525 - val_accuracy: 0.5777\n",
      "Epoch 348/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1124 - accuracy: 0.9410 - val_loss: 2.7775 - val_accuracy: 0.5740\n",
      "Epoch 349/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1034 - accuracy: 0.9438 - val_loss: 2.7416 - val_accuracy: 0.5832\n",
      "Epoch 350/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0931 - accuracy: 0.9433 - val_loss: 3.1883 - val_accuracy: 0.5905\n",
      "Epoch 351/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.9392 - val_loss: 2.9268 - val_accuracy: 0.5960\n",
      "Epoch 352/500\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.0891 - accuracy: 0.9484 - val_loss: 3.6942 - val_accuracy: 0.5905\n",
      "Epoch 353/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1094 - accuracy: 0.9429 - val_loss: 2.5728 - val_accuracy: 0.6015\n",
      "Epoch 354/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1113 - accuracy: 0.9342 - val_loss: 2.7495 - val_accuracy: 0.6106\n",
      "Epoch 355/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0955 - accuracy: 0.9479 - val_loss: 3.1611 - val_accuracy: 0.5887\n",
      "Epoch 356/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1236 - accuracy: 0.9269 - val_loss: 2.8539 - val_accuracy: 0.6033\n",
      "Epoch 357/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1062 - accuracy: 0.9442 - val_loss: 2.8771 - val_accuracy: 0.6069\n",
      "Epoch 358/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1308 - accuracy: 0.9264 - val_loss: 2.6856 - val_accuracy: 0.5814\n",
      "Epoch 359/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1009 - accuracy: 0.9406 - val_loss: 3.3256 - val_accuracy: 0.5978\n",
      "Epoch 360/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0998 - accuracy: 0.9397 - val_loss: 3.2509 - val_accuracy: 0.5850\n",
      "Epoch 361/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1333 - accuracy: 0.9269 - val_loss: 2.9059 - val_accuracy: 0.5887\n",
      "Epoch 362/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0945 - accuracy: 0.9438 - val_loss: 3.2212 - val_accuracy: 0.6033\n",
      "Epoch 363/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0997 - accuracy: 0.9429 - val_loss: 3.8063 - val_accuracy: 0.5795\n",
      "Epoch 364/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0911 - accuracy: 0.9438 - val_loss: 3.9335 - val_accuracy: 0.5759\n",
      "Epoch 365/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0970 - accuracy: 0.9452 - val_loss: 3.5198 - val_accuracy: 0.5722\n",
      "Epoch 366/500\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.0869 - accuracy: 0.9470 - val_loss: 4.3193 - val_accuracy: 0.5612\n",
      "Epoch 367/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0829 - accuracy: 0.9502 - val_loss: 4.2187 - val_accuracy: 0.5941\n",
      "Epoch 368/500\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0861 - accuracy: 0.9497 - val_loss: 4.6424 - val_accuracy: 0.5649\n",
      "Epoch 369/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0891 - accuracy: 0.9493 - val_loss: 4.0257 - val_accuracy: 0.5777\n",
      "Epoch 370/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0861 - accuracy: 0.9452 - val_loss: 4.8113 - val_accuracy: 0.5740\n",
      "Epoch 371/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0980 - accuracy: 0.9447 - val_loss: 3.8780 - val_accuracy: 0.5996\n",
      "Epoch 372/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0988 - accuracy: 0.9433 - val_loss: 3.6563 - val_accuracy: 0.5923\n",
      "Epoch 373/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1329 - accuracy: 0.9264 - val_loss: 2.9775 - val_accuracy: 0.5704\n",
      "Epoch 374/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1051 - accuracy: 0.9447 - val_loss: 3.3030 - val_accuracy: 0.5722\n",
      "Epoch 375/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1131 - accuracy: 0.9429 - val_loss: 2.8652 - val_accuracy: 0.5777\n",
      "Epoch 376/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.9360 - val_loss: 2.9293 - val_accuracy: 0.5850\n",
      "Epoch 377/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0937 - accuracy: 0.9479 - val_loss: 3.3864 - val_accuracy: 0.5740\n",
      "Epoch 378/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1022 - accuracy: 0.9484 - val_loss: 2.8831 - val_accuracy: 0.5594\n",
      "Epoch 379/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0853 - accuracy: 0.9456 - val_loss: 3.4133 - val_accuracy: 0.5850\n",
      "Epoch 380/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0909 - accuracy: 0.9461 - val_loss: 3.5201 - val_accuracy: 0.5887\n",
      "Epoch 381/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0954 - accuracy: 0.9502 - val_loss: 3.1948 - val_accuracy: 0.5905\n",
      "Epoch 382/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0905 - accuracy: 0.9447 - val_loss: 3.8159 - val_accuracy: 0.5795\n",
      "Epoch 383/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0949 - accuracy: 0.9461 - val_loss: 3.4289 - val_accuracy: 0.5704\n",
      "Epoch 384/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1100 - accuracy: 0.9420 - val_loss: 3.2599 - val_accuracy: 0.5978\n",
      "Epoch 385/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1374 - accuracy: 0.9337 - val_loss: 2.1721 - val_accuracy: 0.5832\n",
      "Epoch 386/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1077 - accuracy: 0.9452 - val_loss: 2.5880 - val_accuracy: 0.5814\n",
      "Epoch 387/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1154 - accuracy: 0.9397 - val_loss: 2.6310 - val_accuracy: 0.5832\n",
      "Epoch 388/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1113 - accuracy: 0.9310 - val_loss: 2.7989 - val_accuracy: 0.5704\n",
      "Epoch 389/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1112 - accuracy: 0.9397 - val_loss: 2.9836 - val_accuracy: 0.5868\n",
      "Epoch 390/500\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.1092 - accuracy: 0.9388 - val_loss: 2.9797 - val_accuracy: 0.6069\n",
      "Epoch 391/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1032 - accuracy: 0.9392 - val_loss: 3.4351 - val_accuracy: 0.5905\n",
      "Epoch 392/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0928 - accuracy: 0.9442 - val_loss: 3.4140 - val_accuracy: 0.5722\n",
      "Epoch 393/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0939 - accuracy: 0.9520 - val_loss: 3.7176 - val_accuracy: 0.5814\n",
      "Epoch 394/500\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.1018 - accuracy: 0.9433 - val_loss: 3.1782 - val_accuracy: 0.5777\n",
      "Epoch 395/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1028 - accuracy: 0.9410 - val_loss: 3.3191 - val_accuracy: 0.5923\n",
      "Epoch 396/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1277 - accuracy: 0.9383 - val_loss: 2.3270 - val_accuracy: 0.5887\n",
      "Epoch 397/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1160 - accuracy: 0.9383 - val_loss: 2.3504 - val_accuracy: 0.5832\n",
      "Epoch 398/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1053 - accuracy: 0.9410 - val_loss: 2.6241 - val_accuracy: 0.5868\n",
      "Epoch 399/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0891 - accuracy: 0.9442 - val_loss: 3.3838 - val_accuracy: 0.5887\n",
      "Epoch 400/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0851 - accuracy: 0.9493 - val_loss: 3.6771 - val_accuracy: 0.5978\n",
      "Epoch 401/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0805 - accuracy: 0.9529 - val_loss: 3.6054 - val_accuracy: 0.5923\n",
      "Epoch 402/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0938 - accuracy: 0.9438 - val_loss: 3.2376 - val_accuracy: 0.6015\n",
      "Epoch 403/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0855 - accuracy: 0.9493 - val_loss: 3.4609 - val_accuracy: 0.5795\n",
      "Epoch 404/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0975 - accuracy: 0.9429 - val_loss: 3.2153 - val_accuracy: 0.5905\n",
      "Epoch 405/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0853 - accuracy: 0.9516 - val_loss: 3.5010 - val_accuracy: 0.5795\n",
      "Epoch 406/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0842 - accuracy: 0.9502 - val_loss: 3.5286 - val_accuracy: 0.5887\n",
      "Epoch 407/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1012 - accuracy: 0.9456 - val_loss: 3.1322 - val_accuracy: 0.5795\n",
      "Epoch 408/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1063 - accuracy: 0.9374 - val_loss: 3.6466 - val_accuracy: 0.5887\n",
      "Epoch 409/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0959 - accuracy: 0.9447 - val_loss: 3.6216 - val_accuracy: 0.5887\n",
      "Epoch 410/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9452 - val_loss: 2.9352 - val_accuracy: 0.5850\n",
      "Epoch 411/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0956 - accuracy: 0.9424 - val_loss: 3.3931 - val_accuracy: 0.5868\n",
      "Epoch 412/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1099 - accuracy: 0.9420 - val_loss: 3.0778 - val_accuracy: 0.5923\n",
      "Epoch 413/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0972 - accuracy: 0.9447 - val_loss: 3.3564 - val_accuracy: 0.5868\n",
      "Epoch 414/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0818 - accuracy: 0.9525 - val_loss: 4.0731 - val_accuracy: 0.5832\n",
      "Epoch 415/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0985 - accuracy: 0.9442 - val_loss: 3.1616 - val_accuracy: 0.5814\n",
      "Epoch 416/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1152 - accuracy: 0.9388 - val_loss: 3.1698 - val_accuracy: 0.5996\n",
      "Epoch 417/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0812 - accuracy: 0.9525 - val_loss: 3.9710 - val_accuracy: 0.6051\n",
      "Epoch 418/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0928 - accuracy: 0.9479 - val_loss: 3.4375 - val_accuracy: 0.5868\n",
      "Epoch 419/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9538 - val_loss: 3.7169 - val_accuracy: 0.5905\n",
      "Epoch 420/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0871 - accuracy: 0.9470 - val_loss: 4.0747 - val_accuracy: 0.5960\n",
      "Epoch 421/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1592 - accuracy: 0.9333 - val_loss: 1.8945 - val_accuracy: 0.5814\n",
      "Epoch 422/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0921 - accuracy: 0.9461 - val_loss: 2.8880 - val_accuracy: 0.5923\n",
      "Epoch 423/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0989 - accuracy: 0.9429 - val_loss: 2.8453 - val_accuracy: 0.5960\n",
      "Epoch 424/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0944 - accuracy: 0.9484 - val_loss: 2.9480 - val_accuracy: 0.5941\n",
      "Epoch 425/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0879 - accuracy: 0.9502 - val_loss: 3.1337 - val_accuracy: 0.6033\n",
      "Epoch 426/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0762 - accuracy: 0.9538 - val_loss: 3.3398 - val_accuracy: 0.6015\n",
      "Epoch 427/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.0928 - accuracy: 0.9474 - val_loss: 3.0289 - val_accuracy: 0.5960\n",
      "Epoch 428/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0957 - accuracy: 0.9452 - val_loss: 3.1984 - val_accuracy: 0.5795\n",
      "Epoch 429/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1286 - accuracy: 0.9292 - val_loss: 2.3752 - val_accuracy: 0.5722\n",
      "Epoch 430/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1177 - accuracy: 0.9342 - val_loss: 2.6413 - val_accuracy: 0.5978\n",
      "Epoch 431/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0978 - accuracy: 0.9465 - val_loss: 2.8073 - val_accuracy: 0.6051\n",
      "Epoch 432/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0978 - accuracy: 0.9452 - val_loss: 3.3151 - val_accuracy: 0.5832\n",
      "Epoch 433/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0990 - accuracy: 0.9456 - val_loss: 2.7749 - val_accuracy: 0.5777\n",
      "Epoch 434/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0904 - accuracy: 0.9484 - val_loss: 3.1145 - val_accuracy: 0.5686\n",
      "Epoch 435/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0940 - accuracy: 0.9525 - val_loss: 3.0976 - val_accuracy: 0.5795\n",
      "Epoch 436/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0934 - accuracy: 0.9488 - val_loss: 3.1705 - val_accuracy: 0.5704\n",
      "Epoch 437/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0986 - accuracy: 0.9493 - val_loss: 2.9561 - val_accuracy: 0.5631\n",
      "Epoch 438/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0883 - accuracy: 0.9516 - val_loss: 2.9995 - val_accuracy: 0.5704\n",
      "Epoch 439/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0793 - accuracy: 0.9488 - val_loss: 3.6826 - val_accuracy: 0.5722\n",
      "Epoch 440/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1173 - accuracy: 0.9392 - val_loss: 2.5684 - val_accuracy: 0.5868\n",
      "Epoch 441/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1097 - accuracy: 0.9415 - val_loss: 2.6578 - val_accuracy: 0.5905\n",
      "Epoch 442/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0815 - accuracy: 0.9529 - val_loss: 3.2708 - val_accuracy: 0.5960\n",
      "Epoch 443/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0830 - accuracy: 0.9525 - val_loss: 3.4278 - val_accuracy: 0.5905\n",
      "Epoch 444/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1024 - accuracy: 0.9493 - val_loss: 2.7059 - val_accuracy: 0.5850\n",
      "Epoch 445/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0827 - accuracy: 0.9534 - val_loss: 3.3966 - val_accuracy: 0.5887\n",
      "Epoch 446/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0760 - accuracy: 0.9525 - val_loss: 3.5140 - val_accuracy: 0.5814\n",
      "Epoch 447/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0809 - accuracy: 0.9516 - val_loss: 3.8185 - val_accuracy: 0.5887\n",
      "Epoch 448/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0937 - accuracy: 0.9474 - val_loss: 3.0599 - val_accuracy: 0.5905\n",
      "Epoch 449/500\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.1219 - accuracy: 0.9346 - val_loss: 2.5482 - val_accuracy: 0.5850\n",
      "Epoch 450/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1053 - accuracy: 0.9447 - val_loss: 3.3078 - val_accuracy: 0.5777\n",
      "Epoch 451/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0982 - accuracy: 0.9488 - val_loss: 3.0315 - val_accuracy: 0.5814\n",
      "Epoch 452/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0914 - accuracy: 0.9456 - val_loss: 3.3786 - val_accuracy: 0.5777\n",
      "Epoch 453/500\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.0973 - accuracy: 0.9406 - val_loss: 3.0145 - val_accuracy: 0.5649\n",
      "Epoch 454/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1071 - accuracy: 0.9424 - val_loss: 3.1797 - val_accuracy: 0.5832\n",
      "Epoch 455/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0810 - accuracy: 0.9525 - val_loss: 3.7918 - val_accuracy: 0.5832\n",
      "Epoch 456/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0889 - accuracy: 0.9474 - val_loss: 3.5076 - val_accuracy: 0.5777\n",
      "Epoch 457/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0942 - accuracy: 0.9442 - val_loss: 3.9125 - val_accuracy: 0.5996\n",
      "Epoch 458/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0957 - accuracy: 0.9511 - val_loss: 3.7395 - val_accuracy: 0.5996\n",
      "Epoch 459/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0986 - accuracy: 0.9516 - val_loss: 3.2831 - val_accuracy: 0.5887\n",
      "Epoch 460/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1177 - accuracy: 0.9410 - val_loss: 2.4006 - val_accuracy: 0.5960\n",
      "Epoch 461/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0930 - accuracy: 0.9520 - val_loss: 2.8470 - val_accuracy: 0.5941\n",
      "Epoch 462/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0771 - accuracy: 0.9548 - val_loss: 3.1783 - val_accuracy: 0.5740\n",
      "Epoch 463/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0790 - accuracy: 0.9561 - val_loss: 3.2989 - val_accuracy: 0.6069\n",
      "Epoch 464/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0894 - accuracy: 0.9516 - val_loss: 3.2884 - val_accuracy: 0.5960\n",
      "Epoch 465/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0792 - accuracy: 0.9552 - val_loss: 3.4622 - val_accuracy: 0.5905\n",
      "Epoch 466/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0866 - accuracy: 0.9470 - val_loss: 3.4837 - val_accuracy: 0.5759\n",
      "Epoch 467/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0868 - accuracy: 0.9488 - val_loss: 3.8140 - val_accuracy: 0.5960\n",
      "Epoch 468/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0743 - accuracy: 0.9575 - val_loss: 4.0718 - val_accuracy: 0.6033\n",
      "Epoch 469/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0893 - accuracy: 0.9534 - val_loss: 3.6253 - val_accuracy: 0.5814\n",
      "Epoch 470/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0736 - accuracy: 0.9584 - val_loss: 4.0754 - val_accuracy: 0.5887\n",
      "Epoch 471/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.0829 - accuracy: 0.9516 - val_loss: 3.8796 - val_accuracy: 0.5850\n",
      "Epoch 472/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.1249 - accuracy: 0.9383 - val_loss: 2.1115 - val_accuracy: 0.5814\n",
      "Epoch 473/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0904 - accuracy: 0.9502 - val_loss: 2.9049 - val_accuracy: 0.5905\n",
      "Epoch 474/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0868 - accuracy: 0.9552 - val_loss: 3.0622 - val_accuracy: 0.5814\n",
      "Epoch 475/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0984 - accuracy: 0.9484 - val_loss: 2.5380 - val_accuracy: 0.5759\n",
      "Epoch 476/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0955 - accuracy: 0.9479 - val_loss: 3.1326 - val_accuracy: 0.5850\n",
      "Epoch 477/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1041 - accuracy: 0.9479 - val_loss: 2.5938 - val_accuracy: 0.5814\n",
      "Epoch 478/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0826 - accuracy: 0.9538 - val_loss: 3.1512 - val_accuracy: 0.5832\n",
      "Epoch 479/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0797 - accuracy: 0.9534 - val_loss: 3.3688 - val_accuracy: 0.5795\n",
      "Epoch 480/500\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0737 - accuracy: 0.9543 - val_loss: 3.8248 - val_accuracy: 0.5777\n",
      "Epoch 481/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0800 - accuracy: 0.9502 - val_loss: 3.9552 - val_accuracy: 0.5832\n",
      "Epoch 482/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0806 - accuracy: 0.9506 - val_loss: 3.8441 - val_accuracy: 0.5759\n",
      "Epoch 483/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0976 - accuracy: 0.9488 - val_loss: 3.4094 - val_accuracy: 0.5832\n",
      "Epoch 484/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1025 - accuracy: 0.9474 - val_loss: 3.0304 - val_accuracy: 0.5777\n",
      "Epoch 485/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1030 - accuracy: 0.9438 - val_loss: 2.7306 - val_accuracy: 0.5777\n",
      "Epoch 486/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0935 - accuracy: 0.9493 - val_loss: 2.9814 - val_accuracy: 0.5887\n",
      "Epoch 487/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0978 - accuracy: 0.9438 - val_loss: 3.2130 - val_accuracy: 0.5941\n",
      "Epoch 488/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0914 - accuracy: 0.9529 - val_loss: 3.1233 - val_accuracy: 0.5777\n",
      "Epoch 489/500\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1206 - accuracy: 0.9447 - val_loss: 2.1494 - val_accuracy: 0.5832\n",
      "Epoch 490/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1144 - accuracy: 0.9424 - val_loss: 2.1438 - val_accuracy: 0.5777\n",
      "Epoch 491/500\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1101 - accuracy: 0.9442 - val_loss: 2.7332 - val_accuracy: 0.5868\n",
      "Epoch 492/500\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0974 - accuracy: 0.9502 - val_loss: 2.6736 - val_accuracy: 0.5887\n",
      "Epoch 493/500\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1084 - accuracy: 0.9438 - val_loss: 2.3733 - val_accuracy: 0.5923\n",
      "Epoch 494/500\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0996 - accuracy: 0.9447 - val_loss: 2.6218 - val_accuracy: 0.5704\n",
      "Epoch 495/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1181 - accuracy: 0.9447 - val_loss: 2.3057 - val_accuracy: 0.5777\n",
      "Epoch 496/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1023 - accuracy: 0.9397 - val_loss: 2.6103 - val_accuracy: 0.5905\n",
      "Epoch 497/500\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0742 - accuracy: 0.9575 - val_loss: 3.2858 - val_accuracy: 0.5777\n",
      "Epoch 498/500\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0753 - accuracy: 0.9525 - val_loss: 3.5561 - val_accuracy: 0.5686\n",
      "Epoch 499/500\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0934 - accuracy: 0.9447 - val_loss: 3.2055 - val_accuracy: 0.5832\n",
      "Epoch 500/500\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0979 - accuracy: 0.9456 - val_loss: 3.0289 - val_accuracy: 0.5941\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 470\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/467\n",
      "69/69 [==============================] - 20s 33ms/step - loss: 0.6715 - accuracy: 0.4374 - val_loss: 0.6697 - val_accuracy: 0.4004\n",
      "Epoch 2/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.6484 - accuracy: 0.5571 - val_loss: 0.6506 - val_accuracy: 0.6399\n",
      "Epoch 3/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.6399 - accuracy: 0.5914 - val_loss: 0.6504 - val_accuracy: 0.6344\n",
      "Epoch 4/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.6396 - accuracy: 0.5663 - val_loss: 0.6459 - val_accuracy: 0.6252\n",
      "Epoch 5/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6336 - accuracy: 0.6092 - val_loss: 0.6407 - val_accuracy: 0.5740\n",
      "Epoch 6/467\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.6323 - accuracy: 0.6037 - val_loss: 0.6376 - val_accuracy: 0.6161\n",
      "Epoch 7/467\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.6319 - accuracy: 0.5969 - val_loss: 0.6479 - val_accuracy: 0.5649\n",
      "Epoch 8/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6252 - accuracy: 0.6261 - val_loss: 0.6426 - val_accuracy: 0.5923\n",
      "Epoch 9/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6212 - accuracy: 0.6234 - val_loss: 0.6400 - val_accuracy: 0.6124\n",
      "Epoch 10/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.6182 - accuracy: 0.6312 - val_loss: 0.6379 - val_accuracy: 0.6234\n",
      "Epoch 11/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6212 - accuracy: 0.6069 - val_loss: 0.6420 - val_accuracy: 0.6472\n",
      "Epoch 12/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.6106 - accuracy: 0.6298 - val_loss: 0.6590 - val_accuracy: 0.6417\n",
      "Epoch 13/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.6081 - accuracy: 0.6280 - val_loss: 0.6481 - val_accuracy: 0.6362\n",
      "Epoch 14/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.6080 - accuracy: 0.6431 - val_loss: 0.6402 - val_accuracy: 0.5960\n",
      "Epoch 15/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.6034 - accuracy: 0.6440 - val_loss: 0.6497 - val_accuracy: 0.5832\n",
      "Epoch 16/467\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.5998 - accuracy: 0.6444 - val_loss: 0.6496 - val_accuracy: 0.6453\n",
      "Epoch 17/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.5936 - accuracy: 0.6376 - val_loss: 0.6543 - val_accuracy: 0.6307\n",
      "Epoch 18/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5892 - accuracy: 0.6380 - val_loss: 0.6647 - val_accuracy: 0.6252\n",
      "Epoch 19/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.5839 - accuracy: 0.6554 - val_loss: 0.6524 - val_accuracy: 0.6106\n",
      "Epoch 20/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.5749 - accuracy: 0.6622 - val_loss: 0.6606 - val_accuracy: 0.5740\n",
      "Epoch 21/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5823 - accuracy: 0.6495 - val_loss: 0.6706 - val_accuracy: 0.6252\n",
      "Epoch 22/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5740 - accuracy: 0.6522 - val_loss: 0.6778 - val_accuracy: 0.6106\n",
      "Epoch 23/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.5696 - accuracy: 0.6664 - val_loss: 0.6584 - val_accuracy: 0.6344\n",
      "Epoch 24/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.5641 - accuracy: 0.6650 - val_loss: 0.6886 - val_accuracy: 0.6069\n",
      "Epoch 25/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.5635 - accuracy: 0.6700 - val_loss: 0.6710 - val_accuracy: 0.6051\n",
      "Epoch 26/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.5560 - accuracy: 0.6810 - val_loss: 0.6819 - val_accuracy: 0.5576\n",
      "Epoch 27/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.5425 - accuracy: 0.6865 - val_loss: 0.7091 - val_accuracy: 0.6143\n",
      "Epoch 28/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.5349 - accuracy: 0.6856 - val_loss: 0.7297 - val_accuracy: 0.5704\n",
      "Epoch 29/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.5370 - accuracy: 0.6814 - val_loss: 0.7181 - val_accuracy: 0.6015\n",
      "Epoch 30/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.5318 - accuracy: 0.6842 - val_loss: 0.7522 - val_accuracy: 0.6179\n",
      "Epoch 31/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.5269 - accuracy: 0.6979 - val_loss: 0.7614 - val_accuracy: 0.5850\n",
      "Epoch 32/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.5239 - accuracy: 0.6961 - val_loss: 0.7438 - val_accuracy: 0.6325\n",
      "Epoch 33/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5119 - accuracy: 0.7057 - val_loss: 0.7469 - val_accuracy: 0.6362\n",
      "Epoch 34/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.5071 - accuracy: 0.7125 - val_loss: 0.7827 - val_accuracy: 0.5777\n",
      "Epoch 35/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.4993 - accuracy: 0.7144 - val_loss: 0.7642 - val_accuracy: 0.6234\n",
      "Epoch 36/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.4939 - accuracy: 0.7217 - val_loss: 0.8196 - val_accuracy: 0.6216\n",
      "Epoch 37/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.4858 - accuracy: 0.7322 - val_loss: 0.8416 - val_accuracy: 0.5704\n",
      "Epoch 38/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.4838 - accuracy: 0.7303 - val_loss: 0.8327 - val_accuracy: 0.6069\n",
      "Epoch 39/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.4643 - accuracy: 0.7409 - val_loss: 0.9549 - val_accuracy: 0.6088\n",
      "Epoch 40/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4733 - accuracy: 0.7308 - val_loss: 0.9055 - val_accuracy: 0.5996\n",
      "Epoch 41/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.4608 - accuracy: 0.7354 - val_loss: 0.9949 - val_accuracy: 0.6033\n",
      "Epoch 42/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.4628 - accuracy: 0.7431 - val_loss: 0.9760 - val_accuracy: 0.5576\n",
      "Epoch 43/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.4551 - accuracy: 0.7441 - val_loss: 0.9100 - val_accuracy: 0.5484\n",
      "Epoch 44/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.4587 - accuracy: 0.7413 - val_loss: 0.9511 - val_accuracy: 0.5941\n",
      "Epoch 45/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4461 - accuracy: 0.7564 - val_loss: 0.9108 - val_accuracy: 0.5777\n",
      "Epoch 46/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.4705 - accuracy: 0.7363 - val_loss: 0.8503 - val_accuracy: 0.6216\n",
      "Epoch 47/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4429 - accuracy: 0.7770 - val_loss: 1.0016 - val_accuracy: 0.5777\n",
      "Epoch 48/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.4244 - accuracy: 0.7797 - val_loss: 0.9908 - val_accuracy: 0.5631\n",
      "Epoch 49/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.4215 - accuracy: 0.7646 - val_loss: 1.0763 - val_accuracy: 0.5905\n",
      "Epoch 50/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.4023 - accuracy: 0.7838 - val_loss: 1.1340 - val_accuracy: 0.5941\n",
      "Epoch 51/467\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.4120 - accuracy: 0.7797 - val_loss: 1.2452 - val_accuracy: 0.6069\n",
      "Epoch 52/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.4003 - accuracy: 0.7856 - val_loss: 1.3152 - val_accuracy: 0.6033\n",
      "Epoch 53/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.3939 - accuracy: 0.7911 - val_loss: 1.3330 - val_accuracy: 0.5960\n",
      "Epoch 54/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.4063 - accuracy: 0.7669 - val_loss: 1.3732 - val_accuracy: 0.6015\n",
      "Epoch 55/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.4123 - accuracy: 0.7815 - val_loss: 1.1399 - val_accuracy: 0.5576\n",
      "Epoch 56/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.4015 - accuracy: 0.7756 - val_loss: 1.2962 - val_accuracy: 0.5740\n",
      "Epoch 57/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4293 - accuracy: 0.7596 - val_loss: 1.1268 - val_accuracy: 0.6197\n",
      "Epoch 58/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.3822 - accuracy: 0.7930 - val_loss: 1.2652 - val_accuracy: 0.5905\n",
      "Epoch 59/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3686 - accuracy: 0.8030 - val_loss: 1.3537 - val_accuracy: 0.5941\n",
      "Epoch 60/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.3620 - accuracy: 0.8012 - val_loss: 1.3314 - val_accuracy: 0.5978\n",
      "Epoch 61/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3665 - accuracy: 0.7994 - val_loss: 1.2057 - val_accuracy: 0.5612\n",
      "Epoch 62/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.3737 - accuracy: 0.7952 - val_loss: 1.1207 - val_accuracy: 0.5905\n",
      "Epoch 63/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.3514 - accuracy: 0.8039 - val_loss: 1.4280 - val_accuracy: 0.5704\n",
      "Epoch 64/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.3389 - accuracy: 0.8190 - val_loss: 1.5064 - val_accuracy: 0.6069\n",
      "Epoch 65/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.3476 - accuracy: 0.8099 - val_loss: 1.3975 - val_accuracy: 0.6143\n",
      "Epoch 66/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.3395 - accuracy: 0.8144 - val_loss: 1.3047 - val_accuracy: 0.5814\n",
      "Epoch 67/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.3362 - accuracy: 0.8227 - val_loss: 1.4438 - val_accuracy: 0.5996\n",
      "Epoch 68/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.3129 - accuracy: 0.8410 - val_loss: 1.5319 - val_accuracy: 0.5759\n",
      "Epoch 69/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.3292 - accuracy: 0.8195 - val_loss: 1.5755 - val_accuracy: 0.5960\n",
      "Epoch 70/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.3163 - accuracy: 0.8291 - val_loss: 1.6733 - val_accuracy: 0.5759\n",
      "Epoch 71/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.3022 - accuracy: 0.8432 - val_loss: 1.7510 - val_accuracy: 0.5686\n",
      "Epoch 72/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.2942 - accuracy: 0.8391 - val_loss: 1.9447 - val_accuracy: 0.6088\n",
      "Epoch 73/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2913 - accuracy: 0.8515 - val_loss: 1.9890 - val_accuracy: 0.5558\n",
      "Epoch 74/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.3111 - accuracy: 0.8346 - val_loss: 1.7238 - val_accuracy: 0.6015\n",
      "Epoch 75/467\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.8314 - val_loss: 1.4488 - val_accuracy: 0.6124\n",
      "Epoch 76/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2917 - accuracy: 0.8446 - val_loss: 1.9009 - val_accuracy: 0.5759\n",
      "Epoch 77/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2921 - accuracy: 0.8437 - val_loss: 1.8339 - val_accuracy: 0.5923\n",
      "Epoch 78/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2761 - accuracy: 0.8510 - val_loss: 2.0530 - val_accuracy: 0.5686\n",
      "Epoch 79/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2794 - accuracy: 0.8528 - val_loss: 2.2079 - val_accuracy: 0.5850\n",
      "Epoch 80/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.2977 - accuracy: 0.8350 - val_loss: 2.3938 - val_accuracy: 0.5941\n",
      "Epoch 81/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.3211 - accuracy: 0.8323 - val_loss: 1.4813 - val_accuracy: 0.5667\n",
      "Epoch 82/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2834 - accuracy: 0.8446 - val_loss: 1.9653 - val_accuracy: 0.5905\n",
      "Epoch 83/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2592 - accuracy: 0.8656 - val_loss: 2.5869 - val_accuracy: 0.6033\n",
      "Epoch 84/467\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2968 - accuracy: 0.8483 - val_loss: 1.9725 - val_accuracy: 0.5558\n",
      "Epoch 85/467\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.2703 - accuracy: 0.8524 - val_loss: 1.8822 - val_accuracy: 0.5905\n",
      "Epoch 86/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.2723 - accuracy: 0.8510 - val_loss: 2.0129 - val_accuracy: 0.5960\n",
      "Epoch 87/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.2638 - accuracy: 0.8652 - val_loss: 1.9793 - val_accuracy: 0.5832\n",
      "Epoch 88/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2567 - accuracy: 0.8601 - val_loss: 2.1514 - val_accuracy: 0.5868\n",
      "Epoch 89/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2424 - accuracy: 0.8656 - val_loss: 2.1705 - val_accuracy: 0.5594\n",
      "Epoch 90/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.2564 - accuracy: 0.8615 - val_loss: 2.0751 - val_accuracy: 0.5612\n",
      "Epoch 91/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2299 - accuracy: 0.8734 - val_loss: 2.2886 - val_accuracy: 0.5978\n",
      "Epoch 92/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2494 - accuracy: 0.8688 - val_loss: 2.0548 - val_accuracy: 0.5667\n",
      "Epoch 93/467\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.2503 - accuracy: 0.8684 - val_loss: 2.0889 - val_accuracy: 0.5649\n",
      "Epoch 94/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2380 - accuracy: 0.8766 - val_loss: 2.4070 - val_accuracy: 0.5832\n",
      "Epoch 95/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2683 - accuracy: 0.8679 - val_loss: 1.9287 - val_accuracy: 0.5759\n",
      "Epoch 96/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2302 - accuracy: 0.8784 - val_loss: 2.2305 - val_accuracy: 0.5814\n",
      "Epoch 97/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2312 - accuracy: 0.8789 - val_loss: 2.3771 - val_accuracy: 0.6106\n",
      "Epoch 98/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2321 - accuracy: 0.8752 - val_loss: 2.3427 - val_accuracy: 0.5814\n",
      "Epoch 99/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2311 - accuracy: 0.8789 - val_loss: 2.3309 - val_accuracy: 0.6088\n",
      "Epoch 100/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2442 - accuracy: 0.8766 - val_loss: 2.2403 - val_accuracy: 0.5777\n",
      "Epoch 101/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2176 - accuracy: 0.8935 - val_loss: 2.4982 - val_accuracy: 0.5941\n",
      "Epoch 102/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.2148 - accuracy: 0.8830 - val_loss: 2.2679 - val_accuracy: 0.5832\n",
      "Epoch 103/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.2077 - accuracy: 0.8917 - val_loss: 2.7168 - val_accuracy: 0.5887\n",
      "Epoch 104/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2415 - accuracy: 0.8771 - val_loss: 2.3004 - val_accuracy: 0.5722\n",
      "Epoch 105/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2313 - accuracy: 0.8793 - val_loss: 2.5008 - val_accuracy: 0.5740\n",
      "Epoch 106/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.2049 - accuracy: 0.8921 - val_loss: 2.7003 - val_accuracy: 0.6179\n",
      "Epoch 107/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.2471 - accuracy: 0.8766 - val_loss: 2.1059 - val_accuracy: 0.5594\n",
      "Epoch 108/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.2087 - accuracy: 0.8899 - val_loss: 2.7692 - val_accuracy: 0.6051\n",
      "Epoch 109/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.2473 - accuracy: 0.8862 - val_loss: 1.9236 - val_accuracy: 0.5923\n",
      "Epoch 110/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2003 - accuracy: 0.8931 - val_loss: 2.3673 - val_accuracy: 0.5832\n",
      "Epoch 111/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.2087 - accuracy: 0.8931 - val_loss: 2.3672 - val_accuracy: 0.5814\n",
      "Epoch 112/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1894 - accuracy: 0.8958 - val_loss: 2.4197 - val_accuracy: 0.5868\n",
      "Epoch 113/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.2063 - accuracy: 0.8835 - val_loss: 2.8348 - val_accuracy: 0.5759\n",
      "Epoch 114/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2006 - accuracy: 0.8899 - val_loss: 3.3132 - val_accuracy: 0.5996\n",
      "Epoch 115/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1915 - accuracy: 0.8967 - val_loss: 2.8274 - val_accuracy: 0.5704\n",
      "Epoch 116/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1954 - accuracy: 0.8931 - val_loss: 2.5373 - val_accuracy: 0.5466\n",
      "Epoch 117/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.2108 - accuracy: 0.8931 - val_loss: 2.5463 - val_accuracy: 0.5759\n",
      "Epoch 118/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1883 - accuracy: 0.9017 - val_loss: 2.7201 - val_accuracy: 0.5777\n",
      "Epoch 119/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1787 - accuracy: 0.9090 - val_loss: 3.1660 - val_accuracy: 0.5941\n",
      "Epoch 120/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.2026 - accuracy: 0.8935 - val_loss: 2.5344 - val_accuracy: 0.5887\n",
      "Epoch 121/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1845 - accuracy: 0.8995 - val_loss: 3.3388 - val_accuracy: 0.5411\n",
      "Epoch 122/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2125 - accuracy: 0.8981 - val_loss: 2.4619 - val_accuracy: 0.5740\n",
      "Epoch 123/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1999 - accuracy: 0.8963 - val_loss: 2.2227 - val_accuracy: 0.5795\n",
      "Epoch 124/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.2157 - accuracy: 0.8921 - val_loss: 2.1399 - val_accuracy: 0.5814\n",
      "Epoch 125/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2149 - accuracy: 0.8867 - val_loss: 2.1951 - val_accuracy: 0.6033\n",
      "Epoch 126/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1826 - accuracy: 0.9100 - val_loss: 2.6575 - val_accuracy: 0.5667\n",
      "Epoch 127/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1815 - accuracy: 0.8944 - val_loss: 2.9237 - val_accuracy: 0.5832\n",
      "Epoch 128/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1830 - accuracy: 0.9008 - val_loss: 2.9014 - val_accuracy: 0.6088\n",
      "Epoch 129/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1668 - accuracy: 0.9100 - val_loss: 3.4819 - val_accuracy: 0.6033\n",
      "Epoch 130/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1642 - accuracy: 0.9122 - val_loss: 3.3747 - val_accuracy: 0.5941\n",
      "Epoch 131/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1972 - accuracy: 0.8885 - val_loss: 2.5295 - val_accuracy: 0.5941\n",
      "Epoch 132/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1870 - accuracy: 0.8981 - val_loss: 3.0012 - val_accuracy: 0.5795\n",
      "Epoch 133/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1670 - accuracy: 0.9077 - val_loss: 2.9304 - val_accuracy: 0.5887\n",
      "Epoch 134/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1666 - accuracy: 0.9072 - val_loss: 3.0419 - val_accuracy: 0.5612\n",
      "Epoch 135/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.2338 - accuracy: 0.8871 - val_loss: 2.6141 - val_accuracy: 0.5777\n",
      "Epoch 136/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1908 - accuracy: 0.9090 - val_loss: 2.4327 - val_accuracy: 0.5667\n",
      "Epoch 137/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1666 - accuracy: 0.9118 - val_loss: 2.8814 - val_accuracy: 0.6051\n",
      "Epoch 138/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1800 - accuracy: 0.9063 - val_loss: 2.8306 - val_accuracy: 0.5740\n",
      "Epoch 139/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1811 - accuracy: 0.9072 - val_loss: 2.6016 - val_accuracy: 0.5795\n",
      "Epoch 140/467\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.1700 - accuracy: 0.9095 - val_loss: 3.2402 - val_accuracy: 0.5832\n",
      "Epoch 141/467\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.1768 - accuracy: 0.9072 - val_loss: 2.7890 - val_accuracy: 0.5667\n",
      "Epoch 142/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1787 - accuracy: 0.9113 - val_loss: 2.3997 - val_accuracy: 0.5686\n",
      "Epoch 143/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1723 - accuracy: 0.9059 - val_loss: 2.5876 - val_accuracy: 0.5704\n",
      "Epoch 144/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1748 - accuracy: 0.9077 - val_loss: 2.3941 - val_accuracy: 0.5887\n",
      "Epoch 145/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1663 - accuracy: 0.9141 - val_loss: 2.8737 - val_accuracy: 0.5960\n",
      "Epoch 146/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1614 - accuracy: 0.9145 - val_loss: 2.9098 - val_accuracy: 0.6033\n",
      "Epoch 147/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1782 - accuracy: 0.9054 - val_loss: 2.3738 - val_accuracy: 0.5960\n",
      "Epoch 148/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1602 - accuracy: 0.9200 - val_loss: 2.6104 - val_accuracy: 0.5722\n",
      "Epoch 149/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1399 - accuracy: 0.9264 - val_loss: 3.1353 - val_accuracy: 0.5941\n",
      "Epoch 150/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1724 - accuracy: 0.9095 - val_loss: 2.4453 - val_accuracy: 0.5905\n",
      "Epoch 151/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1641 - accuracy: 0.9132 - val_loss: 2.7250 - val_accuracy: 0.5923\n",
      "Epoch 152/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1532 - accuracy: 0.9141 - val_loss: 2.9364 - val_accuracy: 0.6051\n",
      "Epoch 153/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1763 - accuracy: 0.9100 - val_loss: 2.5291 - val_accuracy: 0.5484\n",
      "Epoch 154/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1497 - accuracy: 0.9154 - val_loss: 2.8773 - val_accuracy: 0.5832\n",
      "Epoch 155/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1517 - accuracy: 0.9118 - val_loss: 2.9550 - val_accuracy: 0.5667\n",
      "Epoch 156/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1534 - accuracy: 0.9159 - val_loss: 2.8745 - val_accuracy: 0.5814\n",
      "Epoch 157/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1559 - accuracy: 0.9118 - val_loss: 3.2400 - val_accuracy: 0.5759\n",
      "Epoch 158/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1447 - accuracy: 0.9191 - val_loss: 3.3293 - val_accuracy: 0.5850\n",
      "Epoch 159/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1751 - accuracy: 0.9068 - val_loss: 2.9329 - val_accuracy: 0.5923\n",
      "Epoch 160/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1715 - accuracy: 0.9104 - val_loss: 2.4322 - val_accuracy: 0.5631\n",
      "Epoch 161/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1702 - accuracy: 0.9090 - val_loss: 2.6881 - val_accuracy: 0.5941\n",
      "Epoch 162/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1667 - accuracy: 0.9109 - val_loss: 2.7458 - val_accuracy: 0.5759\n",
      "Epoch 163/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1439 - accuracy: 0.9164 - val_loss: 3.1989 - val_accuracy: 0.5558\n",
      "Epoch 164/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1575 - accuracy: 0.9136 - val_loss: 3.2172 - val_accuracy: 0.5850\n",
      "Epoch 165/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1922 - accuracy: 0.9049 - val_loss: 2.7290 - val_accuracy: 0.6015\n",
      "Epoch 166/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1684 - accuracy: 0.9104 - val_loss: 2.6252 - val_accuracy: 0.5686\n",
      "Epoch 167/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1522 - accuracy: 0.9232 - val_loss: 2.8339 - val_accuracy: 0.5740\n",
      "Epoch 168/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1406 - accuracy: 0.9232 - val_loss: 3.3912 - val_accuracy: 0.5941\n",
      "Epoch 169/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1400 - accuracy: 0.9191 - val_loss: 3.2243 - val_accuracy: 0.5704\n",
      "Epoch 170/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1269 - accuracy: 0.9255 - val_loss: 3.5675 - val_accuracy: 0.5759\n",
      "Epoch 171/467\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.1326 - accuracy: 0.9278 - val_loss: 3.8083 - val_accuracy: 0.5777\n",
      "Epoch 172/467\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.1611 - accuracy: 0.9086 - val_loss: 3.1834 - val_accuracy: 0.5868\n",
      "Epoch 173/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1899 - accuracy: 0.9072 - val_loss: 2.7029 - val_accuracy: 0.5905\n",
      "Epoch 174/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1496 - accuracy: 0.9205 - val_loss: 2.9587 - val_accuracy: 0.5521\n",
      "Epoch 175/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1773 - accuracy: 0.9059 - val_loss: 2.5524 - val_accuracy: 0.5850\n",
      "Epoch 176/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1716 - accuracy: 0.9168 - val_loss: 2.7806 - val_accuracy: 0.5941\n",
      "Epoch 177/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1502 - accuracy: 0.9214 - val_loss: 2.7626 - val_accuracy: 0.6051\n",
      "Epoch 178/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1688 - accuracy: 0.9200 - val_loss: 2.3908 - val_accuracy: 0.5722\n",
      "Epoch 179/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1595 - accuracy: 0.9173 - val_loss: 2.4148 - val_accuracy: 0.5887\n",
      "Epoch 180/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1468 - accuracy: 0.9209 - val_loss: 2.9971 - val_accuracy: 0.5777\n",
      "Epoch 181/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1398 - accuracy: 0.9246 - val_loss: 2.8392 - val_accuracy: 0.5740\n",
      "Epoch 182/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1525 - accuracy: 0.9214 - val_loss: 3.0351 - val_accuracy: 0.5612\n",
      "Epoch 183/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1411 - accuracy: 0.9237 - val_loss: 2.7216 - val_accuracy: 0.5777\n",
      "Epoch 184/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1527 - accuracy: 0.9200 - val_loss: 2.5231 - val_accuracy: 0.5448\n",
      "Epoch 185/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1521 - accuracy: 0.9214 - val_loss: 2.6967 - val_accuracy: 0.5667\n",
      "Epoch 186/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1750 - accuracy: 0.9186 - val_loss: 2.1045 - val_accuracy: 0.5539\n",
      "Epoch 187/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1588 - accuracy: 0.9196 - val_loss: 2.6380 - val_accuracy: 0.5923\n",
      "Epoch 188/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1927 - accuracy: 0.9081 - val_loss: 2.2576 - val_accuracy: 0.5832\n",
      "Epoch 189/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1565 - accuracy: 0.9209 - val_loss: 2.2881 - val_accuracy: 0.5923\n",
      "Epoch 190/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1454 - accuracy: 0.9250 - val_loss: 2.3474 - val_accuracy: 0.5704\n",
      "Epoch 191/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1311 - accuracy: 0.9296 - val_loss: 2.9084 - val_accuracy: 0.5649\n",
      "Epoch 192/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1361 - accuracy: 0.9324 - val_loss: 2.6619 - val_accuracy: 0.5612\n",
      "Epoch 193/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1472 - accuracy: 0.9223 - val_loss: 2.4663 - val_accuracy: 0.5740\n",
      "Epoch 194/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1447 - accuracy: 0.9164 - val_loss: 2.4446 - val_accuracy: 0.5686\n",
      "Epoch 195/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1253 - accuracy: 0.9292 - val_loss: 2.9112 - val_accuracy: 0.5941\n",
      "Epoch 196/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1298 - accuracy: 0.9324 - val_loss: 2.9332 - val_accuracy: 0.5722\n",
      "Epoch 197/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1487 - accuracy: 0.9196 - val_loss: 2.7548 - val_accuracy: 0.5759\n",
      "Epoch 198/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1258 - accuracy: 0.9292 - val_loss: 3.1620 - val_accuracy: 0.5704\n",
      "Epoch 199/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1500 - accuracy: 0.9168 - val_loss: 2.9800 - val_accuracy: 0.5594\n",
      "Epoch 200/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1489 - accuracy: 0.9145 - val_loss: 3.0076 - val_accuracy: 0.5740\n",
      "Epoch 201/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1425 - accuracy: 0.9196 - val_loss: 2.9229 - val_accuracy: 0.5667\n",
      "Epoch 202/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1261 - accuracy: 0.9269 - val_loss: 3.1608 - val_accuracy: 0.5740\n",
      "Epoch 203/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1340 - accuracy: 0.9319 - val_loss: 2.8209 - val_accuracy: 0.5759\n",
      "Epoch 204/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1310 - accuracy: 0.9237 - val_loss: 3.0826 - val_accuracy: 0.5850\n",
      "Epoch 205/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1362 - accuracy: 0.9228 - val_loss: 2.7498 - val_accuracy: 0.5795\n",
      "Epoch 206/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1476 - accuracy: 0.9191 - val_loss: 2.5593 - val_accuracy: 0.5814\n",
      "Epoch 207/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1490 - accuracy: 0.9214 - val_loss: 2.6590 - val_accuracy: 0.5759\n",
      "Epoch 208/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1524 - accuracy: 0.9136 - val_loss: 2.5123 - val_accuracy: 0.6033\n",
      "Epoch 209/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1354 - accuracy: 0.9255 - val_loss: 2.8408 - val_accuracy: 0.5795\n",
      "Epoch 210/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1252 - accuracy: 0.9314 - val_loss: 2.6851 - val_accuracy: 0.5594\n",
      "Epoch 211/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1534 - accuracy: 0.9218 - val_loss: 2.5100 - val_accuracy: 0.5704\n",
      "Epoch 212/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1473 - accuracy: 0.9264 - val_loss: 2.4249 - val_accuracy: 0.5612\n",
      "Epoch 213/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1372 - accuracy: 0.9237 - val_loss: 2.6365 - val_accuracy: 0.5704\n",
      "Epoch 214/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1465 - accuracy: 0.9228 - val_loss: 2.4254 - val_accuracy: 0.5704\n",
      "Epoch 215/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1316 - accuracy: 0.9232 - val_loss: 2.6135 - val_accuracy: 0.5832\n",
      "Epoch 216/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1428 - accuracy: 0.9250 - val_loss: 2.2946 - val_accuracy: 0.5631\n",
      "Epoch 217/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1658 - accuracy: 0.9209 - val_loss: 1.9186 - val_accuracy: 0.5539\n",
      "Epoch 218/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1526 - accuracy: 0.9223 - val_loss: 2.1822 - val_accuracy: 0.5649\n",
      "Epoch 219/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1377 - accuracy: 0.9269 - val_loss: 2.2638 - val_accuracy: 0.5832\n",
      "Epoch 220/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1588 - accuracy: 0.9196 - val_loss: 2.2972 - val_accuracy: 0.5722\n",
      "Epoch 221/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1231 - accuracy: 0.9296 - val_loss: 3.2771 - val_accuracy: 0.5795\n",
      "Epoch 222/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1294 - accuracy: 0.9287 - val_loss: 2.8441 - val_accuracy: 0.5649\n",
      "Epoch 223/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1517 - accuracy: 0.9186 - val_loss: 2.5404 - val_accuracy: 0.5612\n",
      "Epoch 224/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1327 - accuracy: 0.9250 - val_loss: 3.1624 - val_accuracy: 0.5667\n",
      "Epoch 225/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1548 - accuracy: 0.9200 - val_loss: 2.2643 - val_accuracy: 0.5649\n",
      "Epoch 226/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1182 - accuracy: 0.9324 - val_loss: 2.8738 - val_accuracy: 0.5558\n",
      "Epoch 227/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.1261 - accuracy: 0.9287 - val_loss: 3.2043 - val_accuracy: 0.5631\n",
      "Epoch 228/467\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.1248 - accuracy: 0.9305 - val_loss: 3.2340 - val_accuracy: 0.5558\n",
      "Epoch 229/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1177 - accuracy: 0.9301 - val_loss: 3.3107 - val_accuracy: 0.5795\n",
      "Epoch 230/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1185 - accuracy: 0.9301 - val_loss: 3.1554 - val_accuracy: 0.5667\n",
      "Epoch 231/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1174 - accuracy: 0.9360 - val_loss: 3.3508 - val_accuracy: 0.5722\n",
      "Epoch 232/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1095 - accuracy: 0.9374 - val_loss: 3.5193 - val_accuracy: 0.5905\n",
      "Epoch 233/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1135 - accuracy: 0.9333 - val_loss: 3.6969 - val_accuracy: 0.5905\n",
      "Epoch 234/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1724 - accuracy: 0.9113 - val_loss: 2.1482 - val_accuracy: 0.5704\n",
      "Epoch 235/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1369 - accuracy: 0.9241 - val_loss: 2.8893 - val_accuracy: 0.5777\n",
      "Epoch 236/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1321 - accuracy: 0.9246 - val_loss: 2.5736 - val_accuracy: 0.5777\n",
      "Epoch 237/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1230 - accuracy: 0.9328 - val_loss: 3.0189 - val_accuracy: 0.5832\n",
      "Epoch 238/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1496 - accuracy: 0.9200 - val_loss: 2.5375 - val_accuracy: 0.5722\n",
      "Epoch 239/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1405 - accuracy: 0.9260 - val_loss: 2.3351 - val_accuracy: 0.5923\n",
      "Epoch 240/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1225 - accuracy: 0.9310 - val_loss: 2.7258 - val_accuracy: 0.5631\n",
      "Epoch 241/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1092 - accuracy: 0.9383 - val_loss: 3.1244 - val_accuracy: 0.5777\n",
      "Epoch 242/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.1098 - accuracy: 0.9360 - val_loss: 3.4466 - val_accuracy: 0.5722\n",
      "Epoch 243/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1463 - accuracy: 0.9200 - val_loss: 3.1359 - val_accuracy: 0.5539\n",
      "Epoch 244/467\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.1583 - accuracy: 0.9214 - val_loss: 2.2001 - val_accuracy: 0.5576\n",
      "Epoch 245/467\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.1772 - accuracy: 0.9168 - val_loss: 2.8425 - val_accuracy: 0.5649\n",
      "Epoch 246/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1202 - accuracy: 0.9314 - val_loss: 3.2324 - val_accuracy: 0.5558\n",
      "Epoch 247/467\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.1371 - accuracy: 0.9264 - val_loss: 2.8154 - val_accuracy: 0.5686\n",
      "Epoch 248/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1381 - accuracy: 0.9273 - val_loss: 3.1986 - val_accuracy: 0.5466\n",
      "Epoch 249/467\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1606 - accuracy: 0.9182 - val_loss: 1.9894 - val_accuracy: 0.5759\n",
      "Epoch 250/467\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1236 - accuracy: 0.9337 - val_loss: 2.4311 - val_accuracy: 0.5667\n",
      "Epoch 251/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1095 - accuracy: 0.9429 - val_loss: 2.9921 - val_accuracy: 0.5850\n",
      "Epoch 252/467\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1205 - accuracy: 0.9328 - val_loss: 3.1548 - val_accuracy: 0.5832\n",
      "Epoch 253/467\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.1292 - accuracy: 0.9328 - val_loss: 2.9473 - val_accuracy: 0.5686\n",
      "Epoch 254/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1109 - accuracy: 0.9383 - val_loss: 3.2327 - val_accuracy: 0.5740\n",
      "Epoch 255/467\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.1181 - accuracy: 0.9328 - val_loss: 3.1195 - val_accuracy: 0.5759\n",
      "Epoch 256/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1135 - accuracy: 0.9383 - val_loss: 3.1526 - val_accuracy: 0.5814\n",
      "Epoch 257/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.1123 - accuracy: 0.9333 - val_loss: 3.3006 - val_accuracy: 0.5539\n",
      "Epoch 258/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1164 - accuracy: 0.9333 - val_loss: 3.0309 - val_accuracy: 0.5814\n",
      "Epoch 259/467\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.1338 - accuracy: 0.9328 - val_loss: 3.0008 - val_accuracy: 0.5722\n",
      "Epoch 260/467\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1270 - accuracy: 0.9333 - val_loss: 2.4996 - val_accuracy: 0.5996\n",
      "Epoch 261/467\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.1182 - accuracy: 0.9310 - val_loss: 3.1364 - val_accuracy: 0.5686\n",
      "Epoch 262/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1350 - accuracy: 0.9310 - val_loss: 2.7184 - val_accuracy: 0.5905\n",
      "Epoch 263/467\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1504 - accuracy: 0.9273 - val_loss: 2.5014 - val_accuracy: 0.5521\n",
      "Epoch 264/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1234 - accuracy: 0.9333 - val_loss: 2.7285 - val_accuracy: 0.5814\n",
      "Epoch 265/467\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1384 - accuracy: 0.9310 - val_loss: 2.4716 - val_accuracy: 0.5941\n",
      "Epoch 266/467\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1483 - accuracy: 0.9223 - val_loss: 2.2912 - val_accuracy: 0.5814\n",
      "Epoch 267/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1334 - accuracy: 0.9296 - val_loss: 2.3251 - val_accuracy: 0.5759\n",
      "Epoch 268/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1001 - accuracy: 0.9442 - val_loss: 3.0392 - val_accuracy: 0.6015\n",
      "Epoch 269/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1377 - accuracy: 0.9333 - val_loss: 2.5246 - val_accuracy: 0.5832\n",
      "Epoch 270/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1496 - accuracy: 0.9246 - val_loss: 2.0644 - val_accuracy: 0.5759\n",
      "Epoch 271/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1191 - accuracy: 0.9324 - val_loss: 2.6844 - val_accuracy: 0.5832\n",
      "Epoch 272/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1212 - accuracy: 0.9337 - val_loss: 2.8764 - val_accuracy: 0.5887\n",
      "Epoch 273/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1235 - accuracy: 0.9301 - val_loss: 3.0820 - val_accuracy: 0.5777\n",
      "Epoch 274/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1225 - accuracy: 0.9296 - val_loss: 3.2446 - val_accuracy: 0.6015\n",
      "Epoch 275/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1165 - accuracy: 0.9328 - val_loss: 2.9262 - val_accuracy: 0.5850\n",
      "Epoch 276/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1094 - accuracy: 0.9388 - val_loss: 3.0218 - val_accuracy: 0.5777\n",
      "Epoch 277/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1062 - accuracy: 0.9397 - val_loss: 3.0373 - val_accuracy: 0.5686\n",
      "Epoch 278/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0979 - accuracy: 0.9388 - val_loss: 3.4428 - val_accuracy: 0.5814\n",
      "Epoch 279/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1137 - accuracy: 0.9324 - val_loss: 3.2168 - val_accuracy: 0.5868\n",
      "Epoch 280/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1030 - accuracy: 0.9406 - val_loss: 3.2050 - val_accuracy: 0.5795\n",
      "Epoch 281/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1012 - accuracy: 0.9383 - val_loss: 3.8350 - val_accuracy: 0.5814\n",
      "Epoch 282/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1320 - accuracy: 0.9292 - val_loss: 2.5983 - val_accuracy: 0.6069\n",
      "Epoch 283/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1198 - accuracy: 0.9342 - val_loss: 2.6226 - val_accuracy: 0.5704\n",
      "Epoch 284/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1025 - accuracy: 0.9415 - val_loss: 3.5074 - val_accuracy: 0.5667\n",
      "Epoch 285/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1201 - accuracy: 0.9388 - val_loss: 3.0120 - val_accuracy: 0.5795\n",
      "Epoch 286/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1051 - accuracy: 0.9360 - val_loss: 3.1207 - val_accuracy: 0.5594\n",
      "Epoch 287/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1153 - accuracy: 0.9333 - val_loss: 3.1707 - val_accuracy: 0.5941\n",
      "Epoch 288/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.1400 - accuracy: 0.9237 - val_loss: 2.2629 - val_accuracy: 0.5667\n",
      "Epoch 289/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1247 - accuracy: 0.9328 - val_loss: 3.1832 - val_accuracy: 0.5722\n",
      "Epoch 290/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1087 - accuracy: 0.9374 - val_loss: 3.7545 - val_accuracy: 0.5594\n",
      "Epoch 291/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1153 - accuracy: 0.9356 - val_loss: 3.4245 - val_accuracy: 0.5887\n",
      "Epoch 292/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1122 - accuracy: 0.9369 - val_loss: 3.0856 - val_accuracy: 0.5996\n",
      "Epoch 293/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1210 - accuracy: 0.9333 - val_loss: 3.0831 - val_accuracy: 0.5868\n",
      "Epoch 294/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1333 - accuracy: 0.9292 - val_loss: 2.5533 - val_accuracy: 0.5868\n",
      "Epoch 295/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1080 - accuracy: 0.9365 - val_loss: 3.1086 - val_accuracy: 0.5941\n",
      "Epoch 296/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1094 - accuracy: 0.9378 - val_loss: 3.1366 - val_accuracy: 0.5686\n",
      "Epoch 297/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1107 - accuracy: 0.9383 - val_loss: 3.3185 - val_accuracy: 0.5923\n",
      "Epoch 298/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1053 - accuracy: 0.9442 - val_loss: 3.3888 - val_accuracy: 0.6051\n",
      "Epoch 299/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1530 - accuracy: 0.9205 - val_loss: 2.4503 - val_accuracy: 0.5814\n",
      "Epoch 300/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1340 - accuracy: 0.9324 - val_loss: 2.4543 - val_accuracy: 0.5814\n",
      "Epoch 301/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1108 - accuracy: 0.9360 - val_loss: 2.8847 - val_accuracy: 0.5850\n",
      "Epoch 302/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1036 - accuracy: 0.9378 - val_loss: 3.1823 - val_accuracy: 0.5978\n",
      "Epoch 303/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1201 - accuracy: 0.9319 - val_loss: 2.9434 - val_accuracy: 0.5832\n",
      "Epoch 304/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0973 - accuracy: 0.9401 - val_loss: 3.2638 - val_accuracy: 0.5960\n",
      "Epoch 305/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0953 - accuracy: 0.9470 - val_loss: 3.3429 - val_accuracy: 0.5704\n",
      "Epoch 306/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1239 - accuracy: 0.9328 - val_loss: 3.0917 - val_accuracy: 0.5814\n",
      "Epoch 307/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1430 - accuracy: 0.9237 - val_loss: 2.6900 - val_accuracy: 0.5905\n",
      "Epoch 308/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1163 - accuracy: 0.9374 - val_loss: 3.0375 - val_accuracy: 0.5832\n",
      "Epoch 309/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2010 - accuracy: 0.9104 - val_loss: 1.7489 - val_accuracy: 0.5850\n",
      "Epoch 310/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1173 - accuracy: 0.9388 - val_loss: 2.5414 - val_accuracy: 0.5850\n",
      "Epoch 311/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0978 - accuracy: 0.9438 - val_loss: 2.7889 - val_accuracy: 0.5814\n",
      "Epoch 312/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1337 - accuracy: 0.9342 - val_loss: 2.4790 - val_accuracy: 0.5740\n",
      "Epoch 313/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1151 - accuracy: 0.9397 - val_loss: 2.8939 - val_accuracy: 0.5740\n",
      "Epoch 314/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1122 - accuracy: 0.9388 - val_loss: 2.6374 - val_accuracy: 0.5704\n",
      "Epoch 315/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0998 - accuracy: 0.9465 - val_loss: 3.0778 - val_accuracy: 0.5814\n",
      "Epoch 316/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1158 - accuracy: 0.9383 - val_loss: 2.6803 - val_accuracy: 0.5850\n",
      "Epoch 317/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1017 - accuracy: 0.9410 - val_loss: 2.9638 - val_accuracy: 0.5686\n",
      "Epoch 318/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1083 - accuracy: 0.9383 - val_loss: 2.9584 - val_accuracy: 0.5667\n",
      "Epoch 319/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1010 - accuracy: 0.9410 - val_loss: 3.3065 - val_accuracy: 0.5667\n",
      "Epoch 320/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1206 - accuracy: 0.9296 - val_loss: 2.9480 - val_accuracy: 0.5722\n",
      "Epoch 321/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1298 - accuracy: 0.9273 - val_loss: 2.4150 - val_accuracy: 0.5722\n",
      "Epoch 322/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1268 - accuracy: 0.9264 - val_loss: 2.4385 - val_accuracy: 0.5960\n",
      "Epoch 323/467\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9397 - val_loss: 2.8358 - val_accuracy: 0.5814\n",
      "Epoch 324/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1037 - accuracy: 0.9410 - val_loss: 2.7540 - val_accuracy: 0.5941\n",
      "Epoch 325/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1508 - accuracy: 0.9351 - val_loss: 1.9698 - val_accuracy: 0.5759\n",
      "Epoch 326/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1258 - accuracy: 0.9292 - val_loss: 2.3908 - val_accuracy: 0.5978\n",
      "Epoch 327/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1116 - accuracy: 0.9388 - val_loss: 2.4719 - val_accuracy: 0.5777\n",
      "Epoch 328/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1113 - accuracy: 0.9420 - val_loss: 2.5191 - val_accuracy: 0.5978\n",
      "Epoch 329/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1037 - accuracy: 0.9415 - val_loss: 2.7032 - val_accuracy: 0.5868\n",
      "Epoch 330/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1035 - accuracy: 0.9406 - val_loss: 2.6439 - val_accuracy: 0.5759\n",
      "Epoch 331/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1149 - accuracy: 0.9374 - val_loss: 2.5056 - val_accuracy: 0.5686\n",
      "Epoch 332/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1204 - accuracy: 0.9310 - val_loss: 2.4727 - val_accuracy: 0.5631\n",
      "Epoch 333/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1117 - accuracy: 0.9397 - val_loss: 2.6879 - val_accuracy: 0.5795\n",
      "Epoch 334/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1051 - accuracy: 0.9397 - val_loss: 2.6975 - val_accuracy: 0.5740\n",
      "Epoch 335/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1189 - accuracy: 0.9324 - val_loss: 2.5135 - val_accuracy: 0.5686\n",
      "Epoch 336/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0953 - accuracy: 0.9442 - val_loss: 3.0434 - val_accuracy: 0.5850\n",
      "Epoch 337/467\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9406 - val_loss: 3.0421 - val_accuracy: 0.5923\n",
      "Epoch 338/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1125 - accuracy: 0.9392 - val_loss: 2.8518 - val_accuracy: 0.5777\n",
      "Epoch 339/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.9388 - val_loss: 2.8552 - val_accuracy: 0.5759\n",
      "Epoch 340/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1281 - accuracy: 0.9328 - val_loss: 2.2802 - val_accuracy: 0.5960\n",
      "Epoch 341/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1341 - accuracy: 0.9278 - val_loss: 2.2067 - val_accuracy: 0.5832\n",
      "Epoch 342/467\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.1115 - accuracy: 0.9342 - val_loss: 2.6083 - val_accuracy: 0.5814\n",
      "Epoch 343/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1089 - accuracy: 0.9452 - val_loss: 2.2601 - val_accuracy: 0.5612\n",
      "Epoch 344/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1079 - accuracy: 0.9438 - val_loss: 2.7211 - val_accuracy: 0.5576\n",
      "Epoch 345/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1128 - accuracy: 0.9397 - val_loss: 2.5365 - val_accuracy: 0.5704\n",
      "Epoch 346/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1166 - accuracy: 0.9337 - val_loss: 2.6463 - val_accuracy: 0.5667\n",
      "Epoch 347/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1112 - accuracy: 0.9378 - val_loss: 2.6560 - val_accuracy: 0.5941\n",
      "Epoch 348/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1069 - accuracy: 0.9383 - val_loss: 2.7605 - val_accuracy: 0.5777\n",
      "Epoch 349/467\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1022 - accuracy: 0.9401 - val_loss: 2.9657 - val_accuracy: 0.5740\n",
      "Epoch 350/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0862 - accuracy: 0.9461 - val_loss: 3.4719 - val_accuracy: 0.5850\n",
      "Epoch 351/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0879 - accuracy: 0.9442 - val_loss: 3.5376 - val_accuracy: 0.5850\n",
      "Epoch 352/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0984 - accuracy: 0.9433 - val_loss: 3.4132 - val_accuracy: 0.5759\n",
      "Epoch 353/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1021 - accuracy: 0.9429 - val_loss: 2.8790 - val_accuracy: 0.5740\n",
      "Epoch 354/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1089 - accuracy: 0.9369 - val_loss: 2.6923 - val_accuracy: 0.5722\n",
      "Epoch 355/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1207 - accuracy: 0.9324 - val_loss: 2.6903 - val_accuracy: 0.5649\n",
      "Epoch 356/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1146 - accuracy: 0.9374 - val_loss: 2.9765 - val_accuracy: 0.5868\n",
      "Epoch 357/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0916 - accuracy: 0.9442 - val_loss: 3.1099 - val_accuracy: 0.5795\n",
      "Epoch 358/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1288 - accuracy: 0.9333 - val_loss: 1.9180 - val_accuracy: 0.5814\n",
      "Epoch 359/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1322 - accuracy: 0.9356 - val_loss: 2.0351 - val_accuracy: 0.5795\n",
      "Epoch 360/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1253 - accuracy: 0.9287 - val_loss: 2.3850 - val_accuracy: 0.5612\n",
      "Epoch 361/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1174 - accuracy: 0.9351 - val_loss: 2.5841 - val_accuracy: 0.5686\n",
      "Epoch 362/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1110 - accuracy: 0.9388 - val_loss: 2.5624 - val_accuracy: 0.5832\n",
      "Epoch 363/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0999 - accuracy: 0.9452 - val_loss: 2.8445 - val_accuracy: 0.5740\n",
      "Epoch 364/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0844 - accuracy: 0.9502 - val_loss: 3.1794 - val_accuracy: 0.5868\n",
      "Epoch 365/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0900 - accuracy: 0.9493 - val_loss: 3.1773 - val_accuracy: 0.5923\n",
      "Epoch 366/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1196 - accuracy: 0.9346 - val_loss: 2.5786 - val_accuracy: 0.5686\n",
      "Epoch 367/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1028 - accuracy: 0.9383 - val_loss: 2.9422 - val_accuracy: 0.5795\n",
      "Epoch 368/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1462 - accuracy: 0.9269 - val_loss: 2.1909 - val_accuracy: 0.6051\n",
      "Epoch 369/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1126 - accuracy: 0.9342 - val_loss: 2.5880 - val_accuracy: 0.5923\n",
      "Epoch 370/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1060 - accuracy: 0.9420 - val_loss: 2.7566 - val_accuracy: 0.5960\n",
      "Epoch 371/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0894 - accuracy: 0.9511 - val_loss: 3.1774 - val_accuracy: 0.5923\n",
      "Epoch 372/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0938 - accuracy: 0.9470 - val_loss: 3.1950 - val_accuracy: 0.5759\n",
      "Epoch 373/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1079 - accuracy: 0.9429 - val_loss: 2.5135 - val_accuracy: 0.5850\n",
      "Epoch 374/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0918 - accuracy: 0.9461 - val_loss: 2.7756 - val_accuracy: 0.5777\n",
      "Epoch 375/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0973 - accuracy: 0.9474 - val_loss: 2.7572 - val_accuracy: 0.5832\n",
      "Epoch 376/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0878 - accuracy: 0.9461 - val_loss: 2.7872 - val_accuracy: 0.6015\n",
      "Epoch 377/467\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1234 - accuracy: 0.9410 - val_loss: 1.9466 - val_accuracy: 0.5722\n",
      "Epoch 378/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1043 - accuracy: 0.9456 - val_loss: 2.6053 - val_accuracy: 0.6069\n",
      "Epoch 379/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0990 - accuracy: 0.9420 - val_loss: 2.9624 - val_accuracy: 0.5850\n",
      "Epoch 380/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0950 - accuracy: 0.9488 - val_loss: 3.1579 - val_accuracy: 0.5923\n",
      "Epoch 381/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0848 - accuracy: 0.9548 - val_loss: 3.3103 - val_accuracy: 0.6161\n",
      "Epoch 382/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1053 - accuracy: 0.9447 - val_loss: 2.6635 - val_accuracy: 0.6124\n",
      "Epoch 383/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0896 - accuracy: 0.9506 - val_loss: 3.3811 - val_accuracy: 0.5832\n",
      "Epoch 384/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1219 - accuracy: 0.9433 - val_loss: 2.2377 - val_accuracy: 0.5887\n",
      "Epoch 385/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0993 - accuracy: 0.9474 - val_loss: 2.7209 - val_accuracy: 0.5887\n",
      "Epoch 386/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0878 - accuracy: 0.9479 - val_loss: 2.8252 - val_accuracy: 0.5850\n",
      "Epoch 387/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0937 - accuracy: 0.9433 - val_loss: 3.1515 - val_accuracy: 0.5923\n",
      "Epoch 388/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1052 - accuracy: 0.9406 - val_loss: 3.1639 - val_accuracy: 0.5887\n",
      "Epoch 389/467\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.1134 - accuracy: 0.9415 - val_loss: 2.3766 - val_accuracy: 0.6051\n",
      "Epoch 390/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1164 - accuracy: 0.9324 - val_loss: 2.8939 - val_accuracy: 0.6051\n",
      "Epoch 391/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1340 - accuracy: 0.9324 - val_loss: 2.4686 - val_accuracy: 0.5941\n",
      "Epoch 392/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1176 - accuracy: 0.9292 - val_loss: 2.7746 - val_accuracy: 0.5686\n",
      "Epoch 393/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1056 - accuracy: 0.9401 - val_loss: 2.7740 - val_accuracy: 0.6051\n",
      "Epoch 394/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1109 - accuracy: 0.9356 - val_loss: 3.0973 - val_accuracy: 0.5722\n",
      "Epoch 395/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0869 - accuracy: 0.9525 - val_loss: 3.2341 - val_accuracy: 0.5850\n",
      "Epoch 396/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0910 - accuracy: 0.9474 - val_loss: 3.3324 - val_accuracy: 0.5905\n",
      "Epoch 397/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1028 - accuracy: 0.9484 - val_loss: 2.9856 - val_accuracy: 0.5832\n",
      "Epoch 398/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0991 - accuracy: 0.9474 - val_loss: 3.0619 - val_accuracy: 0.5978\n",
      "Epoch 399/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1036 - accuracy: 0.9392 - val_loss: 2.9625 - val_accuracy: 0.5777\n",
      "Epoch 400/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1127 - accuracy: 0.9406 - val_loss: 2.6468 - val_accuracy: 0.5686\n",
      "Epoch 401/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1098 - accuracy: 0.9397 - val_loss: 2.4956 - val_accuracy: 0.6033\n",
      "Epoch 402/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1027 - accuracy: 0.9465 - val_loss: 2.6830 - val_accuracy: 0.5868\n",
      "Epoch 403/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1027 - accuracy: 0.9465 - val_loss: 2.8071 - val_accuracy: 0.5905\n",
      "Epoch 404/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0951 - accuracy: 0.9479 - val_loss: 3.0926 - val_accuracy: 0.5722\n",
      "Epoch 405/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0905 - accuracy: 0.9474 - val_loss: 3.5768 - val_accuracy: 0.5686\n",
      "Epoch 406/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1025 - accuracy: 0.9452 - val_loss: 2.8500 - val_accuracy: 0.6015\n",
      "Epoch 407/467\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0998 - accuracy: 0.9479 - val_loss: 2.7388 - val_accuracy: 0.5960\n",
      "Epoch 408/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0955 - accuracy: 0.9415 - val_loss: 2.8484 - val_accuracy: 0.5814\n",
      "Epoch 409/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0960 - accuracy: 0.9479 - val_loss: 2.8870 - val_accuracy: 0.5905\n",
      "Epoch 410/467\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0991 - accuracy: 0.9484 - val_loss: 3.3552 - val_accuracy: 0.5850\n",
      "Epoch 411/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1067 - accuracy: 0.9447 - val_loss: 2.4348 - val_accuracy: 0.5941\n",
      "Epoch 412/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1262 - accuracy: 0.9420 - val_loss: 2.3713 - val_accuracy: 0.5905\n",
      "Epoch 413/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1479 - accuracy: 0.9237 - val_loss: 2.1784 - val_accuracy: 0.6015\n",
      "Epoch 414/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1062 - accuracy: 0.9410 - val_loss: 2.7411 - val_accuracy: 0.5923\n",
      "Epoch 415/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0941 - accuracy: 0.9497 - val_loss: 3.0463 - val_accuracy: 0.5960\n",
      "Epoch 416/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1005 - accuracy: 0.9465 - val_loss: 2.5208 - val_accuracy: 0.5832\n",
      "Epoch 417/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0828 - accuracy: 0.9516 - val_loss: 2.9361 - val_accuracy: 0.5960\n",
      "Epoch 418/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0884 - accuracy: 0.9520 - val_loss: 2.9030 - val_accuracy: 0.5850\n",
      "Epoch 419/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0926 - accuracy: 0.9424 - val_loss: 3.2243 - val_accuracy: 0.5777\n",
      "Epoch 420/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0989 - accuracy: 0.9461 - val_loss: 2.6550 - val_accuracy: 0.5777\n",
      "Epoch 421/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0907 - accuracy: 0.9488 - val_loss: 2.9841 - val_accuracy: 0.5722\n",
      "Epoch 422/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1048 - accuracy: 0.9420 - val_loss: 2.6844 - val_accuracy: 0.5649\n",
      "Epoch 423/467\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1022 - accuracy: 0.9369 - val_loss: 2.7853 - val_accuracy: 0.5868\n",
      "Epoch 424/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1007 - accuracy: 0.9447 - val_loss: 2.7662 - val_accuracy: 0.5868\n",
      "Epoch 425/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1027 - accuracy: 0.9397 - val_loss: 2.9304 - val_accuracy: 0.5686\n",
      "Epoch 426/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1094 - accuracy: 0.9420 - val_loss: 2.8021 - val_accuracy: 0.5594\n",
      "Epoch 427/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0918 - accuracy: 0.9456 - val_loss: 3.3196 - val_accuracy: 0.5649\n",
      "Epoch 428/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0864 - accuracy: 0.9557 - val_loss: 3.3084 - val_accuracy: 0.5777\n",
      "Epoch 429/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1136 - accuracy: 0.9346 - val_loss: 3.1201 - val_accuracy: 0.5905\n",
      "Epoch 430/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0994 - accuracy: 0.9461 - val_loss: 3.2153 - val_accuracy: 0.5868\n",
      "Epoch 431/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0820 - accuracy: 0.9543 - val_loss: 3.4700 - val_accuracy: 0.5868\n",
      "Epoch 432/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0878 - accuracy: 0.9506 - val_loss: 3.1954 - val_accuracy: 0.5941\n",
      "Epoch 433/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0930 - accuracy: 0.9470 - val_loss: 3.1722 - val_accuracy: 0.6015\n",
      "Epoch 434/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1051 - accuracy: 0.9433 - val_loss: 2.8696 - val_accuracy: 0.5887\n",
      "Epoch 435/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0908 - accuracy: 0.9488 - val_loss: 3.3324 - val_accuracy: 0.5759\n",
      "Epoch 436/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0771 - accuracy: 0.9520 - val_loss: 3.9503 - val_accuracy: 0.5722\n",
      "Epoch 437/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0867 - accuracy: 0.9488 - val_loss: 3.6022 - val_accuracy: 0.5832\n",
      "Epoch 438/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1246 - accuracy: 0.9346 - val_loss: 2.2855 - val_accuracy: 0.5594\n",
      "Epoch 439/467\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.0987 - accuracy: 0.9429 - val_loss: 2.7031 - val_accuracy: 0.6069\n",
      "Epoch 440/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0838 - accuracy: 0.9479 - val_loss: 3.0329 - val_accuracy: 0.5923\n",
      "Epoch 441/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0903 - accuracy: 0.9474 - val_loss: 3.3561 - val_accuracy: 0.5777\n",
      "Epoch 442/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1311 - accuracy: 0.9324 - val_loss: 2.7578 - val_accuracy: 0.5978\n",
      "Epoch 443/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1026 - accuracy: 0.9388 - val_loss: 2.8842 - val_accuracy: 0.5814\n",
      "Epoch 444/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1043 - accuracy: 0.9406 - val_loss: 2.9901 - val_accuracy: 0.5832\n",
      "Epoch 445/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0906 - accuracy: 0.9497 - val_loss: 2.9983 - val_accuracy: 0.5631\n",
      "Epoch 446/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0941 - accuracy: 0.9456 - val_loss: 3.3464 - val_accuracy: 0.5558\n",
      "Epoch 447/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0794 - accuracy: 0.9516 - val_loss: 4.0894 - val_accuracy: 0.5759\n",
      "Epoch 448/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0847 - accuracy: 0.9516 - val_loss: 3.9977 - val_accuracy: 0.5484\n",
      "Epoch 449/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1206 - accuracy: 0.9374 - val_loss: 2.3841 - val_accuracy: 0.5814\n",
      "Epoch 450/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0948 - accuracy: 0.9493 - val_loss: 3.0584 - val_accuracy: 0.5795\n",
      "Epoch 451/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0842 - accuracy: 0.9525 - val_loss: 3.2617 - val_accuracy: 0.5759\n",
      "Epoch 452/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.0760 - accuracy: 0.9488 - val_loss: 3.8433 - val_accuracy: 0.5868\n",
      "Epoch 453/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1123 - accuracy: 0.9378 - val_loss: 2.7609 - val_accuracy: 0.5722\n",
      "Epoch 454/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1098 - accuracy: 0.9392 - val_loss: 2.6680 - val_accuracy: 0.5667\n",
      "Epoch 455/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1035 - accuracy: 0.9415 - val_loss: 2.9516 - val_accuracy: 0.5814\n",
      "Epoch 456/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0927 - accuracy: 0.9465 - val_loss: 3.2424 - val_accuracy: 0.6015\n",
      "Epoch 457/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.0753 - accuracy: 0.9552 - val_loss: 3.8807 - val_accuracy: 0.5887\n",
      "Epoch 458/467\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.0698 - accuracy: 0.9589 - val_loss: 4.1614 - val_accuracy: 0.5905\n",
      "Epoch 459/467\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1101 - accuracy: 0.9415 - val_loss: 3.0503 - val_accuracy: 0.5740\n",
      "Epoch 460/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0931 - accuracy: 0.9470 - val_loss: 3.8505 - val_accuracy: 0.5722\n",
      "Epoch 461/467\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0942 - accuracy: 0.9493 - val_loss: 3.5266 - val_accuracy: 0.5905\n",
      "Epoch 462/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0940 - accuracy: 0.9534 - val_loss: 3.4560 - val_accuracy: 0.5887\n",
      "Epoch 463/467\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0946 - accuracy: 0.9506 - val_loss: 3.2471 - val_accuracy: 0.5814\n",
      "Epoch 464/467\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1160 - accuracy: 0.9378 - val_loss: 2.4897 - val_accuracy: 0.5722\n",
      "Epoch 465/467\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1258 - accuracy: 0.9374 - val_loss: 2.0115 - val_accuracy: 0.5667\n",
      "Epoch 466/467\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.0962 - accuracy: 0.9493 - val_loss: 2.9428 - val_accuracy: 0.5795\n",
      "Epoch 467/467\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.0797 - accuracy: 0.9511 - val_loss: 3.5815 - val_accuracy: 0.5832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x213c5e30b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit(X_train, Y_train, epochs=467, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.722846  0.756863  0.739464       255\n",
      "           1   0.851319  0.827506  0.839243       429\n",
      "\n",
      "    accuracy                       0.801170       684\n",
      "   macro avg   0.787083  0.792184  0.789354       684\n",
      "weighted avg   0.803423  0.801170  0.802045       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = hypermodel.predict(X_test)\n",
    "res.round()\n",
    "actual = []\n",
    "for num in res:\n",
    "    if num>0.5:\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,actual,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x213c3afe430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "confusionmatrix = confusion_matrix(Y_test, actual)\n",
    "cm_display = ConfusionMatrixDisplay(confusionmatrix, display_labels=[0,1])\n",
    "cm_display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
