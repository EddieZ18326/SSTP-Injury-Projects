{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0      3   2   2  25   0   3  10   0   0   0   0   0   0   0   0   0   1   1\n",
      "1      3   3   1  61   0   3  10   0   0   0   0   0   0   0   0   0   7   1\n",
      "2      3   3   1  65   0   3  10   0   0   0   0   0   0   0   0   0   6   1\n",
      "3      3   2   1  49   0   3  10   0   0   0   1   0   0   0   0   0   5   1\n",
      "4      3   1   1  54   0   5   2   1   1   0   0   0   0   0   0   1   5   1\n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "3414   1   2   1  57   0   6   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3415   1   1   1  24   0   3   7   0   0   0   0   0   0   0   0   0   1   4\n",
      "3416   1   1   1  50   0   3  10   0   0   0   0   0   0   0   0   0   6   4\n",
      "3417   1   2   1  58   0   3   9   0   0   0   0   0   0   0   0   0   6   4\n",
      "3418   1   2   1   3   0   4  10   0   0   0   0   0   0   0   0   0   5   4\n",
      "\n",
      "[3419 rows x 18 columns]\n",
      "      0\n",
      "0     0\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "...  ..\n",
      "3414  1\n",
      "3415  1\n",
      "3416  1\n",
      "3417  0\n",
      "3418  1\n",
      "\n",
      "[3419 rows x 1 columns]\n",
      "(2735, 18)\n",
      "(2735, 1)\n",
      "(684, 18)\n",
      "Index(['Location of Incident', 'Time', 'Sex', 'Age', 'Intentional', 'Role',\n",
      "       'Injury Agent', 'Confined Space', 'Grain Involved', 'Alcohol/Drugs',\n",
      "       'Seatbelt', 'Helmet', 'ROPS', 'Agritourism', 'Other PPE',\n",
      "       'Drowning/Suffocation', 'Day', 'Season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('/Users/eddie/Downloads/Log In - AgInjuryNews (1).xlsx - Sheet1 (1) - Log In - AgInjuryNews (1).xlsx - Sheet1 (1).csv')\n",
    "\n",
    "X = pd.DataFrame(dataset.iloc[:,:18].values)\n",
    "Y = pd.DataFrame(dataset.iloc[:,18:].values)\n",
    "print(X)\n",
    "print(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=0)\n",
    "X_train, X_train_val, Y_train, Y_train_val = train_test_split(X,Y,test_size=0.2)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.reshape(2735,18,1)\n",
    "X_test.reshape(684,18,1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "features = pd.DataFrame(dataset.iloc[:,:18])\n",
    "features = features.columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Dropout \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=128, max_value=512, step=32)\n",
    "  model.add(LSTM(hp_units, input_shape=(18, 1), return_sequences=True))\n",
    "  model.add(Dropout(0.5))  # Regularization to avoid overfitting\n",
    "\n",
    "  # Another LSTM layer\n",
    "  hp_units2 = hp.Int('units2', min_value=32, max_value=128, step=16)\n",
    "  model.add(LSTM(hp_units2, return_sequences=False))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Dense layer\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  model.add(Dense(1,activation = 'sigmoid'))\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4,1e-5,1e-6])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape = (18,)))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from lstm_hyper\\lstm_hyper\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='lstm_hyper',\n",
    "                     project_name='lstm_hyper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 416 and the optimal learning rate for the optimizer\n",
      "is 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(X_train, Y_train, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/69 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.6259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 6s 37ms/step - loss: 0.6729 - accuracy: 0.6257 - val_loss: 0.6608 - val_accuracy: 0.6325\n",
      "Epoch 2/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6642 - accuracy: 0.6293 - val_loss: 0.6636 - val_accuracy: 0.6325\n",
      "Epoch 3/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6621 - accuracy: 0.6293 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 4/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6636 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 5/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6624 - accuracy: 0.6293 - val_loss: 0.6591 - val_accuracy: 0.6325\n",
      "Epoch 6/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6624 - accuracy: 0.6293 - val_loss: 0.6622 - val_accuracy: 0.6325\n",
      "Epoch 7/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6635 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 8/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6598 - accuracy: 0.6293 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 9/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6611 - accuracy: 0.6293 - val_loss: 0.6579 - val_accuracy: 0.6325\n",
      "Epoch 10/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6620 - accuracy: 0.6293 - val_loss: 0.6604 - val_accuracy: 0.6325\n",
      "Epoch 11/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6609 - accuracy: 0.6293 - val_loss: 0.6587 - val_accuracy: 0.6325\n",
      "Epoch 12/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6624 - accuracy: 0.6293 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 13/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6594 - accuracy: 0.6293 - val_loss: 0.6574 - val_accuracy: 0.6325\n",
      "Epoch 14/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6597 - accuracy: 0.6293 - val_loss: 0.6582 - val_accuracy: 0.6325\n",
      "Epoch 15/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6602 - accuracy: 0.6293 - val_loss: 0.6574 - val_accuracy: 0.6325\n",
      "Epoch 16/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6598 - accuracy: 0.6293 - val_loss: 0.6573 - val_accuracy: 0.6325\n",
      "Epoch 17/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6588 - accuracy: 0.6293 - val_loss: 0.6573 - val_accuracy: 0.6325\n",
      "Epoch 18/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6593 - accuracy: 0.6293 - val_loss: 0.6574 - val_accuracy: 0.6325\n",
      "Epoch 19/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6598 - accuracy: 0.6293 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 20/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6583 - accuracy: 0.6293 - val_loss: 0.6574 - val_accuracy: 0.6325\n",
      "Epoch 21/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6584 - accuracy: 0.6293 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 22/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6579 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 23/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6593 - accuracy: 0.6289 - val_loss: 0.6574 - val_accuracy: 0.6325\n",
      "Epoch 24/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6586 - accuracy: 0.6293 - val_loss: 0.6583 - val_accuracy: 0.6325\n",
      "Epoch 25/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6589 - accuracy: 0.6293 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 26/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6584 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 27/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6590 - accuracy: 0.6293 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 28/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6593 - accuracy: 0.6293 - val_loss: 0.6576 - val_accuracy: 0.6325\n",
      "Epoch 29/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6594 - accuracy: 0.6293 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 30/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6588 - accuracy: 0.6293 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 31/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6577 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 32/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6580 - accuracy: 0.6293 - val_loss: 0.6578 - val_accuracy: 0.6325\n",
      "Epoch 33/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6590 - accuracy: 0.6293 - val_loss: 0.6581 - val_accuracy: 0.6325\n",
      "Epoch 34/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6571 - accuracy: 0.6293 - val_loss: 0.6583 - val_accuracy: 0.6325\n",
      "Epoch 35/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6576 - accuracy: 0.6293 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 36/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6586 - accuracy: 0.6293 - val_loss: 0.6579 - val_accuracy: 0.6325\n",
      "Epoch 37/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6584 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 38/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6580 - accuracy: 0.6293 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 39/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6578 - accuracy: 0.6293 - val_loss: 0.6587 - val_accuracy: 0.6325\n",
      "Epoch 40/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6569 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 41/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6583 - accuracy: 0.6293 - val_loss: 0.6581 - val_accuracy: 0.6325\n",
      "Epoch 42/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6573 - accuracy: 0.6293 - val_loss: 0.6581 - val_accuracy: 0.6325\n",
      "Epoch 43/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6587 - accuracy: 0.6293 - val_loss: 0.6582 - val_accuracy: 0.6325\n",
      "Epoch 44/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6574 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 45/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6581 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 46/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6590 - accuracy: 0.6293 - val_loss: 0.6583 - val_accuracy: 0.6325\n",
      "Epoch 47/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6576 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 48/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6575 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 49/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6581 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 50/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6589 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 51/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6582 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 52/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6568 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 53/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6572 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 54/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6574 - accuracy: 0.6293 - val_loss: 0.6587 - val_accuracy: 0.6325\n",
      "Epoch 55/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6567 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 56/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6584 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 57/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6589 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 58/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6572 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 59/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6584 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 60/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6574 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 61/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6568 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 62/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6582 - accuracy: 0.6293 - val_loss: 0.6590 - val_accuracy: 0.6325\n",
      "Epoch 63/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6585 - accuracy: 0.6293 - val_loss: 0.6587 - val_accuracy: 0.6325\n",
      "Epoch 64/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6574 - accuracy: 0.6293 - val_loss: 0.6592 - val_accuracy: 0.6325\n",
      "Epoch 65/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6582 - accuracy: 0.6293 - val_loss: 0.6589 - val_accuracy: 0.6325\n",
      "Epoch 66/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6577 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 67/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6578 - accuracy: 0.6293 - val_loss: 0.6589 - val_accuracy: 0.6325\n",
      "Epoch 68/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6570 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 69/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6576 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 70/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6572 - accuracy: 0.6293 - val_loss: 0.6589 - val_accuracy: 0.6325\n",
      "Epoch 71/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6585 - accuracy: 0.6293 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 72/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6570 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 73/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6568 - accuracy: 0.6293 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 74/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6564 - accuracy: 0.6293 - val_loss: 0.6591 - val_accuracy: 0.6325\n",
      "Epoch 75/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6581 - accuracy: 0.6293 - val_loss: 0.6593 - val_accuracy: 0.6325\n",
      "Epoch 76/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6574 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 77/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6581 - accuracy: 0.6293 - val_loss: 0.6589 - val_accuracy: 0.6325\n",
      "Epoch 78/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6570 - accuracy: 0.6293 - val_loss: 0.6587 - val_accuracy: 0.6325\n",
      "Epoch 79/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6567 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 80/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6581 - accuracy: 0.6293 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 81/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6572 - accuracy: 0.6293 - val_loss: 0.6592 - val_accuracy: 0.6325\n",
      "Epoch 82/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6578 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 83/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6573 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 84/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6570 - accuracy: 0.6293 - val_loss: 0.6591 - val_accuracy: 0.6325\n",
      "Epoch 85/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6577 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 86/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6565 - accuracy: 0.6293 - val_loss: 0.6591 - val_accuracy: 0.6325\n",
      "Epoch 87/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6588 - accuracy: 0.6293 - val_loss: 0.6590 - val_accuracy: 0.6325\n",
      "Epoch 88/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6560 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 89/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6573 - accuracy: 0.6293 - val_loss: 0.6587 - val_accuracy: 0.6325\n",
      "Epoch 90/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6557 - accuracy: 0.6293 - val_loss: 0.6591 - val_accuracy: 0.6325\n",
      "Epoch 91/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6570 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 92/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6573 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 93/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6562 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 94/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6579 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 95/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6594 - accuracy: 0.6293 - val_loss: 0.6589 - val_accuracy: 0.6325\n",
      "Epoch 96/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6569 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 97/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6574 - accuracy: 0.6293 - val_loss: 0.6592 - val_accuracy: 0.6325\n",
      "Epoch 98/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6563 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 99/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6583 - accuracy: 0.6293 - val_loss: 0.6589 - val_accuracy: 0.6325\n",
      "Epoch 100/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6569 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 101/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6573 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 102/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6576 - accuracy: 0.6293 - val_loss: 0.6589 - val_accuracy: 0.6325\n",
      "Epoch 103/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6582 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 104/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6560 - accuracy: 0.6293 - val_loss: 0.6586 - val_accuracy: 0.6325\n",
      "Epoch 105/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6573 - accuracy: 0.6293 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 106/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6561 - accuracy: 0.6293 - val_loss: 0.6583 - val_accuracy: 0.6325\n",
      "Epoch 107/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6563 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 108/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6578 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 109/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6566 - accuracy: 0.6293 - val_loss: 0.6583 - val_accuracy: 0.6325\n",
      "Epoch 110/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6568 - accuracy: 0.6293 - val_loss: 0.6583 - val_accuracy: 0.6325\n",
      "Epoch 111/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6552 - accuracy: 0.6293 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 112/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6561 - accuracy: 0.6293 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 113/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6567 - accuracy: 0.6293 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 114/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6560 - accuracy: 0.6293 - val_loss: 0.6579 - val_accuracy: 0.6325\n",
      "Epoch 115/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6563 - accuracy: 0.6293 - val_loss: 0.6579 - val_accuracy: 0.6325\n",
      "Epoch 116/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6559 - accuracy: 0.6293 - val_loss: 0.6574 - val_accuracy: 0.6325\n",
      "Epoch 117/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6556 - accuracy: 0.6293 - val_loss: 0.6579 - val_accuracy: 0.6325\n",
      "Epoch 118/1000\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 0.6563 - accuracy: 0.6293 - val_loss: 0.6568 - val_accuracy: 0.6325\n",
      "Epoch 119/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6571 - accuracy: 0.6293 - val_loss: 0.6574 - val_accuracy: 0.6325\n",
      "Epoch 120/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6560 - accuracy: 0.6293 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 121/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6552 - accuracy: 0.6293 - val_loss: 0.6573 - val_accuracy: 0.6325\n",
      "Epoch 122/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6552 - accuracy: 0.6293 - val_loss: 0.6576 - val_accuracy: 0.6325\n",
      "Epoch 123/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6551 - accuracy: 0.6289 - val_loss: 0.6568 - val_accuracy: 0.6325\n",
      "Epoch 124/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6554 - accuracy: 0.6293 - val_loss: 0.6569 - val_accuracy: 0.6325\n",
      "Epoch 125/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6566 - accuracy: 0.6293 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 126/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6552 - accuracy: 0.6293 - val_loss: 0.6575 - val_accuracy: 0.6325\n",
      "Epoch 127/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6551 - accuracy: 0.6293 - val_loss: 0.6576 - val_accuracy: 0.6325\n",
      "Epoch 128/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6547 - accuracy: 0.6293 - val_loss: 0.6576 - val_accuracy: 0.6325\n",
      "Epoch 129/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6563 - accuracy: 0.6298 - val_loss: 0.6569 - val_accuracy: 0.6325\n",
      "Epoch 130/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6536 - accuracy: 0.6293 - val_loss: 0.6565 - val_accuracy: 0.6325\n",
      "Epoch 131/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6558 - accuracy: 0.6284 - val_loss: 0.6573 - val_accuracy: 0.6325\n",
      "Epoch 132/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6556 - accuracy: 0.6293 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 133/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6556 - accuracy: 0.6293 - val_loss: 0.6566 - val_accuracy: 0.6325\n",
      "Epoch 134/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6556 - accuracy: 0.6289 - val_loss: 0.6576 - val_accuracy: 0.6325\n",
      "Epoch 135/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6546 - accuracy: 0.6293 - val_loss: 0.6568 - val_accuracy: 0.6325\n",
      "Epoch 136/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6533 - accuracy: 0.6293 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 137/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6535 - accuracy: 0.6293 - val_loss: 0.6564 - val_accuracy: 0.6325\n",
      "Epoch 138/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6548 - accuracy: 0.6298 - val_loss: 0.6564 - val_accuracy: 0.6325\n",
      "Epoch 139/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6539 - accuracy: 0.6289 - val_loss: 0.6562 - val_accuracy: 0.6325\n",
      "Epoch 140/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6534 - accuracy: 0.6303 - val_loss: 0.6565 - val_accuracy: 0.6325\n",
      "Epoch 141/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6555 - accuracy: 0.6307 - val_loss: 0.6561 - val_accuracy: 0.6325\n",
      "Epoch 142/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6540 - accuracy: 0.6275 - val_loss: 0.6561 - val_accuracy: 0.6325\n",
      "Epoch 143/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6544 - accuracy: 0.6284 - val_loss: 0.6554 - val_accuracy: 0.6325\n",
      "Epoch 144/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6548 - accuracy: 0.6298 - val_loss: 0.6554 - val_accuracy: 0.6325\n",
      "Epoch 145/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6540 - accuracy: 0.6298 - val_loss: 0.6564 - val_accuracy: 0.6325\n",
      "Epoch 146/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6537 - accuracy: 0.6312 - val_loss: 0.6564 - val_accuracy: 0.6325\n",
      "Epoch 147/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6534 - accuracy: 0.6298 - val_loss: 0.6559 - val_accuracy: 0.6325\n",
      "Epoch 148/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6513 - accuracy: 0.6312 - val_loss: 0.6561 - val_accuracy: 0.6307\n",
      "Epoch 149/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6532 - accuracy: 0.6289 - val_loss: 0.6571 - val_accuracy: 0.6307\n",
      "Epoch 150/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6537 - accuracy: 0.6307 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 151/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6551 - accuracy: 0.6298 - val_loss: 0.6573 - val_accuracy: 0.6325\n",
      "Epoch 152/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6529 - accuracy: 0.6321 - val_loss: 0.6554 - val_accuracy: 0.6325\n",
      "Epoch 153/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6536 - accuracy: 0.6316 - val_loss: 0.6565 - val_accuracy: 0.6344\n",
      "Epoch 154/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6535 - accuracy: 0.6325 - val_loss: 0.6574 - val_accuracy: 0.6344\n",
      "Epoch 155/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6516 - accuracy: 0.6303 - val_loss: 0.6561 - val_accuracy: 0.6344\n",
      "Epoch 156/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6529 - accuracy: 0.6289 - val_loss: 0.6577 - val_accuracy: 0.6344\n",
      "Epoch 157/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6528 - accuracy: 0.6312 - val_loss: 0.6552 - val_accuracy: 0.6344\n",
      "Epoch 158/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6553 - accuracy: 0.6284 - val_loss: 0.6573 - val_accuracy: 0.6344\n",
      "Epoch 159/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6536 - accuracy: 0.6289 - val_loss: 0.6577 - val_accuracy: 0.6307\n",
      "Epoch 160/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6532 - accuracy: 0.6280 - val_loss: 0.6560 - val_accuracy: 0.6325\n",
      "Epoch 161/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6542 - accuracy: 0.6312 - val_loss: 0.6555 - val_accuracy: 0.6344\n",
      "Epoch 162/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6530 - accuracy: 0.6312 - val_loss: 0.6562 - val_accuracy: 0.6344\n",
      "Epoch 163/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6528 - accuracy: 0.6307 - val_loss: 0.6577 - val_accuracy: 0.6344\n",
      "Epoch 164/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6524 - accuracy: 0.6271 - val_loss: 0.6568 - val_accuracy: 0.6289\n",
      "Epoch 165/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6529 - accuracy: 0.6312 - val_loss: 0.6555 - val_accuracy: 0.6344\n",
      "Epoch 166/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6526 - accuracy: 0.6298 - val_loss: 0.6567 - val_accuracy: 0.6307\n",
      "Epoch 167/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6516 - accuracy: 0.6316 - val_loss: 0.6584 - val_accuracy: 0.6325\n",
      "Epoch 168/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6513 - accuracy: 0.6316 - val_loss: 0.6606 - val_accuracy: 0.6271\n",
      "Epoch 169/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6508 - accuracy: 0.6321 - val_loss: 0.6570 - val_accuracy: 0.6344\n",
      "Epoch 170/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6523 - accuracy: 0.6266 - val_loss: 0.6579 - val_accuracy: 0.6344\n",
      "Epoch 171/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6536 - accuracy: 0.6303 - val_loss: 0.6562 - val_accuracy: 0.6325\n",
      "Epoch 172/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6526 - accuracy: 0.6293 - val_loss: 0.6553 - val_accuracy: 0.6307\n",
      "Epoch 173/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6505 - accuracy: 0.6325 - val_loss: 0.6591 - val_accuracy: 0.6271\n",
      "Epoch 174/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6501 - accuracy: 0.6335 - val_loss: 0.6600 - val_accuracy: 0.6216\n",
      "Epoch 175/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6515 - accuracy: 0.6344 - val_loss: 0.6566 - val_accuracy: 0.6325\n",
      "Epoch 176/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6528 - accuracy: 0.6275 - val_loss: 0.6575 - val_accuracy: 0.6307\n",
      "Epoch 177/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6507 - accuracy: 0.6275 - val_loss: 0.6571 - val_accuracy: 0.6307\n",
      "Epoch 178/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6492 - accuracy: 0.6312 - val_loss: 0.6590 - val_accuracy: 0.6216\n",
      "Epoch 179/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6521 - accuracy: 0.6316 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 180/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6498 - accuracy: 0.6312 - val_loss: 0.6634 - val_accuracy: 0.6252\n",
      "Epoch 181/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6502 - accuracy: 0.6312 - val_loss: 0.6609 - val_accuracy: 0.6289\n",
      "Epoch 182/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6521 - accuracy: 0.6266 - val_loss: 0.6586 - val_accuracy: 0.6344\n",
      "Epoch 183/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6484 - accuracy: 0.6335 - val_loss: 0.6581 - val_accuracy: 0.6325\n",
      "Epoch 184/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6503 - accuracy: 0.6266 - val_loss: 0.6603 - val_accuracy: 0.6344\n",
      "Epoch 185/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6500 - accuracy: 0.6335 - val_loss: 0.6603 - val_accuracy: 0.6289\n",
      "Epoch 186/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6505 - accuracy: 0.6266 - val_loss: 0.6606 - val_accuracy: 0.6362\n",
      "Epoch 187/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6492 - accuracy: 0.6307 - val_loss: 0.6620 - val_accuracy: 0.6307\n",
      "Epoch 188/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6501 - accuracy: 0.6316 - val_loss: 0.6603 - val_accuracy: 0.6362\n",
      "Epoch 189/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6503 - accuracy: 0.6316 - val_loss: 0.6576 - val_accuracy: 0.6344\n",
      "Epoch 190/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6496 - accuracy: 0.6261 - val_loss: 0.6587 - val_accuracy: 0.6380\n",
      "Epoch 191/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6455 - accuracy: 0.6325 - val_loss: 0.6626 - val_accuracy: 0.6143\n",
      "Epoch 192/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6474 - accuracy: 0.6307 - val_loss: 0.6599 - val_accuracy: 0.6289\n",
      "Epoch 193/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6474 - accuracy: 0.6325 - val_loss: 0.6599 - val_accuracy: 0.6252\n",
      "Epoch 194/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6494 - accuracy: 0.6298 - val_loss: 0.6596 - val_accuracy: 0.6380\n",
      "Epoch 195/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6461 - accuracy: 0.6312 - val_loss: 0.6596 - val_accuracy: 0.6362\n",
      "Epoch 196/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6462 - accuracy: 0.6316 - val_loss: 0.6591 - val_accuracy: 0.6380\n",
      "Epoch 197/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6460 - accuracy: 0.6312 - val_loss: 0.6613 - val_accuracy: 0.6399\n",
      "Epoch 198/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6474 - accuracy: 0.6303 - val_loss: 0.6585 - val_accuracy: 0.6325\n",
      "Epoch 199/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6451 - accuracy: 0.6298 - val_loss: 0.6618 - val_accuracy: 0.6289\n",
      "Epoch 200/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6435 - accuracy: 0.6316 - val_loss: 0.6590 - val_accuracy: 0.6234\n",
      "Epoch 201/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6481 - accuracy: 0.6289 - val_loss: 0.6599 - val_accuracy: 0.6362\n",
      "Epoch 202/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6472 - accuracy: 0.6293 - val_loss: 0.6597 - val_accuracy: 0.6344\n",
      "Epoch 203/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6457 - accuracy: 0.6271 - val_loss: 0.6596 - val_accuracy: 0.6362\n",
      "Epoch 204/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6469 - accuracy: 0.6293 - val_loss: 0.6590 - val_accuracy: 0.6380\n",
      "Epoch 205/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6470 - accuracy: 0.6353 - val_loss: 0.6566 - val_accuracy: 0.6362\n",
      "Epoch 206/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6460 - accuracy: 0.6339 - val_loss: 0.6588 - val_accuracy: 0.6307\n",
      "Epoch 207/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6470 - accuracy: 0.6307 - val_loss: 0.6592 - val_accuracy: 0.6344\n",
      "Epoch 208/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6466 - accuracy: 0.6371 - val_loss: 0.6560 - val_accuracy: 0.6362\n",
      "Epoch 209/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6464 - accuracy: 0.6234 - val_loss: 0.6602 - val_accuracy: 0.6344\n",
      "Epoch 210/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6468 - accuracy: 0.6307 - val_loss: 0.6587 - val_accuracy: 0.6325\n",
      "Epoch 211/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6447 - accuracy: 0.6362 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 212/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6471 - accuracy: 0.6307 - val_loss: 0.6579 - val_accuracy: 0.6344\n",
      "Epoch 213/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6458 - accuracy: 0.6293 - val_loss: 0.6558 - val_accuracy: 0.6362\n",
      "Epoch 214/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6441 - accuracy: 0.6321 - val_loss: 0.6612 - val_accuracy: 0.6362\n",
      "Epoch 215/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6436 - accuracy: 0.6330 - val_loss: 0.6593 - val_accuracy: 0.6325\n",
      "Epoch 216/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6461 - accuracy: 0.6335 - val_loss: 0.6563 - val_accuracy: 0.6344\n",
      "Epoch 217/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6450 - accuracy: 0.6362 - val_loss: 0.6602 - val_accuracy: 0.6344\n",
      "Epoch 218/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6424 - accuracy: 0.6312 - val_loss: 0.6584 - val_accuracy: 0.6399\n",
      "Epoch 219/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6451 - accuracy: 0.6321 - val_loss: 0.6570 - val_accuracy: 0.6344\n",
      "Epoch 220/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6421 - accuracy: 0.6325 - val_loss: 0.6565 - val_accuracy: 0.6362\n",
      "Epoch 221/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6451 - accuracy: 0.6312 - val_loss: 0.6553 - val_accuracy: 0.6362\n",
      "Epoch 222/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6457 - accuracy: 0.6303 - val_loss: 0.6557 - val_accuracy: 0.6362\n",
      "Epoch 223/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6446 - accuracy: 0.6325 - val_loss: 0.6585 - val_accuracy: 0.6362\n",
      "Epoch 224/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6441 - accuracy: 0.6316 - val_loss: 0.6584 - val_accuracy: 0.6362\n",
      "Epoch 225/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6438 - accuracy: 0.6353 - val_loss: 0.6589 - val_accuracy: 0.6344\n",
      "Epoch 226/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6422 - accuracy: 0.6348 - val_loss: 0.6595 - val_accuracy: 0.6271\n",
      "Epoch 227/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6435 - accuracy: 0.6316 - val_loss: 0.6572 - val_accuracy: 0.6344\n",
      "Epoch 228/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6443 - accuracy: 0.6303 - val_loss: 0.6576 - val_accuracy: 0.6362\n",
      "Epoch 229/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6409 - accuracy: 0.6335 - val_loss: 0.6562 - val_accuracy: 0.6399\n",
      "Epoch 230/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6445 - accuracy: 0.6389 - val_loss: 0.6573 - val_accuracy: 0.6417\n",
      "Epoch 231/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6451 - accuracy: 0.6312 - val_loss: 0.6592 - val_accuracy: 0.6325\n",
      "Epoch 232/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6417 - accuracy: 0.6353 - val_loss: 0.6569 - val_accuracy: 0.6380\n",
      "Epoch 233/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6455 - accuracy: 0.6307 - val_loss: 0.6584 - val_accuracy: 0.6380\n",
      "Epoch 234/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6426 - accuracy: 0.6280 - val_loss: 0.6563 - val_accuracy: 0.6380\n",
      "Epoch 235/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6450 - accuracy: 0.6344 - val_loss: 0.6644 - val_accuracy: 0.6325\n",
      "Epoch 236/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6446 - accuracy: 0.6303 - val_loss: 0.6578 - val_accuracy: 0.6325\n",
      "Epoch 237/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6432 - accuracy: 0.6371 - val_loss: 0.6587 - val_accuracy: 0.6289\n",
      "Epoch 238/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6430 - accuracy: 0.6316 - val_loss: 0.6584 - val_accuracy: 0.6380\n",
      "Epoch 239/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6453 - accuracy: 0.6403 - val_loss: 0.6571 - val_accuracy: 0.6380\n",
      "Epoch 240/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6415 - accuracy: 0.6385 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 241/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6422 - accuracy: 0.6325 - val_loss: 0.6602 - val_accuracy: 0.6234\n",
      "Epoch 242/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6431 - accuracy: 0.6339 - val_loss: 0.6584 - val_accuracy: 0.6362\n",
      "Epoch 243/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6415 - accuracy: 0.6325 - val_loss: 0.6588 - val_accuracy: 0.6325\n",
      "Epoch 244/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6441 - accuracy: 0.6261 - val_loss: 0.6590 - val_accuracy: 0.6179\n",
      "Epoch 245/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6418 - accuracy: 0.6417 - val_loss: 0.6608 - val_accuracy: 0.6271\n",
      "Epoch 246/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6405 - accuracy: 0.6394 - val_loss: 0.6583 - val_accuracy: 0.6380\n",
      "Epoch 247/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6446 - accuracy: 0.6380 - val_loss: 0.6566 - val_accuracy: 0.6362\n",
      "Epoch 248/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6405 - accuracy: 0.6312 - val_loss: 0.6589 - val_accuracy: 0.6271\n",
      "Epoch 249/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6411 - accuracy: 0.6380 - val_loss: 0.6647 - val_accuracy: 0.6344\n",
      "Epoch 250/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6442 - accuracy: 0.6367 - val_loss: 0.6567 - val_accuracy: 0.6325\n",
      "Epoch 251/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6445 - accuracy: 0.6385 - val_loss: 0.6580 - val_accuracy: 0.6380\n",
      "Epoch 252/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6436 - accuracy: 0.6266 - val_loss: 0.6599 - val_accuracy: 0.6472\n",
      "Epoch 253/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6414 - accuracy: 0.6357 - val_loss: 0.6605 - val_accuracy: 0.6289\n",
      "Epoch 254/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6398 - accuracy: 0.6344 - val_loss: 0.6583 - val_accuracy: 0.6453\n",
      "Epoch 255/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6435 - accuracy: 0.6348 - val_loss: 0.6556 - val_accuracy: 0.6380\n",
      "Epoch 256/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6435 - accuracy: 0.6307 - val_loss: 0.6602 - val_accuracy: 0.6124\n",
      "Epoch 257/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6423 - accuracy: 0.6271 - val_loss: 0.6561 - val_accuracy: 0.6435\n",
      "Epoch 258/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6428 - accuracy: 0.6344 - val_loss: 0.6580 - val_accuracy: 0.6289\n",
      "Epoch 259/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6443 - accuracy: 0.6335 - val_loss: 0.6583 - val_accuracy: 0.6289\n",
      "Epoch 260/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6395 - accuracy: 0.6380 - val_loss: 0.6570 - val_accuracy: 0.6399\n",
      "Epoch 261/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6422 - accuracy: 0.6344 - val_loss: 0.6558 - val_accuracy: 0.6344\n",
      "Epoch 262/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6407 - accuracy: 0.6339 - val_loss: 0.6580 - val_accuracy: 0.6325\n",
      "Epoch 263/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6419 - accuracy: 0.6353 - val_loss: 0.6569 - val_accuracy: 0.6344\n",
      "Epoch 264/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6415 - accuracy: 0.6417 - val_loss: 0.6567 - val_accuracy: 0.6234\n",
      "Epoch 265/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6409 - accuracy: 0.6339 - val_loss: 0.6567 - val_accuracy: 0.6344\n",
      "Epoch 266/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6413 - accuracy: 0.6357 - val_loss: 0.6583 - val_accuracy: 0.6289\n",
      "Epoch 267/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6422 - accuracy: 0.6348 - val_loss: 0.6569 - val_accuracy: 0.6362\n",
      "Epoch 268/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6392 - accuracy: 0.6394 - val_loss: 0.6569 - val_accuracy: 0.6362\n",
      "Epoch 269/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6414 - accuracy: 0.6330 - val_loss: 0.6599 - val_accuracy: 0.6289\n",
      "Epoch 270/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6422 - accuracy: 0.6417 - val_loss: 0.6600 - val_accuracy: 0.6307\n",
      "Epoch 271/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6398 - accuracy: 0.6399 - val_loss: 0.6573 - val_accuracy: 0.6307\n",
      "Epoch 272/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6409 - accuracy: 0.6408 - val_loss: 0.6614 - val_accuracy: 0.6307\n",
      "Epoch 273/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6420 - accuracy: 0.6376 - val_loss: 0.6574 - val_accuracy: 0.6380\n",
      "Epoch 274/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6401 - accuracy: 0.6403 - val_loss: 0.6555 - val_accuracy: 0.6380\n",
      "Epoch 275/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6447 - accuracy: 0.6289 - val_loss: 0.6545 - val_accuracy: 0.6362\n",
      "Epoch 276/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6400 - accuracy: 0.6335 - val_loss: 0.6587 - val_accuracy: 0.6307\n",
      "Epoch 277/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6377 - accuracy: 0.6421 - val_loss: 0.6559 - val_accuracy: 0.6362\n",
      "Epoch 278/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6367 - accuracy: 0.6403 - val_loss: 0.6542 - val_accuracy: 0.6344\n",
      "Epoch 279/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6391 - accuracy: 0.6348 - val_loss: 0.6582 - val_accuracy: 0.6325\n",
      "Epoch 280/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6367 - accuracy: 0.6449 - val_loss: 0.6529 - val_accuracy: 0.6380\n",
      "Epoch 281/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6404 - accuracy: 0.6367 - val_loss: 0.6560 - val_accuracy: 0.6325\n",
      "Epoch 282/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6433 - accuracy: 0.6289 - val_loss: 0.6582 - val_accuracy: 0.6289\n",
      "Epoch 283/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6405 - accuracy: 0.6362 - val_loss: 0.6576 - val_accuracy: 0.6234\n",
      "Epoch 284/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6408 - accuracy: 0.6435 - val_loss: 0.6553 - val_accuracy: 0.6289\n",
      "Epoch 285/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6404 - accuracy: 0.6417 - val_loss: 0.6563 - val_accuracy: 0.6252\n",
      "Epoch 286/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6425 - accuracy: 0.6353 - val_loss: 0.6546 - val_accuracy: 0.6417\n",
      "Epoch 287/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6373 - accuracy: 0.6412 - val_loss: 0.6580 - val_accuracy: 0.6362\n",
      "Epoch 288/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6404 - accuracy: 0.6385 - val_loss: 0.6534 - val_accuracy: 0.6325\n",
      "Epoch 289/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6401 - accuracy: 0.6394 - val_loss: 0.6543 - val_accuracy: 0.6362\n",
      "Epoch 290/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6415 - accuracy: 0.6330 - val_loss: 0.6547 - val_accuracy: 0.6325\n",
      "Epoch 291/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6354 - accuracy: 0.6403 - val_loss: 0.6556 - val_accuracy: 0.6307\n",
      "Epoch 292/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6408 - accuracy: 0.6399 - val_loss: 0.6597 - val_accuracy: 0.6106\n",
      "Epoch 293/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6381 - accuracy: 0.6394 - val_loss: 0.6538 - val_accuracy: 0.6362\n",
      "Epoch 294/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6347 - accuracy: 0.6481 - val_loss: 0.6585 - val_accuracy: 0.6271\n",
      "Epoch 295/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6401 - accuracy: 0.6312 - val_loss: 0.6554 - val_accuracy: 0.6435\n",
      "Epoch 296/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6390 - accuracy: 0.6376 - val_loss: 0.6536 - val_accuracy: 0.6453\n",
      "Epoch 297/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6409 - accuracy: 0.6472 - val_loss: 0.6531 - val_accuracy: 0.6271\n",
      "Epoch 298/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6375 - accuracy: 0.6426 - val_loss: 0.6548 - val_accuracy: 0.6289\n",
      "Epoch 299/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6386 - accuracy: 0.6467 - val_loss: 0.6563 - val_accuracy: 0.6271\n",
      "Epoch 300/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6383 - accuracy: 0.6321 - val_loss: 0.6540 - val_accuracy: 0.6252\n",
      "Epoch 301/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6413 - accuracy: 0.6481 - val_loss: 0.6547 - val_accuracy: 0.6289\n",
      "Epoch 302/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6403 - accuracy: 0.6421 - val_loss: 0.6546 - val_accuracy: 0.6325\n",
      "Epoch 303/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6336 - accuracy: 0.6531 - val_loss: 0.6542 - val_accuracy: 0.6271\n",
      "Epoch 304/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6406 - accuracy: 0.6385 - val_loss: 0.6538 - val_accuracy: 0.6289\n",
      "Epoch 305/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6378 - accuracy: 0.6444 - val_loss: 0.6573 - val_accuracy: 0.6197\n",
      "Epoch 306/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6405 - accuracy: 0.6435 - val_loss: 0.6553 - val_accuracy: 0.6271\n",
      "Epoch 307/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6392 - accuracy: 0.6449 - val_loss: 0.6579 - val_accuracy: 0.6271\n",
      "Epoch 308/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6353 - accuracy: 0.6476 - val_loss: 0.6576 - val_accuracy: 0.6344\n",
      "Epoch 309/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6372 - accuracy: 0.6463 - val_loss: 0.6570 - val_accuracy: 0.6271\n",
      "Epoch 310/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6358 - accuracy: 0.6444 - val_loss: 0.6599 - val_accuracy: 0.6015\n",
      "Epoch 311/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6346 - accuracy: 0.6549 - val_loss: 0.6615 - val_accuracy: 0.6271\n",
      "Epoch 312/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6388 - accuracy: 0.6421 - val_loss: 0.6557 - val_accuracy: 0.6325\n",
      "Epoch 313/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6343 - accuracy: 0.6490 - val_loss: 0.6569 - val_accuracy: 0.6307\n",
      "Epoch 314/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6382 - accuracy: 0.6408 - val_loss: 0.6545 - val_accuracy: 0.6271\n",
      "Epoch 315/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6356 - accuracy: 0.6513 - val_loss: 0.6559 - val_accuracy: 0.6417\n",
      "Epoch 316/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6350 - accuracy: 0.6467 - val_loss: 0.6582 - val_accuracy: 0.6216\n",
      "Epoch 317/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6371 - accuracy: 0.6499 - val_loss: 0.6560 - val_accuracy: 0.6252\n",
      "Epoch 318/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6347 - accuracy: 0.6504 - val_loss: 0.6560 - val_accuracy: 0.6234\n",
      "Epoch 319/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6372 - accuracy: 0.6476 - val_loss: 0.6537 - val_accuracy: 0.6271\n",
      "Epoch 320/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6355 - accuracy: 0.6495 - val_loss: 0.6544 - val_accuracy: 0.6362\n",
      "Epoch 321/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6301 - accuracy: 0.6586 - val_loss: 0.6588 - val_accuracy: 0.6124\n",
      "Epoch 322/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6355 - accuracy: 0.6467 - val_loss: 0.6615 - val_accuracy: 0.6088\n",
      "Epoch 323/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6341 - accuracy: 0.6522 - val_loss: 0.6568 - val_accuracy: 0.6179\n",
      "Epoch 324/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6322 - accuracy: 0.6472 - val_loss: 0.6614 - val_accuracy: 0.6289\n",
      "Epoch 325/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6368 - accuracy: 0.6431 - val_loss: 0.6562 - val_accuracy: 0.6216\n",
      "Epoch 326/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6358 - accuracy: 0.6467 - val_loss: 0.6555 - val_accuracy: 0.6179\n",
      "Epoch 327/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6332 - accuracy: 0.6522 - val_loss: 0.6628 - val_accuracy: 0.6069\n",
      "Epoch 328/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6375 - accuracy: 0.6435 - val_loss: 0.6546 - val_accuracy: 0.6216\n",
      "Epoch 329/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6329 - accuracy: 0.6536 - val_loss: 0.6526 - val_accuracy: 0.6271\n",
      "Epoch 330/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6370 - accuracy: 0.6403 - val_loss: 0.6520 - val_accuracy: 0.6344\n",
      "Epoch 331/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6321 - accuracy: 0.6508 - val_loss: 0.6552 - val_accuracy: 0.6234\n",
      "Epoch 332/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6380 - accuracy: 0.6412 - val_loss: 0.6516 - val_accuracy: 0.6325\n",
      "Epoch 333/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6361 - accuracy: 0.6499 - val_loss: 0.6538 - val_accuracy: 0.6252\n",
      "Epoch 334/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6320 - accuracy: 0.6499 - val_loss: 0.6526 - val_accuracy: 0.6307\n",
      "Epoch 335/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6340 - accuracy: 0.6444 - val_loss: 0.6549 - val_accuracy: 0.6197\n",
      "Epoch 336/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6323 - accuracy: 0.6549 - val_loss: 0.6549 - val_accuracy: 0.6179\n",
      "Epoch 337/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6336 - accuracy: 0.6559 - val_loss: 0.6528 - val_accuracy: 0.6344\n",
      "Epoch 338/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6341 - accuracy: 0.6476 - val_loss: 0.6519 - val_accuracy: 0.6307\n",
      "Epoch 339/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6341 - accuracy: 0.6440 - val_loss: 0.6548 - val_accuracy: 0.6179\n",
      "Epoch 340/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6306 - accuracy: 0.6540 - val_loss: 0.6545 - val_accuracy: 0.6197\n",
      "Epoch 341/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6312 - accuracy: 0.6522 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 342/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6339 - accuracy: 0.6513 - val_loss: 0.6553 - val_accuracy: 0.6161\n",
      "Epoch 343/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6320 - accuracy: 0.6458 - val_loss: 0.6569 - val_accuracy: 0.6124\n",
      "Epoch 344/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6318 - accuracy: 0.6581 - val_loss: 0.6520 - val_accuracy: 0.6289\n",
      "Epoch 345/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6317 - accuracy: 0.6449 - val_loss: 0.6601 - val_accuracy: 0.6069\n",
      "Epoch 346/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6352 - accuracy: 0.6485 - val_loss: 0.6535 - val_accuracy: 0.6252\n",
      "Epoch 347/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6324 - accuracy: 0.6513 - val_loss: 0.6548 - val_accuracy: 0.6124\n",
      "Epoch 348/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6331 - accuracy: 0.6499 - val_loss: 0.6518 - val_accuracy: 0.6234\n",
      "Epoch 349/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6307 - accuracy: 0.6549 - val_loss: 0.6580 - val_accuracy: 0.6051\n",
      "Epoch 350/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6322 - accuracy: 0.6540 - val_loss: 0.6548 - val_accuracy: 0.6197\n",
      "Epoch 351/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6341 - accuracy: 0.6431 - val_loss: 0.6596 - val_accuracy: 0.5941\n",
      "Epoch 352/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6293 - accuracy: 0.6513 - val_loss: 0.6555 - val_accuracy: 0.6197\n",
      "Epoch 353/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6340 - accuracy: 0.6499 - val_loss: 0.6594 - val_accuracy: 0.5960\n",
      "Epoch 354/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6342 - accuracy: 0.6463 - val_loss: 0.6533 - val_accuracy: 0.6234\n",
      "Epoch 355/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6326 - accuracy: 0.6504 - val_loss: 0.6534 - val_accuracy: 0.6234\n",
      "Epoch 356/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6301 - accuracy: 0.6572 - val_loss: 0.6547 - val_accuracy: 0.6271\n",
      "Epoch 357/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6302 - accuracy: 0.6568 - val_loss: 0.6591 - val_accuracy: 0.6124\n",
      "Epoch 358/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6340 - accuracy: 0.6449 - val_loss: 0.6517 - val_accuracy: 0.6161\n",
      "Epoch 359/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6359 - accuracy: 0.6463 - val_loss: 0.6544 - val_accuracy: 0.6216\n",
      "Epoch 360/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6327 - accuracy: 0.6545 - val_loss: 0.6552 - val_accuracy: 0.6179\n",
      "Epoch 361/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6327 - accuracy: 0.6508 - val_loss: 0.6520 - val_accuracy: 0.6197\n",
      "Epoch 362/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6334 - accuracy: 0.6586 - val_loss: 0.6561 - val_accuracy: 0.6234\n",
      "Epoch 363/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6333 - accuracy: 0.6508 - val_loss: 0.6571 - val_accuracy: 0.6143\n",
      "Epoch 364/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6314 - accuracy: 0.6609 - val_loss: 0.6551 - val_accuracy: 0.6252\n",
      "Epoch 365/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6306 - accuracy: 0.6504 - val_loss: 0.6578 - val_accuracy: 0.6069\n",
      "Epoch 366/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6345 - accuracy: 0.6481 - val_loss: 0.6556 - val_accuracy: 0.6197\n",
      "Epoch 367/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6278 - accuracy: 0.6600 - val_loss: 0.6616 - val_accuracy: 0.6088\n",
      "Epoch 368/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6326 - accuracy: 0.6586 - val_loss: 0.6562 - val_accuracy: 0.6143\n",
      "Epoch 369/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6317 - accuracy: 0.6513 - val_loss: 0.6512 - val_accuracy: 0.6179\n",
      "Epoch 370/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6278 - accuracy: 0.6590 - val_loss: 0.6540 - val_accuracy: 0.6234\n",
      "Epoch 371/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6378 - accuracy: 0.6380 - val_loss: 0.6559 - val_accuracy: 0.6197\n",
      "Epoch 372/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6248 - accuracy: 0.6577 - val_loss: 0.6538 - val_accuracy: 0.6325\n",
      "Epoch 373/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6330 - accuracy: 0.6554 - val_loss: 0.6537 - val_accuracy: 0.6124\n",
      "Epoch 374/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6317 - accuracy: 0.6604 - val_loss: 0.6537 - val_accuracy: 0.6088\n",
      "Epoch 375/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6295 - accuracy: 0.6577 - val_loss: 0.6578 - val_accuracy: 0.6051\n",
      "Epoch 376/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6348 - accuracy: 0.6513 - val_loss: 0.6517 - val_accuracy: 0.6216\n",
      "Epoch 377/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6296 - accuracy: 0.6613 - val_loss: 0.6544 - val_accuracy: 0.6216\n",
      "Epoch 378/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6280 - accuracy: 0.6536 - val_loss: 0.6577 - val_accuracy: 0.6307\n",
      "Epoch 379/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6316 - accuracy: 0.6449 - val_loss: 0.6562 - val_accuracy: 0.6124\n",
      "Epoch 380/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6277 - accuracy: 0.6568 - val_loss: 0.6557 - val_accuracy: 0.6252\n",
      "Epoch 381/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6283 - accuracy: 0.6554 - val_loss: 0.6548 - val_accuracy: 0.6289\n",
      "Epoch 382/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6300 - accuracy: 0.6527 - val_loss: 0.6554 - val_accuracy: 0.6179\n",
      "Epoch 383/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6271 - accuracy: 0.6563 - val_loss: 0.6569 - val_accuracy: 0.6106\n",
      "Epoch 384/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6238 - accuracy: 0.6618 - val_loss: 0.6571 - val_accuracy: 0.6069\n",
      "Epoch 385/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6303 - accuracy: 0.6458 - val_loss: 0.6529 - val_accuracy: 0.6271\n",
      "Epoch 386/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6292 - accuracy: 0.6568 - val_loss: 0.6578 - val_accuracy: 0.6179\n",
      "Epoch 387/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6276 - accuracy: 0.6513 - val_loss: 0.6616 - val_accuracy: 0.6015\n",
      "Epoch 388/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6320 - accuracy: 0.6554 - val_loss: 0.6575 - val_accuracy: 0.6161\n",
      "Epoch 389/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6274 - accuracy: 0.6604 - val_loss: 0.6533 - val_accuracy: 0.6179\n",
      "Epoch 390/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6279 - accuracy: 0.6586 - val_loss: 0.6573 - val_accuracy: 0.6143\n",
      "Epoch 391/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6282 - accuracy: 0.6590 - val_loss: 0.6557 - val_accuracy: 0.6234\n",
      "Epoch 392/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6293 - accuracy: 0.6458 - val_loss: 0.6585 - val_accuracy: 0.6216\n",
      "Epoch 393/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6257 - accuracy: 0.6540 - val_loss: 0.6565 - val_accuracy: 0.6106\n",
      "Epoch 394/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6276 - accuracy: 0.6563 - val_loss: 0.6537 - val_accuracy: 0.6216\n",
      "Epoch 395/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6247 - accuracy: 0.6453 - val_loss: 0.6559 - val_accuracy: 0.6179\n",
      "Epoch 396/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6265 - accuracy: 0.6513 - val_loss: 0.6604 - val_accuracy: 0.6088\n",
      "Epoch 397/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6253 - accuracy: 0.6595 - val_loss: 0.6695 - val_accuracy: 0.5960\n",
      "Epoch 398/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6308 - accuracy: 0.6481 - val_loss: 0.6559 - val_accuracy: 0.6197\n",
      "Epoch 399/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6261 - accuracy: 0.6600 - val_loss: 0.6556 - val_accuracy: 0.6161\n",
      "Epoch 400/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6268 - accuracy: 0.6590 - val_loss: 0.6579 - val_accuracy: 0.6161\n",
      "Epoch 401/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6250 - accuracy: 0.6595 - val_loss: 0.6557 - val_accuracy: 0.6197\n",
      "Epoch 402/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6264 - accuracy: 0.6572 - val_loss: 0.6523 - val_accuracy: 0.6289\n",
      "Epoch 403/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6310 - accuracy: 0.6609 - val_loss: 0.6560 - val_accuracy: 0.6307\n",
      "Epoch 404/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6297 - accuracy: 0.6545 - val_loss: 0.6534 - val_accuracy: 0.6161\n",
      "Epoch 405/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6276 - accuracy: 0.6559 - val_loss: 0.6518 - val_accuracy: 0.6325\n",
      "Epoch 406/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6261 - accuracy: 0.6549 - val_loss: 0.6575 - val_accuracy: 0.6124\n",
      "Epoch 407/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6262 - accuracy: 0.6700 - val_loss: 0.6562 - val_accuracy: 0.6124\n",
      "Epoch 408/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6262 - accuracy: 0.6513 - val_loss: 0.6513 - val_accuracy: 0.6143\n",
      "Epoch 409/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6248 - accuracy: 0.6600 - val_loss: 0.6517 - val_accuracy: 0.6179\n",
      "Epoch 410/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6297 - accuracy: 0.6527 - val_loss: 0.6585 - val_accuracy: 0.6197\n",
      "Epoch 411/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6239 - accuracy: 0.6600 - val_loss: 0.6524 - val_accuracy: 0.6271\n",
      "Epoch 412/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6201 - accuracy: 0.6581 - val_loss: 0.6566 - val_accuracy: 0.6197\n",
      "Epoch 413/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6247 - accuracy: 0.6636 - val_loss: 0.6582 - val_accuracy: 0.6124\n",
      "Epoch 414/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6290 - accuracy: 0.6545 - val_loss: 0.6568 - val_accuracy: 0.6216\n",
      "Epoch 415/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6246 - accuracy: 0.6604 - val_loss: 0.6532 - val_accuracy: 0.6289\n",
      "Epoch 416/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6237 - accuracy: 0.6563 - val_loss: 0.6551 - val_accuracy: 0.6216\n",
      "Epoch 417/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6252 - accuracy: 0.6604 - val_loss: 0.6600 - val_accuracy: 0.6088\n",
      "Epoch 418/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6284 - accuracy: 0.6545 - val_loss: 0.6525 - val_accuracy: 0.6197\n",
      "Epoch 419/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6244 - accuracy: 0.6563 - val_loss: 0.6546 - val_accuracy: 0.6289\n",
      "Epoch 420/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6245 - accuracy: 0.6563 - val_loss: 0.6592 - val_accuracy: 0.6051\n",
      "Epoch 421/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6272 - accuracy: 0.6581 - val_loss: 0.6562 - val_accuracy: 0.6106\n",
      "Epoch 422/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6285 - accuracy: 0.6513 - val_loss: 0.6522 - val_accuracy: 0.6179\n",
      "Epoch 423/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6252 - accuracy: 0.6595 - val_loss: 0.6558 - val_accuracy: 0.5996\n",
      "Epoch 424/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6243 - accuracy: 0.6600 - val_loss: 0.6562 - val_accuracy: 0.6033\n",
      "Epoch 425/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6233 - accuracy: 0.6563 - val_loss: 0.6569 - val_accuracy: 0.6143\n",
      "Epoch 426/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6226 - accuracy: 0.6577 - val_loss: 0.6625 - val_accuracy: 0.6124\n",
      "Epoch 427/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6226 - accuracy: 0.6549 - val_loss: 0.6563 - val_accuracy: 0.6325\n",
      "Epoch 428/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6229 - accuracy: 0.6654 - val_loss: 0.6568 - val_accuracy: 0.6106\n",
      "Epoch 429/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.6267 - accuracy: 0.6549 - val_loss: 0.6533 - val_accuracy: 0.6271\n",
      "Epoch 430/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6211 - accuracy: 0.6595 - val_loss: 0.6541 - val_accuracy: 0.6161\n",
      "Epoch 431/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6220 - accuracy: 0.6632 - val_loss: 0.6546 - val_accuracy: 0.6197\n",
      "Epoch 432/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6226 - accuracy: 0.6536 - val_loss: 0.6522 - val_accuracy: 0.6179\n",
      "Epoch 433/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6250 - accuracy: 0.6604 - val_loss: 0.6559 - val_accuracy: 0.6362\n",
      "Epoch 434/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6255 - accuracy: 0.6517 - val_loss: 0.6525 - val_accuracy: 0.6307\n",
      "Epoch 435/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6261 - accuracy: 0.6577 - val_loss: 0.6534 - val_accuracy: 0.6234\n",
      "Epoch 436/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6228 - accuracy: 0.6586 - val_loss: 0.6579 - val_accuracy: 0.6124\n",
      "Epoch 437/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6221 - accuracy: 0.6622 - val_loss: 0.6537 - val_accuracy: 0.6161\n",
      "Epoch 438/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6247 - accuracy: 0.6618 - val_loss: 0.6578 - val_accuracy: 0.6088\n",
      "Epoch 439/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6190 - accuracy: 0.6540 - val_loss: 0.6586 - val_accuracy: 0.6069\n",
      "Epoch 440/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6248 - accuracy: 0.6586 - val_loss: 0.6574 - val_accuracy: 0.6143\n",
      "Epoch 441/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6262 - accuracy: 0.6577 - val_loss: 0.6560 - val_accuracy: 0.6216\n",
      "Epoch 442/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6223 - accuracy: 0.6545 - val_loss: 0.6581 - val_accuracy: 0.6289\n",
      "Epoch 443/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6168 - accuracy: 0.6636 - val_loss: 0.6539 - val_accuracy: 0.6344\n",
      "Epoch 444/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6211 - accuracy: 0.6600 - val_loss: 0.6587 - val_accuracy: 0.6124\n",
      "Epoch 445/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6179 - accuracy: 0.6618 - val_loss: 0.6529 - val_accuracy: 0.6197\n",
      "Epoch 446/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6175 - accuracy: 0.6696 - val_loss: 0.6584 - val_accuracy: 0.6015\n",
      "Epoch 447/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6221 - accuracy: 0.6682 - val_loss: 0.6525 - val_accuracy: 0.6179\n",
      "Epoch 448/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6269 - accuracy: 0.6581 - val_loss: 0.6564 - val_accuracy: 0.6289\n",
      "Epoch 449/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6170 - accuracy: 0.6604 - val_loss: 0.6577 - val_accuracy: 0.6069\n",
      "Epoch 450/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6177 - accuracy: 0.6627 - val_loss: 0.6580 - val_accuracy: 0.6143\n",
      "Epoch 451/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6220 - accuracy: 0.6522 - val_loss: 0.6625 - val_accuracy: 0.6197\n",
      "Epoch 452/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6196 - accuracy: 0.6572 - val_loss: 0.6534 - val_accuracy: 0.6161\n",
      "Epoch 453/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6165 - accuracy: 0.6622 - val_loss: 0.6570 - val_accuracy: 0.6106\n",
      "Epoch 454/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6147 - accuracy: 0.6627 - val_loss: 0.6592 - val_accuracy: 0.6088\n",
      "Epoch 455/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6206 - accuracy: 0.6618 - val_loss: 0.6619 - val_accuracy: 0.6106\n",
      "Epoch 456/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6210 - accuracy: 0.6531 - val_loss: 0.6533 - val_accuracy: 0.6088\n",
      "Epoch 457/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6154 - accuracy: 0.6686 - val_loss: 0.6567 - val_accuracy: 0.6197\n",
      "Epoch 458/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6168 - accuracy: 0.6732 - val_loss: 0.6568 - val_accuracy: 0.6124\n",
      "Epoch 459/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6148 - accuracy: 0.6696 - val_loss: 0.6558 - val_accuracy: 0.6307\n",
      "Epoch 460/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6207 - accuracy: 0.6490 - val_loss: 0.6613 - val_accuracy: 0.6088\n",
      "Epoch 461/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6177 - accuracy: 0.6664 - val_loss: 0.6574 - val_accuracy: 0.6124\n",
      "Epoch 462/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6169 - accuracy: 0.6527 - val_loss: 0.6575 - val_accuracy: 0.6325\n",
      "Epoch 463/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6335 - accuracy: 0.6435 - val_loss: 0.6718 - val_accuracy: 0.6033\n",
      "Epoch 464/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6336 - accuracy: 0.6554 - val_loss: 0.6676 - val_accuracy: 0.5996\n",
      "Epoch 465/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6195 - accuracy: 0.6581 - val_loss: 0.6601 - val_accuracy: 0.6088\n",
      "Epoch 466/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6236 - accuracy: 0.6513 - val_loss: 0.6621 - val_accuracy: 0.5978\n",
      "Epoch 467/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6210 - accuracy: 0.6590 - val_loss: 0.6702 - val_accuracy: 0.5832\n",
      "Epoch 468/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6164 - accuracy: 0.6654 - val_loss: 0.6565 - val_accuracy: 0.6289\n",
      "Epoch 469/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6167 - accuracy: 0.6545 - val_loss: 0.6643 - val_accuracy: 0.5996\n",
      "Epoch 470/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6181 - accuracy: 0.6545 - val_loss: 0.6685 - val_accuracy: 0.6051\n",
      "Epoch 471/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6200 - accuracy: 0.6513 - val_loss: 0.6515 - val_accuracy: 0.6289\n",
      "Epoch 472/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6166 - accuracy: 0.6686 - val_loss: 0.6582 - val_accuracy: 0.6033\n",
      "Epoch 473/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6189 - accuracy: 0.6677 - val_loss: 0.6575 - val_accuracy: 0.5960\n",
      "Epoch 474/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6226 - accuracy: 0.6549 - val_loss: 0.6608 - val_accuracy: 0.6197\n",
      "Epoch 475/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6120 - accuracy: 0.6641 - val_loss: 0.6612 - val_accuracy: 0.6197\n",
      "Epoch 476/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6210 - accuracy: 0.6554 - val_loss: 0.6601 - val_accuracy: 0.6143\n",
      "Epoch 477/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6201 - accuracy: 0.6595 - val_loss: 0.6565 - val_accuracy: 0.6289\n",
      "Epoch 478/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.6192 - accuracy: 0.6650 - val_loss: 0.6564 - val_accuracy: 0.6106\n",
      "Epoch 479/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6152 - accuracy: 0.6668 - val_loss: 0.6612 - val_accuracy: 0.5996\n",
      "Epoch 480/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6173 - accuracy: 0.6572 - val_loss: 0.6568 - val_accuracy: 0.6197\n",
      "Epoch 481/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6215 - accuracy: 0.6508 - val_loss: 0.6553 - val_accuracy: 0.6106\n",
      "Epoch 482/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6178 - accuracy: 0.6613 - val_loss: 0.6566 - val_accuracy: 0.6197\n",
      "Epoch 483/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6156 - accuracy: 0.6705 - val_loss: 0.6544 - val_accuracy: 0.6271\n",
      "Epoch 484/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6134 - accuracy: 0.6609 - val_loss: 0.6615 - val_accuracy: 0.6143\n",
      "Epoch 485/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6139 - accuracy: 0.6677 - val_loss: 0.6558 - val_accuracy: 0.6179\n",
      "Epoch 486/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6154 - accuracy: 0.6590 - val_loss: 0.6582 - val_accuracy: 0.6088\n",
      "Epoch 487/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6190 - accuracy: 0.6545 - val_loss: 0.6592 - val_accuracy: 0.6161\n",
      "Epoch 488/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6168 - accuracy: 0.6645 - val_loss: 0.6598 - val_accuracy: 0.6289\n",
      "Epoch 489/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6177 - accuracy: 0.6632 - val_loss: 0.6577 - val_accuracy: 0.6106\n",
      "Epoch 490/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6192 - accuracy: 0.6632 - val_loss: 0.6589 - val_accuracy: 0.6143\n",
      "Epoch 491/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6142 - accuracy: 0.6563 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 492/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6184 - accuracy: 0.6568 - val_loss: 0.6587 - val_accuracy: 0.6124\n",
      "Epoch 493/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6131 - accuracy: 0.6723 - val_loss: 0.6597 - val_accuracy: 0.6161\n",
      "Epoch 494/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6146 - accuracy: 0.6654 - val_loss: 0.6628 - val_accuracy: 0.5960\n",
      "Epoch 495/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6178 - accuracy: 0.6641 - val_loss: 0.6580 - val_accuracy: 0.6197\n",
      "Epoch 496/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6109 - accuracy: 0.6718 - val_loss: 0.6570 - val_accuracy: 0.6179\n",
      "Epoch 497/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6141 - accuracy: 0.6590 - val_loss: 0.6626 - val_accuracy: 0.6179\n",
      "Epoch 498/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6099 - accuracy: 0.6723 - val_loss: 0.6586 - val_accuracy: 0.6161\n",
      "Epoch 499/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6150 - accuracy: 0.6645 - val_loss: 0.6591 - val_accuracy: 0.6069\n",
      "Epoch 500/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6131 - accuracy: 0.6609 - val_loss: 0.6614 - val_accuracy: 0.6051\n",
      "Epoch 501/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6099 - accuracy: 0.6705 - val_loss: 0.6590 - val_accuracy: 0.6106\n",
      "Epoch 502/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6187 - accuracy: 0.6568 - val_loss: 0.6583 - val_accuracy: 0.6051\n",
      "Epoch 503/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6108 - accuracy: 0.6682 - val_loss: 0.6582 - val_accuracy: 0.6143\n",
      "Epoch 504/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6169 - accuracy: 0.6622 - val_loss: 0.6635 - val_accuracy: 0.6216\n",
      "Epoch 505/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6123 - accuracy: 0.6705 - val_loss: 0.6617 - val_accuracy: 0.6124\n",
      "Epoch 506/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6137 - accuracy: 0.6664 - val_loss: 0.6692 - val_accuracy: 0.6088\n",
      "Epoch 507/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6166 - accuracy: 0.6641 - val_loss: 0.6634 - val_accuracy: 0.6106\n",
      "Epoch 508/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6153 - accuracy: 0.6636 - val_loss: 0.6617 - val_accuracy: 0.6106\n",
      "Epoch 509/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6102 - accuracy: 0.6691 - val_loss: 0.6619 - val_accuracy: 0.6216\n",
      "Epoch 510/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6136 - accuracy: 0.6673 - val_loss: 0.6584 - val_accuracy: 0.6161\n",
      "Epoch 511/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6110 - accuracy: 0.6728 - val_loss: 0.6698 - val_accuracy: 0.6033\n",
      "Epoch 512/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6107 - accuracy: 0.6741 - val_loss: 0.6645 - val_accuracy: 0.6069\n",
      "Epoch 513/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6117 - accuracy: 0.6709 - val_loss: 0.6631 - val_accuracy: 0.6088\n",
      "Epoch 514/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6067 - accuracy: 0.6641 - val_loss: 0.6589 - val_accuracy: 0.6015\n",
      "Epoch 515/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6052 - accuracy: 0.6686 - val_loss: 0.6599 - val_accuracy: 0.6197\n",
      "Epoch 516/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6075 - accuracy: 0.6728 - val_loss: 0.6577 - val_accuracy: 0.6106\n",
      "Epoch 517/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6099 - accuracy: 0.6691 - val_loss: 0.6598 - val_accuracy: 0.5978\n",
      "Epoch 518/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6084 - accuracy: 0.6750 - val_loss: 0.6668 - val_accuracy: 0.5887\n",
      "Epoch 519/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6139 - accuracy: 0.6590 - val_loss: 0.6582 - val_accuracy: 0.6015\n",
      "Epoch 520/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6077 - accuracy: 0.6650 - val_loss: 0.6608 - val_accuracy: 0.5978\n",
      "Epoch 521/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6089 - accuracy: 0.6673 - val_loss: 0.6676 - val_accuracy: 0.6069\n",
      "Epoch 522/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6117 - accuracy: 0.6645 - val_loss: 0.6635 - val_accuracy: 0.6088\n",
      "Epoch 523/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6062 - accuracy: 0.6741 - val_loss: 0.6589 - val_accuracy: 0.6143\n",
      "Epoch 524/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6074 - accuracy: 0.6632 - val_loss: 0.6644 - val_accuracy: 0.6106\n",
      "Epoch 525/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6072 - accuracy: 0.6696 - val_loss: 0.6585 - val_accuracy: 0.6161\n",
      "Epoch 526/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6024 - accuracy: 0.6700 - val_loss: 0.6636 - val_accuracy: 0.6197\n",
      "Epoch 527/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6073 - accuracy: 0.6673 - val_loss: 0.6602 - val_accuracy: 0.6033\n",
      "Epoch 528/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6120 - accuracy: 0.6664 - val_loss: 0.6618 - val_accuracy: 0.6015\n",
      "Epoch 529/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6080 - accuracy: 0.6645 - val_loss: 0.6613 - val_accuracy: 0.6015\n",
      "Epoch 530/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6106 - accuracy: 0.6618 - val_loss: 0.6587 - val_accuracy: 0.6069\n",
      "Epoch 531/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6072 - accuracy: 0.6746 - val_loss: 0.6607 - val_accuracy: 0.6161\n",
      "Epoch 532/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6120 - accuracy: 0.6677 - val_loss: 0.6654 - val_accuracy: 0.6124\n",
      "Epoch 533/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6097 - accuracy: 0.6686 - val_loss: 0.6563 - val_accuracy: 0.6216\n",
      "Epoch 534/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6044 - accuracy: 0.6746 - val_loss: 0.6594 - val_accuracy: 0.5996\n",
      "Epoch 535/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6081 - accuracy: 0.6600 - val_loss: 0.6604 - val_accuracy: 0.6179\n",
      "Epoch 536/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6044 - accuracy: 0.6760 - val_loss: 0.6651 - val_accuracy: 0.6051\n",
      "Epoch 537/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6072 - accuracy: 0.6732 - val_loss: 0.6557 - val_accuracy: 0.6088\n",
      "Epoch 538/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6051 - accuracy: 0.6600 - val_loss: 0.6634 - val_accuracy: 0.6197\n",
      "Epoch 539/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6075 - accuracy: 0.6641 - val_loss: 0.6618 - val_accuracy: 0.5996\n",
      "Epoch 540/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6057 - accuracy: 0.6718 - val_loss: 0.6667 - val_accuracy: 0.6033\n",
      "Epoch 541/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6081 - accuracy: 0.6700 - val_loss: 0.6633 - val_accuracy: 0.6143\n",
      "Epoch 542/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6068 - accuracy: 0.6664 - val_loss: 0.6682 - val_accuracy: 0.6106\n",
      "Epoch 543/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6089 - accuracy: 0.6645 - val_loss: 0.6676 - val_accuracy: 0.6051\n",
      "Epoch 544/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6091 - accuracy: 0.6691 - val_loss: 0.6625 - val_accuracy: 0.6033\n",
      "Epoch 545/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6052 - accuracy: 0.6718 - val_loss: 0.6691 - val_accuracy: 0.6106\n",
      "Epoch 546/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6053 - accuracy: 0.6668 - val_loss: 0.6735 - val_accuracy: 0.6106\n",
      "Epoch 547/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6073 - accuracy: 0.6778 - val_loss: 0.6641 - val_accuracy: 0.6015\n",
      "Epoch 548/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6086 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 0.6015\n",
      "Epoch 549/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6032 - accuracy: 0.6755 - val_loss: 0.6636 - val_accuracy: 0.6069\n",
      "Epoch 550/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6026 - accuracy: 0.6782 - val_loss: 0.6674 - val_accuracy: 0.6179\n",
      "Epoch 551/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.6031 - accuracy: 0.6600 - val_loss: 0.6763 - val_accuracy: 0.5631\n",
      "Epoch 552/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6149 - accuracy: 0.6686 - val_loss: 0.6663 - val_accuracy: 0.6143\n",
      "Epoch 553/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6059 - accuracy: 0.6728 - val_loss: 0.6709 - val_accuracy: 0.6015\n",
      "Epoch 554/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6020 - accuracy: 0.6755 - val_loss: 0.6620 - val_accuracy: 0.6015\n",
      "Epoch 555/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6027 - accuracy: 0.6764 - val_loss: 0.6711 - val_accuracy: 0.5868\n",
      "Epoch 556/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6120 - accuracy: 0.6627 - val_loss: 0.6638 - val_accuracy: 0.6143\n",
      "Epoch 557/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6038 - accuracy: 0.6737 - val_loss: 0.6673 - val_accuracy: 0.6124\n",
      "Epoch 558/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5950 - accuracy: 0.6842 - val_loss: 0.6629 - val_accuracy: 0.6106\n",
      "Epoch 559/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6067 - accuracy: 0.6682 - val_loss: 0.6719 - val_accuracy: 0.6106\n",
      "Epoch 560/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6097 - accuracy: 0.6700 - val_loss: 0.6666 - val_accuracy: 0.6106\n",
      "Epoch 561/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6049 - accuracy: 0.6696 - val_loss: 0.6670 - val_accuracy: 0.5923\n",
      "Epoch 562/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6096 - accuracy: 0.6645 - val_loss: 0.6686 - val_accuracy: 0.6069\n",
      "Epoch 563/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6019 - accuracy: 0.6728 - val_loss: 0.6644 - val_accuracy: 0.6106\n",
      "Epoch 564/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6024 - accuracy: 0.6746 - val_loss: 0.6633 - val_accuracy: 0.6033\n",
      "Epoch 565/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6084 - accuracy: 0.6668 - val_loss: 0.6613 - val_accuracy: 0.6051\n",
      "Epoch 566/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6033 - accuracy: 0.6700 - val_loss: 0.6629 - val_accuracy: 0.6179\n",
      "Epoch 567/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6112 - accuracy: 0.6696 - val_loss: 0.6673 - val_accuracy: 0.5978\n",
      "Epoch 568/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6073 - accuracy: 0.6622 - val_loss: 0.6699 - val_accuracy: 0.6088\n",
      "Epoch 569/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6023 - accuracy: 0.6810 - val_loss: 0.6647 - val_accuracy: 0.5996\n",
      "Epoch 570/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6025 - accuracy: 0.6846 - val_loss: 0.6635 - val_accuracy: 0.6051\n",
      "Epoch 571/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5921 - accuracy: 0.6833 - val_loss: 0.6654 - val_accuracy: 0.6179\n",
      "Epoch 572/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6001 - accuracy: 0.6810 - val_loss: 0.6681 - val_accuracy: 0.6088\n",
      "Epoch 573/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6006 - accuracy: 0.6773 - val_loss: 0.6712 - val_accuracy: 0.5996\n",
      "Epoch 574/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.5997 - accuracy: 0.6787 - val_loss: 0.6621 - val_accuracy: 0.6051\n",
      "Epoch 575/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.6043 - accuracy: 0.6673 - val_loss: 0.6628 - val_accuracy: 0.5996\n",
      "Epoch 576/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6034 - accuracy: 0.6718 - val_loss: 0.6586 - val_accuracy: 0.6088\n",
      "Epoch 577/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5996 - accuracy: 0.6755 - val_loss: 0.6732 - val_accuracy: 0.6069\n",
      "Epoch 578/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6007 - accuracy: 0.6750 - val_loss: 0.6749 - val_accuracy: 0.5905\n",
      "Epoch 579/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6019 - accuracy: 0.6650 - val_loss: 0.6663 - val_accuracy: 0.6033\n",
      "Epoch 580/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5993 - accuracy: 0.6792 - val_loss: 0.6745 - val_accuracy: 0.6252\n",
      "Epoch 581/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5988 - accuracy: 0.6750 - val_loss: 0.6721 - val_accuracy: 0.6069\n",
      "Epoch 582/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6071 - accuracy: 0.6622 - val_loss: 0.6660 - val_accuracy: 0.5978\n",
      "Epoch 583/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5986 - accuracy: 0.6764 - val_loss: 0.6712 - val_accuracy: 0.6179\n",
      "Epoch 584/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5997 - accuracy: 0.6746 - val_loss: 0.6716 - val_accuracy: 0.6106\n",
      "Epoch 585/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6061 - accuracy: 0.6645 - val_loss: 0.6683 - val_accuracy: 0.6161\n",
      "Epoch 586/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6006 - accuracy: 0.6792 - val_loss: 0.6679 - val_accuracy: 0.6051\n",
      "Epoch 587/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.6013 - accuracy: 0.6627 - val_loss: 0.6625 - val_accuracy: 0.6088\n",
      "Epoch 588/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5971 - accuracy: 0.6750 - val_loss: 0.6711 - val_accuracy: 0.6051\n",
      "Epoch 589/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6057 - accuracy: 0.6664 - val_loss: 0.6698 - val_accuracy: 0.6015\n",
      "Epoch 590/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5925 - accuracy: 0.6705 - val_loss: 0.6764 - val_accuracy: 0.6124\n",
      "Epoch 591/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5980 - accuracy: 0.6673 - val_loss: 0.6760 - val_accuracy: 0.5759\n",
      "Epoch 592/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5975 - accuracy: 0.6787 - val_loss: 0.6682 - val_accuracy: 0.5996\n",
      "Epoch 593/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6012 - accuracy: 0.6700 - val_loss: 0.6655 - val_accuracy: 0.6051\n",
      "Epoch 594/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5970 - accuracy: 0.6801 - val_loss: 0.6639 - val_accuracy: 0.6088\n",
      "Epoch 595/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6027 - accuracy: 0.6700 - val_loss: 0.6759 - val_accuracy: 0.6015\n",
      "Epoch 596/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6000 - accuracy: 0.6764 - val_loss: 0.6679 - val_accuracy: 0.5978\n",
      "Epoch 597/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5943 - accuracy: 0.6792 - val_loss: 0.6758 - val_accuracy: 0.6069\n",
      "Epoch 598/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6017 - accuracy: 0.6760 - val_loss: 0.6739 - val_accuracy: 0.5905\n",
      "Epoch 599/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5962 - accuracy: 0.6787 - val_loss: 0.6711 - val_accuracy: 0.6088\n",
      "Epoch 600/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6010 - accuracy: 0.6714 - val_loss: 0.6654 - val_accuracy: 0.6161\n",
      "Epoch 601/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6012 - accuracy: 0.6741 - val_loss: 0.6665 - val_accuracy: 0.6106\n",
      "Epoch 602/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6011 - accuracy: 0.6782 - val_loss: 0.6725 - val_accuracy: 0.5960\n",
      "Epoch 603/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.6000 - accuracy: 0.6577 - val_loss: 0.6665 - val_accuracy: 0.6161\n",
      "Epoch 604/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.6027 - accuracy: 0.6755 - val_loss: 0.6664 - val_accuracy: 0.6051\n",
      "Epoch 605/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6018 - accuracy: 0.6696 - val_loss: 0.6738 - val_accuracy: 0.6106\n",
      "Epoch 606/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.6032 - accuracy: 0.6691 - val_loss: 0.6715 - val_accuracy: 0.6143\n",
      "Epoch 607/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.6042 - accuracy: 0.6673 - val_loss: 0.6614 - val_accuracy: 0.6015\n",
      "Epoch 608/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5996 - accuracy: 0.6760 - val_loss: 0.6666 - val_accuracy: 0.6051\n",
      "Epoch 609/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5948 - accuracy: 0.6746 - val_loss: 0.6664 - val_accuracy: 0.5960\n",
      "Epoch 610/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5937 - accuracy: 0.6819 - val_loss: 0.6738 - val_accuracy: 0.6051\n",
      "Epoch 611/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5949 - accuracy: 0.6764 - val_loss: 0.6564 - val_accuracy: 0.6015\n",
      "Epoch 612/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6009 - accuracy: 0.6705 - val_loss: 0.6907 - val_accuracy: 0.6015\n",
      "Epoch 613/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5991 - accuracy: 0.6846 - val_loss: 0.6598 - val_accuracy: 0.6106\n",
      "Epoch 614/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5951 - accuracy: 0.6801 - val_loss: 0.6762 - val_accuracy: 0.6143\n",
      "Epoch 615/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.5958 - accuracy: 0.6773 - val_loss: 0.6638 - val_accuracy: 0.5996\n",
      "Epoch 616/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5945 - accuracy: 0.6778 - val_loss: 0.6709 - val_accuracy: 0.6051\n",
      "Epoch 617/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.6088 - accuracy: 0.6636 - val_loss: 0.6609 - val_accuracy: 0.5923\n",
      "Epoch 618/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5975 - accuracy: 0.6750 - val_loss: 0.6786 - val_accuracy: 0.6033\n",
      "Epoch 619/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5965 - accuracy: 0.6723 - val_loss: 0.6755 - val_accuracy: 0.5960\n",
      "Epoch 620/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5940 - accuracy: 0.6805 - val_loss: 0.6779 - val_accuracy: 0.6015\n",
      "Epoch 621/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5934 - accuracy: 0.6869 - val_loss: 0.6680 - val_accuracy: 0.6106\n",
      "Epoch 622/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5984 - accuracy: 0.6828 - val_loss: 0.6665 - val_accuracy: 0.6124\n",
      "Epoch 623/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5993 - accuracy: 0.6723 - val_loss: 0.6692 - val_accuracy: 0.6051\n",
      "Epoch 624/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5947 - accuracy: 0.6746 - val_loss: 0.6673 - val_accuracy: 0.5905\n",
      "Epoch 625/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5984 - accuracy: 0.6801 - val_loss: 0.6771 - val_accuracy: 0.5941\n",
      "Epoch 626/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5950 - accuracy: 0.6819 - val_loss: 0.6813 - val_accuracy: 0.5996\n",
      "Epoch 627/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5957 - accuracy: 0.6764 - val_loss: 0.6692 - val_accuracy: 0.6015\n",
      "Epoch 628/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5985 - accuracy: 0.6604 - val_loss: 0.6832 - val_accuracy: 0.6197\n",
      "Epoch 629/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6043 - accuracy: 0.6696 - val_loss: 0.6633 - val_accuracy: 0.5960\n",
      "Epoch 630/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5919 - accuracy: 0.6833 - val_loss: 0.6737 - val_accuracy: 0.5996\n",
      "Epoch 631/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5999 - accuracy: 0.6792 - val_loss: 0.6628 - val_accuracy: 0.6161\n",
      "Epoch 632/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5857 - accuracy: 0.6846 - val_loss: 0.6721 - val_accuracy: 0.5996\n",
      "Epoch 633/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.6069 - accuracy: 0.6723 - val_loss: 0.6780 - val_accuracy: 0.6051\n",
      "Epoch 634/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5998 - accuracy: 0.6700 - val_loss: 0.6704 - val_accuracy: 0.6325\n",
      "Epoch 635/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.5978 - accuracy: 0.6792 - val_loss: 0.6780 - val_accuracy: 0.6069\n",
      "Epoch 636/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5951 - accuracy: 0.6810 - val_loss: 0.6747 - val_accuracy: 0.6161\n",
      "Epoch 637/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5947 - accuracy: 0.6828 - val_loss: 0.6677 - val_accuracy: 0.6033\n",
      "Epoch 638/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5890 - accuracy: 0.6778 - val_loss: 0.6730 - val_accuracy: 0.6234\n",
      "Epoch 639/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5929 - accuracy: 0.6814 - val_loss: 0.6706 - val_accuracy: 0.6033\n",
      "Epoch 640/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5907 - accuracy: 0.6819 - val_loss: 0.6740 - val_accuracy: 0.6124\n",
      "Epoch 641/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5939 - accuracy: 0.6824 - val_loss: 0.6713 - val_accuracy: 0.6106\n",
      "Epoch 642/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5948 - accuracy: 0.6837 - val_loss: 0.6761 - val_accuracy: 0.5978\n",
      "Epoch 643/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5959 - accuracy: 0.6750 - val_loss: 0.6660 - val_accuracy: 0.5978\n",
      "Epoch 644/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5892 - accuracy: 0.6773 - val_loss: 0.6791 - val_accuracy: 0.6088\n",
      "Epoch 645/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5943 - accuracy: 0.6824 - val_loss: 0.6751 - val_accuracy: 0.5960\n",
      "Epoch 646/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5869 - accuracy: 0.6856 - val_loss: 0.6745 - val_accuracy: 0.6088\n",
      "Epoch 647/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5971 - accuracy: 0.6714 - val_loss: 0.6792 - val_accuracy: 0.6033\n",
      "Epoch 648/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5858 - accuracy: 0.6796 - val_loss: 0.6736 - val_accuracy: 0.5978\n",
      "Epoch 649/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5871 - accuracy: 0.6878 - val_loss: 0.6845 - val_accuracy: 0.5978\n",
      "Epoch 650/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5916 - accuracy: 0.6696 - val_loss: 0.6785 - val_accuracy: 0.6033\n",
      "Epoch 651/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5910 - accuracy: 0.6764 - val_loss: 0.6644 - val_accuracy: 0.5868\n",
      "Epoch 652/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5950 - accuracy: 0.6741 - val_loss: 0.6810 - val_accuracy: 0.5923\n",
      "Epoch 653/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.5902 - accuracy: 0.6824 - val_loss: 0.6792 - val_accuracy: 0.6051\n",
      "Epoch 654/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5872 - accuracy: 0.6874 - val_loss: 0.6753 - val_accuracy: 0.5978\n",
      "Epoch 655/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5929 - accuracy: 0.6778 - val_loss: 0.6803 - val_accuracy: 0.6106\n",
      "Epoch 656/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5857 - accuracy: 0.6778 - val_loss: 0.6717 - val_accuracy: 0.6088\n",
      "Epoch 657/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5960 - accuracy: 0.6782 - val_loss: 0.6779 - val_accuracy: 0.6069\n",
      "Epoch 658/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5900 - accuracy: 0.6878 - val_loss: 0.6775 - val_accuracy: 0.6124\n",
      "Epoch 659/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5877 - accuracy: 0.6760 - val_loss: 0.6811 - val_accuracy: 0.6015\n",
      "Epoch 660/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5979 - accuracy: 0.6792 - val_loss: 0.6781 - val_accuracy: 0.6033\n",
      "Epoch 661/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5901 - accuracy: 0.6828 - val_loss: 0.6701 - val_accuracy: 0.6069\n",
      "Epoch 662/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.5838 - accuracy: 0.6888 - val_loss: 0.6838 - val_accuracy: 0.5923\n",
      "Epoch 663/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.6048 - accuracy: 0.6888 - val_loss: 0.6676 - val_accuracy: 0.5868\n",
      "Epoch 664/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5921 - accuracy: 0.6805 - val_loss: 0.6872 - val_accuracy: 0.6015\n",
      "Epoch 665/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5942 - accuracy: 0.6792 - val_loss: 0.6747 - val_accuracy: 0.6143\n",
      "Epoch 666/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5905 - accuracy: 0.6668 - val_loss: 0.6790 - val_accuracy: 0.6106\n",
      "Epoch 667/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5883 - accuracy: 0.6819 - val_loss: 0.6810 - val_accuracy: 0.6124\n",
      "Epoch 668/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5974 - accuracy: 0.6696 - val_loss: 0.6839 - val_accuracy: 0.5923\n",
      "Epoch 669/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5912 - accuracy: 0.6792 - val_loss: 0.6867 - val_accuracy: 0.6069\n",
      "Epoch 670/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5880 - accuracy: 0.6833 - val_loss: 0.6932 - val_accuracy: 0.5923\n",
      "Epoch 671/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5876 - accuracy: 0.6796 - val_loss: 0.6740 - val_accuracy: 0.6143\n",
      "Epoch 672/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5898 - accuracy: 0.6878 - val_loss: 0.6819 - val_accuracy: 0.6124\n",
      "Epoch 673/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5879 - accuracy: 0.6728 - val_loss: 0.6774 - val_accuracy: 0.6015\n",
      "Epoch 674/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5893 - accuracy: 0.6869 - val_loss: 0.6763 - val_accuracy: 0.5996\n",
      "Epoch 675/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5908 - accuracy: 0.6856 - val_loss: 0.6641 - val_accuracy: 0.5941\n",
      "Epoch 676/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5910 - accuracy: 0.6760 - val_loss: 0.6857 - val_accuracy: 0.6088\n",
      "Epoch 677/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5940 - accuracy: 0.6796 - val_loss: 0.6750 - val_accuracy: 0.5978\n",
      "Epoch 678/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5911 - accuracy: 0.6865 - val_loss: 0.6811 - val_accuracy: 0.6051\n",
      "Epoch 679/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5871 - accuracy: 0.6888 - val_loss: 0.6695 - val_accuracy: 0.5996\n",
      "Epoch 680/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5910 - accuracy: 0.6814 - val_loss: 0.6748 - val_accuracy: 0.5978\n",
      "Epoch 681/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5840 - accuracy: 0.6792 - val_loss: 0.6807 - val_accuracy: 0.5978\n",
      "Epoch 682/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5864 - accuracy: 0.6837 - val_loss: 0.6766 - val_accuracy: 0.6161\n",
      "Epoch 683/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5885 - accuracy: 0.6837 - val_loss: 0.6807 - val_accuracy: 0.6033\n",
      "Epoch 684/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5839 - accuracy: 0.6878 - val_loss: 0.6801 - val_accuracy: 0.6015\n",
      "Epoch 685/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5894 - accuracy: 0.6828 - val_loss: 0.6897 - val_accuracy: 0.6051\n",
      "Epoch 686/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5935 - accuracy: 0.6700 - val_loss: 0.6767 - val_accuracy: 0.6088\n",
      "Epoch 687/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5861 - accuracy: 0.6828 - val_loss: 0.6801 - val_accuracy: 0.6069\n",
      "Epoch 688/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5918 - accuracy: 0.6810 - val_loss: 0.6724 - val_accuracy: 0.6015\n",
      "Epoch 689/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5921 - accuracy: 0.6764 - val_loss: 0.6772 - val_accuracy: 0.5941\n",
      "Epoch 690/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.5918 - accuracy: 0.6750 - val_loss: 0.6766 - val_accuracy: 0.6051\n",
      "Epoch 691/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5867 - accuracy: 0.6792 - val_loss: 0.6837 - val_accuracy: 0.5941\n",
      "Epoch 692/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5899 - accuracy: 0.6837 - val_loss: 0.6778 - val_accuracy: 0.6069\n",
      "Epoch 693/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5860 - accuracy: 0.6824 - val_loss: 0.6804 - val_accuracy: 0.6161\n",
      "Epoch 694/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5805 - accuracy: 0.6846 - val_loss: 0.6858 - val_accuracy: 0.5978\n",
      "Epoch 695/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5899 - accuracy: 0.6833 - val_loss: 0.6792 - val_accuracy: 0.5978\n",
      "Epoch 696/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5918 - accuracy: 0.6851 - val_loss: 0.6791 - val_accuracy: 0.6033\n",
      "Epoch 697/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5881 - accuracy: 0.6878 - val_loss: 0.6819 - val_accuracy: 0.6033\n",
      "Epoch 698/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.5878 - accuracy: 0.6878 - val_loss: 0.6634 - val_accuracy: 0.6088\n",
      "Epoch 699/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5828 - accuracy: 0.6920 - val_loss: 0.6838 - val_accuracy: 0.6143\n",
      "Epoch 700/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5876 - accuracy: 0.6828 - val_loss: 0.6817 - val_accuracy: 0.5960\n",
      "Epoch 701/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5877 - accuracy: 0.6805 - val_loss: 0.6734 - val_accuracy: 0.6197\n",
      "Epoch 702/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5858 - accuracy: 0.6828 - val_loss: 0.6670 - val_accuracy: 0.6015\n",
      "Epoch 703/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5934 - accuracy: 0.6883 - val_loss: 0.7025 - val_accuracy: 0.6051\n",
      "Epoch 704/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5915 - accuracy: 0.6760 - val_loss: 0.6765 - val_accuracy: 0.6106\n",
      "Epoch 705/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5850 - accuracy: 0.6851 - val_loss: 0.6813 - val_accuracy: 0.6216\n",
      "Epoch 706/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5835 - accuracy: 0.6897 - val_loss: 0.6951 - val_accuracy: 0.5960\n",
      "Epoch 707/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5855 - accuracy: 0.6810 - val_loss: 0.6876 - val_accuracy: 0.6106\n",
      "Epoch 708/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5985 - accuracy: 0.6728 - val_loss: 0.6721 - val_accuracy: 0.6088\n",
      "Epoch 709/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5908 - accuracy: 0.6737 - val_loss: 0.6857 - val_accuracy: 0.6051\n",
      "Epoch 710/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5854 - accuracy: 0.6805 - val_loss: 0.6865 - val_accuracy: 0.6143\n",
      "Epoch 711/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5799 - accuracy: 0.6869 - val_loss: 0.6692 - val_accuracy: 0.6051\n",
      "Epoch 712/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5884 - accuracy: 0.6796 - val_loss: 0.6729 - val_accuracy: 0.5996\n",
      "Epoch 713/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5823 - accuracy: 0.6878 - val_loss: 0.6731 - val_accuracy: 0.6143\n",
      "Epoch 714/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5901 - accuracy: 0.6837 - val_loss: 0.6815 - val_accuracy: 0.5978\n",
      "Epoch 715/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5956 - accuracy: 0.6801 - val_loss: 0.6832 - val_accuracy: 0.6069\n",
      "Epoch 716/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5858 - accuracy: 0.6814 - val_loss: 0.6753 - val_accuracy: 0.6069\n",
      "Epoch 717/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5854 - accuracy: 0.6824 - val_loss: 0.6840 - val_accuracy: 0.6088\n",
      "Epoch 718/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5861 - accuracy: 0.6801 - val_loss: 0.6855 - val_accuracy: 0.6106\n",
      "Epoch 719/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5782 - accuracy: 0.6897 - val_loss: 0.6941 - val_accuracy: 0.6051\n",
      "Epoch 720/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5930 - accuracy: 0.6718 - val_loss: 0.6842 - val_accuracy: 0.5978\n",
      "Epoch 721/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5871 - accuracy: 0.6842 - val_loss: 0.6762 - val_accuracy: 0.6234\n",
      "Epoch 722/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5808 - accuracy: 0.6888 - val_loss: 0.6875 - val_accuracy: 0.6033\n",
      "Epoch 723/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5857 - accuracy: 0.6718 - val_loss: 0.6747 - val_accuracy: 0.6106\n",
      "Epoch 724/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5833 - accuracy: 0.6842 - val_loss: 0.6807 - val_accuracy: 0.6088\n",
      "Epoch 725/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5862 - accuracy: 0.6860 - val_loss: 0.6806 - val_accuracy: 0.6033\n",
      "Epoch 726/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5851 - accuracy: 0.6846 - val_loss: 0.6865 - val_accuracy: 0.6051\n",
      "Epoch 727/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5853 - accuracy: 0.6837 - val_loss: 0.6914 - val_accuracy: 0.6051\n",
      "Epoch 728/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5820 - accuracy: 0.6874 - val_loss: 0.6840 - val_accuracy: 0.6051\n",
      "Epoch 729/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5848 - accuracy: 0.6929 - val_loss: 0.6753 - val_accuracy: 0.5941\n",
      "Epoch 730/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5815 - accuracy: 0.6915 - val_loss: 0.6850 - val_accuracy: 0.5996\n",
      "Epoch 731/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5830 - accuracy: 0.6860 - val_loss: 0.6813 - val_accuracy: 0.5905\n",
      "Epoch 732/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5927 - accuracy: 0.6796 - val_loss: 0.6804 - val_accuracy: 0.5832\n",
      "Epoch 733/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5847 - accuracy: 0.6883 - val_loss: 0.6751 - val_accuracy: 0.6051\n",
      "Epoch 734/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5804 - accuracy: 0.6796 - val_loss: 0.6761 - val_accuracy: 0.6033\n",
      "Epoch 735/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5881 - accuracy: 0.6865 - val_loss: 0.6911 - val_accuracy: 0.6161\n",
      "Epoch 736/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5872 - accuracy: 0.6782 - val_loss: 0.6921 - val_accuracy: 0.5960\n",
      "Epoch 737/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5880 - accuracy: 0.6769 - val_loss: 0.6842 - val_accuracy: 0.6088\n",
      "Epoch 738/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5833 - accuracy: 0.6869 - val_loss: 0.6775 - val_accuracy: 0.5978\n",
      "Epoch 739/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5858 - accuracy: 0.6828 - val_loss: 0.6791 - val_accuracy: 0.5832\n",
      "Epoch 740/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5795 - accuracy: 0.6819 - val_loss: 0.6778 - val_accuracy: 0.6069\n",
      "Epoch 741/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5788 - accuracy: 0.6892 - val_loss: 0.6753 - val_accuracy: 0.5941\n",
      "Epoch 742/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5859 - accuracy: 0.6869 - val_loss: 0.6824 - val_accuracy: 0.5868\n",
      "Epoch 743/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5862 - accuracy: 0.6801 - val_loss: 0.6813 - val_accuracy: 0.6051\n",
      "Epoch 744/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5869 - accuracy: 0.6787 - val_loss: 0.6840 - val_accuracy: 0.5960\n",
      "Epoch 745/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5807 - accuracy: 0.6805 - val_loss: 0.6782 - val_accuracy: 0.6106\n",
      "Epoch 746/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.5800 - accuracy: 0.6901 - val_loss: 0.6826 - val_accuracy: 0.6015\n",
      "Epoch 747/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5821 - accuracy: 0.6778 - val_loss: 0.6890 - val_accuracy: 0.5960\n",
      "Epoch 748/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5751 - accuracy: 0.6860 - val_loss: 0.6958 - val_accuracy: 0.5996\n",
      "Epoch 749/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.5885 - accuracy: 0.6787 - val_loss: 0.6830 - val_accuracy: 0.5960\n",
      "Epoch 750/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5853 - accuracy: 0.6906 - val_loss: 0.6884 - val_accuracy: 0.6069\n",
      "Epoch 751/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5792 - accuracy: 0.6851 - val_loss: 0.6813 - val_accuracy: 0.5923\n",
      "Epoch 752/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5872 - accuracy: 0.6883 - val_loss: 0.6711 - val_accuracy: 0.5960\n",
      "Epoch 753/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5863 - accuracy: 0.6828 - val_loss: 0.6843 - val_accuracy: 0.5978\n",
      "Epoch 754/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5793 - accuracy: 0.6810 - val_loss: 0.6814 - val_accuracy: 0.5887\n",
      "Epoch 755/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5842 - accuracy: 0.6778 - val_loss: 0.7086 - val_accuracy: 0.5960\n",
      "Epoch 756/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5779 - accuracy: 0.6888 - val_loss: 0.6728 - val_accuracy: 0.5923\n",
      "Epoch 757/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.5722 - accuracy: 0.6888 - val_loss: 0.6920 - val_accuracy: 0.5887\n",
      "Epoch 758/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5851 - accuracy: 0.6865 - val_loss: 0.6913 - val_accuracy: 0.5941\n",
      "Epoch 759/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5940 - accuracy: 0.6824 - val_loss: 0.6743 - val_accuracy: 0.6033\n",
      "Epoch 760/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5791 - accuracy: 0.6920 - val_loss: 0.6852 - val_accuracy: 0.5960\n",
      "Epoch 761/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5822 - accuracy: 0.6851 - val_loss: 0.6795 - val_accuracy: 0.6015\n",
      "Epoch 762/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5775 - accuracy: 0.6897 - val_loss: 0.6786 - val_accuracy: 0.5923\n",
      "Epoch 763/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5782 - accuracy: 0.6865 - val_loss: 0.6874 - val_accuracy: 0.6015\n",
      "Epoch 764/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5841 - accuracy: 0.6824 - val_loss: 0.6691 - val_accuracy: 0.5996\n",
      "Epoch 765/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5793 - accuracy: 0.6869 - val_loss: 0.7011 - val_accuracy: 0.5978\n",
      "Epoch 766/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5855 - accuracy: 0.6824 - val_loss: 0.6855 - val_accuracy: 0.5941\n",
      "Epoch 767/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5787 - accuracy: 0.6869 - val_loss: 0.6834 - val_accuracy: 0.5814\n",
      "Epoch 768/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5773 - accuracy: 0.6851 - val_loss: 0.7032 - val_accuracy: 0.6015\n",
      "Epoch 769/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5817 - accuracy: 0.7016 - val_loss: 0.6928 - val_accuracy: 0.5923\n",
      "Epoch 770/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5822 - accuracy: 0.6897 - val_loss: 0.6878 - val_accuracy: 0.5923\n",
      "Epoch 771/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5822 - accuracy: 0.6910 - val_loss: 0.6788 - val_accuracy: 0.5978\n",
      "Epoch 772/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5775 - accuracy: 0.6933 - val_loss: 0.6919 - val_accuracy: 0.5832\n",
      "Epoch 773/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5788 - accuracy: 0.6869 - val_loss: 0.6908 - val_accuracy: 0.5905\n",
      "Epoch 774/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5873 - accuracy: 0.6769 - val_loss: 0.6982 - val_accuracy: 0.6069\n",
      "Epoch 775/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5758 - accuracy: 0.6924 - val_loss: 0.6936 - val_accuracy: 0.5941\n",
      "Epoch 776/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5750 - accuracy: 0.6878 - val_loss: 0.6881 - val_accuracy: 0.5960\n",
      "Epoch 777/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5790 - accuracy: 0.6833 - val_loss: 0.6856 - val_accuracy: 0.5978\n",
      "Epoch 778/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5748 - accuracy: 0.6942 - val_loss: 0.6939 - val_accuracy: 0.6015\n",
      "Epoch 779/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.5805 - accuracy: 0.6819 - val_loss: 0.6960 - val_accuracy: 0.6069\n",
      "Epoch 780/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5772 - accuracy: 0.6897 - val_loss: 0.6936 - val_accuracy: 0.6015\n",
      "Epoch 781/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.5786 - accuracy: 0.6901 - val_loss: 0.6872 - val_accuracy: 0.5996\n",
      "Epoch 782/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.5775 - accuracy: 0.6906 - val_loss: 0.6808 - val_accuracy: 0.5923\n",
      "Epoch 783/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5807 - accuracy: 0.6888 - val_loss: 0.6870 - val_accuracy: 0.5722\n",
      "Epoch 784/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5698 - accuracy: 0.6933 - val_loss: 0.6823 - val_accuracy: 0.5960\n",
      "Epoch 785/1000\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.5800 - accuracy: 0.6892 - val_loss: 0.6899 - val_accuracy: 0.5868\n",
      "Epoch 786/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5745 - accuracy: 0.7029 - val_loss: 0.7001 - val_accuracy: 0.5905\n",
      "Epoch 787/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5861 - accuracy: 0.6846 - val_loss: 0.6925 - val_accuracy: 0.6015\n",
      "Epoch 788/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5807 - accuracy: 0.6851 - val_loss: 0.6939 - val_accuracy: 0.5923\n",
      "Epoch 789/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5795 - accuracy: 0.6869 - val_loss: 0.6786 - val_accuracy: 0.6015\n",
      "Epoch 790/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5756 - accuracy: 0.6869 - val_loss: 0.6922 - val_accuracy: 0.5905\n",
      "Epoch 791/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5714 - accuracy: 0.6915 - val_loss: 0.6941 - val_accuracy: 0.5996\n",
      "Epoch 792/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5722 - accuracy: 0.6956 - val_loss: 0.6899 - val_accuracy: 0.5923\n",
      "Epoch 793/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5745 - accuracy: 0.6856 - val_loss: 0.6906 - val_accuracy: 0.5868\n",
      "Epoch 794/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5791 - accuracy: 0.6883 - val_loss: 0.6890 - val_accuracy: 0.5649\n",
      "Epoch 795/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5751 - accuracy: 0.6878 - val_loss: 0.6873 - val_accuracy: 0.5996\n",
      "Epoch 796/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5746 - accuracy: 0.6856 - val_loss: 0.6985 - val_accuracy: 0.6051\n",
      "Epoch 797/1000\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.5670 - accuracy: 0.6888 - val_loss: 0.7012 - val_accuracy: 0.6051\n",
      "Epoch 798/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5721 - accuracy: 0.6942 - val_loss: 0.7003 - val_accuracy: 0.5887\n",
      "Epoch 799/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5747 - accuracy: 0.6947 - val_loss: 0.6949 - val_accuracy: 0.6051\n",
      "Epoch 800/1000\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.5706 - accuracy: 0.6974 - val_loss: 0.6941 - val_accuracy: 0.5978\n",
      "Epoch 801/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5761 - accuracy: 0.6952 - val_loss: 0.7030 - val_accuracy: 0.5923\n",
      "Epoch 802/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5687 - accuracy: 0.6846 - val_loss: 0.7005 - val_accuracy: 0.5996\n",
      "Epoch 803/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5773 - accuracy: 0.6883 - val_loss: 0.6979 - val_accuracy: 0.5923\n",
      "Epoch 804/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.5719 - accuracy: 0.6915 - val_loss: 0.6938 - val_accuracy: 0.5996\n",
      "Epoch 805/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5774 - accuracy: 0.6910 - val_loss: 0.6894 - val_accuracy: 0.5905\n",
      "Epoch 806/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5734 - accuracy: 0.6938 - val_loss: 0.6846 - val_accuracy: 0.5923\n",
      "Epoch 807/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5753 - accuracy: 0.6915 - val_loss: 0.6970 - val_accuracy: 0.6069\n",
      "Epoch 808/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5765 - accuracy: 0.6792 - val_loss: 0.6939 - val_accuracy: 0.6179\n",
      "Epoch 809/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5731 - accuracy: 0.7011 - val_loss: 0.6936 - val_accuracy: 0.6051\n",
      "Epoch 810/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5667 - accuracy: 0.6961 - val_loss: 0.6961 - val_accuracy: 0.5905\n",
      "Epoch 811/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5774 - accuracy: 0.6961 - val_loss: 0.7058 - val_accuracy: 0.5905\n",
      "Epoch 812/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5763 - accuracy: 0.6810 - val_loss: 0.7008 - val_accuracy: 0.5832\n",
      "Epoch 813/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5734 - accuracy: 0.6933 - val_loss: 0.7136 - val_accuracy: 0.5923\n",
      "Epoch 814/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5686 - accuracy: 0.6993 - val_loss: 0.7102 - val_accuracy: 0.5850\n",
      "Epoch 815/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5734 - accuracy: 0.6906 - val_loss: 0.6896 - val_accuracy: 0.5850\n",
      "Epoch 816/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.5631 - accuracy: 0.6997 - val_loss: 0.7049 - val_accuracy: 0.5978\n",
      "Epoch 817/1000\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.5605 - accuracy: 0.7006 - val_loss: 0.7090 - val_accuracy: 0.5923\n",
      "Epoch 818/1000\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.5772 - accuracy: 0.6892 - val_loss: 0.7003 - val_accuracy: 0.5814\n",
      "Epoch 819/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5801 - accuracy: 0.6878 - val_loss: 0.7029 - val_accuracy: 0.5923\n",
      "Epoch 820/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5777 - accuracy: 0.6901 - val_loss: 0.7077 - val_accuracy: 0.5850\n",
      "Epoch 821/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5813 - accuracy: 0.6878 - val_loss: 0.6982 - val_accuracy: 0.5905\n",
      "Epoch 822/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5768 - accuracy: 0.6837 - val_loss: 0.7058 - val_accuracy: 0.5941\n",
      "Epoch 823/1000\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.5676 - accuracy: 0.6901 - val_loss: 0.6956 - val_accuracy: 0.5795\n",
      "Epoch 824/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5696 - accuracy: 0.6878 - val_loss: 0.7041 - val_accuracy: 0.5978\n",
      "Epoch 825/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5698 - accuracy: 0.7025 - val_loss: 0.7217 - val_accuracy: 0.5868\n",
      "Epoch 826/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5751 - accuracy: 0.6901 - val_loss: 0.6966 - val_accuracy: 0.5923\n",
      "Epoch 827/1000\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.5688 - accuracy: 0.6947 - val_loss: 0.7012 - val_accuracy: 0.5941\n",
      "Epoch 828/1000\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.5710 - accuracy: 0.6929 - val_loss: 0.6924 - val_accuracy: 0.5978\n",
      "Epoch 829/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.5796 - accuracy: 0.6874 - val_loss: 0.7017 - val_accuracy: 0.5868\n",
      "Epoch 830/1000\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.5699 - accuracy: 0.6988 - val_loss: 0.7053 - val_accuracy: 0.5923\n",
      "Epoch 831/1000\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.5658 - accuracy: 0.6929 - val_loss: 0.6993 - val_accuracy: 0.5960\n",
      "Epoch 832/1000\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5624 - accuracy: 0.6929 - val_loss: 0.6956 - val_accuracy: 0.5850\n",
      "Epoch 833/1000\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.5695 - accuracy: 0.6924 - val_loss: 0.6995 - val_accuracy: 0.5978\n",
      "Epoch 834/1000\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 0.5692 - accuracy: 0.6897 - val_loss: 0.6991 - val_accuracy: 0.5978\n",
      "Epoch 835/1000\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5695 - accuracy: 0.6979 - val_loss: 0.7042 - val_accuracy: 0.6015\n",
      "Epoch 836/1000\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.5728 - accuracy: 0.6897 - val_loss: 0.7054 - val_accuracy: 0.5777\n",
      "Epoch 837/1000\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.5683 - accuracy: 0.6965 - val_loss: 0.6988 - val_accuracy: 0.5832\n",
      "Epoch 838/1000\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.5640 - accuracy: 0.6942 - val_loss: 0.7049 - val_accuracy: 0.5978\n",
      "Epoch 839/1000\n",
      "65/69 [===========================>..] - ETA: 0s - loss: 0.5694 - accuracy: 0.6962"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 996\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# hypermodel.fit(X_train, Y_train, epochs=467, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.518135  0.784314  0.624025       255\n",
      "           1   0.815436  0.566434  0.668501       429\n",
      "\n",
      "    accuracy                       0.647661       684\n",
      "   macro avg   0.666785  0.675374  0.646263       684\n",
      "weighted avg   0.704600  0.647661  0.651920       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "res.round()\n",
    "actual = []\n",
    "for num in res:\n",
    "    if num>0.5:\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,actual,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2115dc28b80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "confusionmatrix = confusion_matrix(Y_test, actual)\n",
    "cm_display = ConfusionMatrixDisplay(confusionmatrix, display_labels=[0,1])\n",
    "cm_display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
